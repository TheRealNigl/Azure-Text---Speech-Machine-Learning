<?xml version="1.0"?>
<doc>
    <assembly>
        <name>Microsoft.CognitiveServices.Speech.csharp</name>
    </assembly>
    <members>
        <member name="T:Microsoft.CognitiveServices.Speech.Internal.DisposableBase">
            <summary>
            Base class that implements IDisposable
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Internal.DisposableBase.Finalize">
            <summary>
            The base destructor
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Internal.DisposableBase.IsDisposed">
            <summary>
            Gets whether or not this object has been disposed
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Internal.DisposableBase.Dispose">
            <summary>
            Disposes the current object. It is safe to call this multiple times
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Internal.DisposableBase.Dispose(System.Boolean)">
            <summary>
            The method that actually disposes resources
            </summary>
            <param name="disposeManaged">True if we should dispose both managed and native
            resources, false if we should only dispose native resources</param>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Internal.DisposableBase.CheckDisposed">
            <summary>
            Checks if the object has been disposed and throws an exception if so
            </summary>
            <exception cref="T:System.ObjectDisposedException">If the object has been disposed</exception>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.Internal.ConversationTranslator">
            <summary>
            P/Invokes for the conversation translator
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.Internal.ConversationTranslator.SPXHANDLE_INVALID">
            <summary>
            An invalid handle
            </summary>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.Internal.ConversationTranslator.NativeReadString`1">
            <summary>
            Delegate to read a string value from native code. This will return the length if you pass
            <see cref="F:Microsoft.CognitiveServices.Speech.Internal.Utf8StringHandle.Null"/> as the native string handle. Otherwise it copy the
            native string into the passed in native string handle.
            </summary>
            <typeparam name="THandle">The handle type.</typeparam>
            <param name="handle">The native handle.</param>
            <param name="nativeString">The native string handle.</param>
            <param name="length">The length of the native string handle. If native string handle is
            null, this will be set to the native string length. Otherwise this will be used to determine
            the length of the passed in native string handle.</param>
            <returns>An SPXHR code indicating success, or failure.</returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.Internal.ConversationTranslator.NativeReadValue`2">
            <summary>
            Delegate to read a value from native code
            </summary>
            <typeparam name="THandle">The type of the handle.</typeparam>
            <typeparam name="TValue">The type of the value to read.</typeparam>
            <param name="handle">The native handle.</param>
            <param name="value">The value to set.</param>
            <returns>SPXHR code</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Internal.ConversationTranslator.GetString``1(``0,Microsoft.CognitiveServices.Speech.Internal.ConversationTranslator.NativeReadString{``0})">
            <summary>
            Helper method to read a UTF8 string from native code
            </summary>
            <typeparam name="THandle">The native handle type.</typeparam>
            <param name="handle">The native handle.</param>
            <param name="nativeMethod">The native method to read</param>
            <returns>The string value, or null. Throws an exception on errors</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Internal.ConversationTranslator.GetValue``1(Microsoft.CognitiveServices.Speech.Internal.InteropSafeHandle,Microsoft.CognitiveServices.Speech.Internal.ConversationTranslator.NativeReadValue{Microsoft.CognitiveServices.Speech.Internal.InteropSafeHandle,``0})">
            <summary>
            Helper method to read a value from native code
            </summary>
            <typeparam name="TValue">The value type to read</typeparam>
            <param name="handle">The native handle</param>
            <param name="method">The method to read from native code</param>
            <returns>The value or throws an exception on failure</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Internal.ConversationTranslator.GetValue``1(System.IntPtr,Microsoft.CognitiveServices.Speech.Internal.ConversationTranslator.NativeReadValue{System.IntPtr,``0})">
            <summary>
            Helper method to read a value from native code
            </summary>
            <typeparam name="TValue">The value type to read</typeparam>
            <param name="handle">The native handle</param>
            <param name="method">The method to read from native code</param>
            <returns>The value or throws an exception on failure</returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.Internal.InteropEvent`1">
            <summary>
            Helper class to simplify working with native events.
            </summary>
            <typeparam name="TEventArgs">The type of the event arguments</typeparam>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.Internal.InteropEvent`1.SetNativeCallback">
            <summary>
            Delegate used to set the event callback in the native code
            </summary>
            <param name="instanceHandle">The handle to the native instance</param>
            <param name="callback">The managed callback to invoke when the event is fired</param>
            <param name="context">The context to pass to the native code. This will be set to the managed
            instance GC handle</param>
            <returns>An SPXHR code. Non-zero values indicate failures.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Internal.InteropEvent`1.#ctor(System.Object,Microsoft.CognitiveServices.Speech.Internal.InteropSafeHandle,Microsoft.CognitiveServices.Speech.Internal.InteropEvent{`0}.SetNativeCallback)">
            <summary>
            Creates a new instance
            </summary>
            <param name="sender">The parent instance so events have the right sender</param>
            <param name="senderHandle">The handle to native version of the instance</param>
            <param name="setter">The delegate used to set the handler in native</param>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Internal.InteropEvent`1.Add(System.EventHandler{`0})">
            <summary>
            Adds a new managed event handler
            </summary>
            <param name="handler">The handler</param>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Internal.InteropEvent`1.Remove(System.EventHandler{`0})">
            <summary>
            Removes a managed handler
            </summary>
            <param name="handler">The handler</param>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Internal.InteropEvent`1.Dispose(System.Boolean)">
            <summary>
            Disposes the object
            </summary>
            <param name="disposeManaged">True to dispose managed resources</param>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Internal.InteropEvent`1.FromNativeCallback(System.IntPtr,System.IntPtr,System.IntPtr)">
            <summary>
            The method called from native code to handle event.
            </summary>
            <param name="instanceHandle">The handle to the object in native code.</param>
            <param name="eventHandle">The handle to event object in native code.</param>
            <param name="context">The native pointer used to retrieve the corresponding managed instance.</param>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.Internal.FileLogger">
            <summary>
            Methods to start and stop the file logger
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Internal.FileLogger.StartLogging(System.String)">
            <summary>
            Starts logging to a file.
            </summary>
            <param name="logFile">The file to log to.</param>
            <returns>The status code indicating success or the failure cause.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Internal.FileLogger.StopLogging">
            <summary>
            Stops logging to a file. This releases the file so it can be accessed by other processes.
            </summary>
            <returns>The status code indicating success or the failure cause.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Internal.FileLogger.ResetLogging">
            <summary>
            Resets all logging parameters set
            </summary>
            <returns>The status code indicating success or the failure cause.</returns>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.Internal.SpeakerRecognition.SPXHANDLE_INVALID">
            <summary>
            An invalid handle
            </summary>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.Internal.Utf8StringMarshaler">
            <summary>
            UTF-8 string marshaler.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Internal.Utf8StringMarshaler.MarshalNativeToManaged(System.IntPtr)">
            <summary>Converts the unmanaged data to managed data.</summary>
            <param name="native">A pointer to the unmanaged data to be wrapped.</param>
            <returns>An object that represents the managed view of the COM data.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Internal.Utf8StringMarshaler.MarshalManagedToNative(System.String)">
            <summary>Converts the managed data to unmanaged data.</summary>
            <param name="str">The managed string to be converted.</param>
            <returns>A pointer to the COM view of the managed object.</returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.Internal.Utf8StringHandle">
            <summary>
            Helper class to simplify marshaling a UTF8 string to native and back. You should use
            this in a using() block.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.Internal.Utf8StringHandle.Null">
            <summary>
            Returns a null UTF8 native string handle
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Internal.Utf8StringHandle.#ctor(System.String)">
            <summary>
            Creates a new instance
            </summary>
            <param name="str">The string to marshal</param>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Internal.Utf8StringHandle.#ctor(System.UInt32)">
            <summary>
            Creates a new instance
            </summary>
            <param name="maxLength">The maximum string length including the terminating \0</param>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Internal.Utf8StringHandle.#ctor">
            <summary>
            This is deliberately private to prevent using as an out parameter. You cannot free
            native code in managed unless it was explicitly allocated using LocalAlloc or
            CoTaskMemAlloc(). Using this as an out parameter could result in trying to free
            memory allocated using malloc or new().
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Internal.Utf8StringHandle.Length">
            <summary>
            Gets the length of the native string handle (including the trailing \0).
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Internal.Utf8StringHandle.ToString">
            <summary>
            Gets the managed string representation of the native string
            </summary>
            <returns>The managed string representation</returns>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Internal.Utf8StringHandle.IsInvalid">
            <summary>Gets a value that indicates whether the handle is invalid.</summary>
            <returns>
                <see langword="true" /> if the handle is not valid; otherwise, <see langword="false" />.
            </returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Internal.Utf8StringHandle.ReleaseHandle">
            <summary>
            Executes the code required to free the handle.
            </summary>
            <returns>
                <see langword="true" /> if the handle is released successfully; otherwise, in the event of a catastrophic failure, <see langword=" false" />.
            </returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.Dialog.DialogServiceConfig">
            <summary>
            Class that defines base configurations for dialog service connector
            Added in version 1.5.0
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Dialog.DialogServiceConfig.SetProperty(System.String,System.String)">
            <summary>
            Sets the property by name.
            </summary>
            <param name="name">Name of the property</param>
            <param name="value">Value of the property</param>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Dialog.DialogServiceConfig.SetProperty(Microsoft.CognitiveServices.Speech.PropertyId,System.String)">
            <summary>
            Sets the property by propertyId
            </summary>
            <param name="id">PropertyId of the property</param>
            <param name="value">Value of the property</param>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Dialog.DialogServiceConfig.GetProperty(System.String)">
            <summary>
            Gets the property by name.
            </summary>
            <param name="name">Name of the property</param>
            <returns>Value of the property</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Dialog.DialogServiceConfig.GetProperty(Microsoft.CognitiveServices.Speech.PropertyId)">
            <summary>
            Gets the property by propertyId.
            </summary>
            <param name="id">PropertyId of the property</param>
            <returns>Value of the property</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Dialog.DialogServiceConfig.SetServiceProperty(System.String,System.String,Microsoft.CognitiveServices.Speech.ServicePropertyChannel)">
            <summary>
            Sets a property value that will be passed to service using the specified channel.
            </summary>
            <param name="name">The property name.</param>
            <param name="value">The property value.</param>
            <param name="channel">The channel used to pass the specified property to service.</param>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Dialog.DialogServiceConfig.SetProxy(System.String,System.Int32,System.String,System.String)">
             <summary>
             Sets proxy configuration.
            
             Note: Proxy functionality is not available on macOS. This function will have no effect on this platform.
             </summary>
             <param name="proxyHostName">The host name of the proxy server, without the protocol scheme (http://)</param>
             <param name="proxyPort">The port number of the proxy server.</param>
             <param name="proxyUserName">The user name of the proxy server.</param>
             <param name="proxyPassword">The password of the proxy server.</param>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Dialog.DialogServiceConfig.SetProxy(System.String,System.Int32)">
            <summary>
            Sets proxy configuration.
            </summary>
            <param name="proxyHostName">The host name of the proxy server.</param>
            <param name="proxyPort">The port number of the proxy server.</param>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Dialog.DialogServiceConfig.Language">
            <summary>
            Specifies the name of the language to be used in BCP-47 format
            </summary>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.Dialog.BotFrameworkConfig">
            <summary>
            Class that defines configurations for the dialog service connector object for using a Bot Framework backend.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Dialog.BotFrameworkConfig.FromSubscription(System.String,System.String)">
            <summary>
            Creates an instance of the bot framework config with the specified subscription and region.
            </summary>
            <param name="subscription">Subscription key associated with the bot</param>
            <param name="region">The region name (see the <a href="https://aka.ms/csspeech/region">region page</a>).</param>
            <returns>A new bot framework config.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Dialog.BotFrameworkConfig.FromSubscription(System.String,System.String,System.String)">
            <summary>
            Creates an instance of the bot framework config with the specified subscription and region.
            </summary>
            <param name="subscription">Subscription key associated with the bot</param>
            <param name="region">The region name (see the <a href="https://aka.ms/csspeech/region">region page</a>).</param>
            <param name="botId">The bot ID (aka bot secret) used to select a bot associated with this subscription</param>
            <returns>A new bot framework config.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Dialog.BotFrameworkConfig.FromAuthorizationToken(System.String,System.String,System.String)">
            <summary>
            Creates an instance of the bot framework config with the specified authorization token and region.
            Note: The caller needs to ensure that the authorization token is valid. Before the authorization token
            expires, the caller needs to refresh it by calling this setter with a new valid token.
            As configuration values are copied when creating a new recognizer, the new token value will not apply to recognizers that have already been created.
            For recognizers that have been created before, you need to set authorization token of the corresponding recognizer
            to refresh the token. Otherwise, the recognizers will encounter errors during recognition.
            </summary>
            <param name="authorizationToken">The authorization token associated with the bot</param>
            <param name="region">The region name (see the <a href="https://aka.ms/csspeech/region">region page</a>).</param>
            <param name="botId">The optional bot ID (aka bot secret) used to select a bot associated with this subscription</param>
            <returns>A new bot framework config.</returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.Dialog.CustomCommandsConfig">
            <summary>
            Class that defines configurations for the dialog service connector object for using a CustomCommands backend.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Dialog.CustomCommandsConfig.FromSubscription(System.String,System.String,System.String)">
            <summary>
            Creates an instance of the dialog service config with the specified Custom Commands application id, subscription and region.
            </summary>
            <param name="applicationId">Custom Commands application id.</param>
            <param name="subscription">Subscription key associated with the application.</param>
            <param name="region">The region name (see the <a href="https://aka.ms/csspeech/region">region page</a>).</param>
            <returns>A new Custom Commands config.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Dialog.CustomCommandsConfig.FromAuthorizationToken(System.String,System.String,System.String)">
            <summary>
            Creates an instance of the dialog service config with the specified Custom Commands application id, authorization token and region.
            Note: The caller needs to ensure that the authorization token is valid. Before the authorization token
            expires, the caller needs to refresh it by calling this setter with a new valid token.
            As configuration values are copied when creating a new recognizer, the new token value will not apply to recognizers that have already been created.
            For recognizers that have been created before, you need to set authorization token of the corresponding recognizer
            to refresh the token. Otherwise, the recognizers will encounter errors during recognition.
            </summary>
            <param name="applicationId">Custom Commands application id.</param>
            <param name="authorizationToken">The authorization token associated with the application.</param>
            <param name="region">The region name (see the <a href="https://aka.ms/csspeech/region">region page</a>).</param>
            <returns>A new Custom Commands config.</returns>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Dialog.CustomCommandsConfig.ApplicationId">
            <summary>
            Custom Commands application identifier.
            </summary>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.Dialog.DialogServiceConnector">
            <summary>
            Connects to a speech enabled dialog.
            Added in version 1.5.0
            </summary>
        </member>
        <member name="E:Microsoft.CognitiveServices.Speech.Dialog.DialogServiceConnector.SessionStarted">
            <summary>
            Signal that indicates the start of a listening session. See also <see cref="T:Microsoft.CognitiveServices.Speech.SessionEventArgs"/>.
            </summary>
        </member>
        <member name="E:Microsoft.CognitiveServices.Speech.Dialog.DialogServiceConnector.SessionStopped">
            <summary>
            Signal that indicates the end of a listening session. See also <see cref="T:Microsoft.CognitiveServices.Speech.SessionEventArgs"/>.
            </summary>
        </member>
        <member name="E:Microsoft.CognitiveServices.Speech.Dialog.DialogServiceConnector.Recognized">
            <summary>
            Signal for events containing speech recognition results. See also <see cref="T:Microsoft.CognitiveServices.Speech.SpeechRecognitionEventArgs"/>.
            </summary>
        </member>
        <member name="E:Microsoft.CognitiveServices.Speech.Dialog.DialogServiceConnector.Recognizing">
            <summary>
            Signal for events containing intermediate recognition results. See also <see cref="T:Microsoft.CognitiveServices.Speech.SpeechRecognitionEventArgs"/>.
            </summary>
        </member>
        <member name="E:Microsoft.CognitiveServices.Speech.Dialog.DialogServiceConnector.Canceled">
            <summary>
            Signal for events relating to the cancellation of an interaction. See also <see cref="T:Microsoft.CognitiveServices.Speech.SpeechRecognitionCanceledEventArgs"/>.
            </summary>
        </member>
        <member name="E:Microsoft.CognitiveServices.Speech.Dialog.DialogServiceConnector.ActivityReceived">
            <summary>
            Signal that an activity was received from the backing dialog. See also <see cref="T:Microsoft.CognitiveServices.Speech.Dialog.ActivityReceivedEventArgs"/>.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Dialog.DialogServiceConnector.#ctor(Microsoft.CognitiveServices.Speech.Dialog.DialogServiceConfig)">
            <summary>
            Creates a dialog service connector using the default microphone input for a specified dialog service configuration.
            </summary>
            <param name="config">Dialog service config.</param>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Dialog.DialogServiceConnector.#ctor(Microsoft.CognitiveServices.Speech.Dialog.DialogServiceConfig,Microsoft.CognitiveServices.Speech.Audio.AudioConfig)">
            <summary>
            Creates a dialog service connector using the specified dialog and audio configuration.
            </summary>
            <param name="config">Dialog service config.</param>
            <param name="audioConfig">Audio config.</param>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Dialog.DialogServiceConnector.AuthorizationToken">
            <summary>
            Gets/sets authorization token used to communicate with the service.
            Note: The caller needs to ensure that the authorization token is valid. Before the authorization token
            expires, the caller needs to refresh it by calling this setter with a new valid token.
            Otherwise, the recognizer will encounter errors during recognition.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Dialog.DialogServiceConnector.SpeechActivityTemplate">
            <summary>
            Gets/sets the template for the activity generated by service from speech.
            Properties from the template will be stamped on the generated activity.
            It can be null or empty.
            Note: it has to be a valid Json object.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Dialog.DialogServiceConnector.Properties">
            <summary>
            The collection of properties and their values defined for this <see cref="T:Microsoft.CognitiveServices.Speech.Dialog.DialogServiceConnector"/>.
            Note: The property collection is only valid until the recognizer owning this Properties is disposed or finalized.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Dialog.DialogServiceConnector.Dispose">
            <summary>
            Dispose of associated resources.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Dialog.DialogServiceConnector.Dispose(System.Boolean)">
            <summary>
            This method performs cleanup of resources.
            The Boolean parameter <paramref name="disposing"/> indicates whether the method is called from <see cref="M:System.IDisposable.Dispose"/> (if <paramref name="disposing"/> is true) or from the finalizer (if <paramref name="disposing"/> is false).
            </summary>
            <param name="disposing">Flag to request disposal.</param>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.Dialog.DialogServiceConnector.gch">
            <summary>
            GC handle for callbacks for context.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.Dialog.DialogServiceConnector.disposed">
            <summary>
            disposed is a flag used to indicate if object is disposed.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.Dialog.DialogServiceConnector.isDisposing">
            <summary>
            isDisposing is a flag used to indicate if object is being disposed.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Dialog.DialogServiceConnector.FireEvent_SessionStarted(System.IntPtr,System.IntPtr,System.IntPtr)">
            <summary>
            Method to raise a SessionStarted C# event when a corresponding callback is invoked from the native layer.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Dialog.DialogServiceConnector.FireEvent_SessionStopped(System.IntPtr,System.IntPtr,System.IntPtr)">
            <summary>
            Method to raise a SessionStopped C# event when a corresponding callback is invoked from the native layer.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Dialog.DialogServiceConnector.FireEvent_Recognizing(System.IntPtr,System.IntPtr,System.IntPtr)">
            <summary>
            Method to raise a Recognizing C# event when a corresponding callback is invoked from the native layer.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Dialog.DialogServiceConnector.FireEvent_Recognized(System.IntPtr,System.IntPtr,System.IntPtr)">
            <summary>
            Method to raise a Recognized C# event when a corresponding callback is invoked from the native layer.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Dialog.DialogServiceConnector.FireEvent_Canceled(System.IntPtr,System.IntPtr,System.IntPtr)">
            <summary>
            Method to raise a Canceled C# event when a corresponding callback is invoked from the native layer.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Dialog.DialogServiceConnector.FireEvent_ActivityReceived(System.IntPtr,System.IntPtr,System.IntPtr)">
            <summary>
            Method to raise a ActivityReceived C# event when a corresponding callback is invoked from the native layer.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Dialog.DialogServiceConnector.ConnectAsync">
            <summary>
            Connects with the back end.
            </summary>
            <returns>An asynchronous operation that starts the connection.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Dialog.DialogServiceConnector.DisconnectAsync">
            <summary>
            Disconnects from the back end.
            </summary>
            <returns>An asynchronous operation that starts the disconnection.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Dialog.DialogServiceConnector.SendActivityAsync(System.String)">
            <summary>
            Sends an activity to the backing dialog.
            </summary>
            <param name="activityJSON">Activity to send as a serialized JSON</param>
            <returns>An asynchronous operation that starts the operation.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Dialog.DialogServiceConnector.StartKeywordRecognitionAsync(Microsoft.CognitiveServices.Speech.KeywordRecognitionModel)">
            <summary>
            Initiates keyword recognition.
            </summary>
            <param name="model">Specifies the keyword model to be used.</param>
            <returns>An asynchronous operation that starts the operation.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Dialog.DialogServiceConnector.StopKeywordRecognitionAsync">
            <summary>
            Stop keyword recognition.
            </summary>
            <returns>An asynchronous operation that starts the operation.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Dialog.DialogServiceConnector.ListenOnceAsync">
            <summary>
            Starts a listening session that will terminate after the first utterance.
            </summary>
            <returns>An asynchronous operation that starts the operation.  The task returns a value of <see cref="T:Microsoft.CognitiveServices.Speech.SpeechRecognitionResult"/>.</returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.Dialog.ActivityReceivedEventArgs">
            <summary>
            Class for activity received event arguments.
            Added in version 1.5.0
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Dialog.ActivityReceivedEventArgs.Activity">
            <summary>
            Gets the activity associated with the event as a serialized json.
            </summary>
            <returns>The activity.</returns>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Dialog.ActivityReceivedEventArgs.HasAudio">
            <summary>
            Checks if the event contains audio.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Dialog.ActivityReceivedEventArgs.Audio">
            <summary>
            Gets the audio associated with the event.
            </summary>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.Audio.AudioConfig">
            <summary>
            Represents audio input configuration used for specifying what type of input to use (microphone, file, stream).
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Audio.AudioConfig.FromDefaultMicrophoneInput">
            <summary>
            Creates an AudioConfig object representing the default microphone on the system.
            </summary>
            <returns>The audio input configuration being created.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Audio.AudioConfig.FromWavFileInput(System.String)">
            <summary>
            Creates an AudioConfig object representing the specified file.
            </summary>
            <param name="fileName">Specifies the audio input file.</param>
            <returns>The audio input configuration being created.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Audio.AudioConfig.FromStreamInput(Microsoft.CognitiveServices.Speech.Audio.AudioInputStream)">
            <summary>
            Creates an AudioConfig object representing the specified stream.
            </summary>
            <param name="audioStream">Specifies the custom audio input stream.</param>
            <returns>The audio input configuration being created.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Audio.AudioConfig.FromStreamInput(Microsoft.CognitiveServices.Speech.Audio.PullAudioInputStreamCallback)">
            <summary>
            Creates an AudioConfig object representing the specified stream.
            </summary>
            <param name="callback">Specifies the pull audio input stream callback.</param>
            <returns>The audio input configuration being created.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Audio.AudioConfig.FromStreamInput(Microsoft.CognitiveServices.Speech.Audio.PullAudioInputStreamCallback,Microsoft.CognitiveServices.Speech.Audio.AudioStreamFormat)">
            <summary>
            Creates an AudioConfig object representing the specified stream.
            </summary>
            <param name="callback">Specifies the pull audio input stream callback.</param>
            <param name="format">The audio data format in which audio will be written to the push audio stream's write() method.</param>
            <returns>The audio input configuration being created.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Audio.AudioConfig.FromMicrophoneInput(System.String)">
            <summary>
            Creates an AudioConfig object representing the designated input device.
            NOTE: This method was added in version 1.3.0.
            </summary>
            <param name="deviceName">Specifies the device name. Please refer to <a href="https://aka.ms/csspeech/microphone-selection">this page</a> on how to retrieve platform-specific microphone names.</param>
            <returns>The audio input configuration being created.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Audio.AudioConfig.FromDefaultSpeakerOutput">
            <summary>
            Creates an AudioConfig object representing the default speaker on the system.
            Added in version 1.4.0
            </summary>
            <returns>The audio output configuration being created.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Audio.AudioConfig.FromSpeakerOutput(System.String)">
            <summary>
            Creates an AudioConfig object representing the designated output device.
            NOTE: This method was added in version 1.14.0.
            </summary>
            <param name="deviceName">Specifies the device name. Please refer to <a href="https://aka.ms/csspeech/microphone-selection">this page</a> on how to retrieve platform-specific audio device names.</param>
            <returns>The audio output configuration being created.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Audio.AudioConfig.FromWavFileOutput(System.String)">
            <summary>
            Creates an AudioConfig object representing the specified file.
            Added in version 1.4.0
            </summary>
            <param name="fileName">Specifies the audio output file. The parent directory must already exist.</param>
            <returns>The audio output configuration being created.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Audio.AudioConfig.FromStreamOutput(Microsoft.CognitiveServices.Speech.Audio.AudioOutputStream)">
            <summary>
            Creates an AudioConfig object representing the specified stream.
            Added in version 1.4.0
            </summary>
            <param name="audioStream">Specifies the custom audio output stream.</param>
            <returns>The audio output configuration being created.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Audio.AudioConfig.FromStreamOutput(Microsoft.CognitiveServices.Speech.Audio.PushAudioOutputStreamCallback)">
            <summary>
            Creates an AudioConfig object representing the specified stream.
            Added in version 1.4.0
            </summary>
            <param name="callback">Specifies the push audio output stream callback.</param>
            <returns>The audio output configuration being created.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Audio.AudioConfig.Dispose">
            <summary>
            Dispose of associated resources.
            We may or may not dispose the audio stream, depending if we are told we own the stream give to us.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Audio.AudioConfig.SetProperty(System.String,System.String)">
            <summary>
            Sets the property by name.
            Added in version 1.10.0.
            </summary>
            <param name="name">Name of the property</param>
            <param name="value">Value of the property</param>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Audio.AudioConfig.SetProperty(Microsoft.CognitiveServices.Speech.PropertyId,System.String)">
            <summary>
            Sets the property by propertyId
            Added in version 1.10.0.
            </summary>
            <param name="id">PropertyId of the property</param>
            <param name="value">Value of the property</param>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Audio.AudioConfig.GetProperty(System.String)">
            <summary>
            Gets the property by name.
            Added in version 1.10.0.
            </summary>
            <param name="name">Name of the property</param>
            <returns>Value of the property</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Audio.AudioConfig.GetProperty(Microsoft.CognitiveServices.Speech.PropertyId)">
            <summary>
            Gets the property by propertyId
            Added in version 1.10.0.
            </summary>
            <param name="id">PropertyId of the property</param>
            <returns>Value of the property</returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.Audio.AudioInputStream">
            <summary>
            Represents audio input stream used for custom audio input configurations.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Audio.AudioInputStream.CreatePushStream">
            <summary>
            Creates a memory backed PushAudioInputStream using the default format (16 kHz, 16 bit, mono PCM).
            </summary>
            <returns>The push audio input stream being created.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Audio.AudioInputStream.CreatePushStream(Microsoft.CognitiveServices.Speech.Audio.AudioStreamFormat)">
            <summary>
            Creates a memory backed PushAudioInputStream with the specified audio format.
            </summary>
            <param name="format">The audio data format in which audio will be written to the push audio stream's write() method.</param>
            <returns>The push audio input stream being created.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Audio.AudioInputStream.CreatePullStream(Microsoft.CognitiveServices.Speech.Audio.PullAudioInputStreamCallback)">
            <summary>
            Creates a PullAudioInputStream that delegates to the specified callback interface for read() and close() methods, using the default format (16 kHz, 16 bit, mono PCM).
            </summary>
            <param name="callback">The custom audio input object, derived from PullAudioInputStreamCallback</param>
            <returns>The pull audio input stream being created.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Audio.AudioInputStream.CreatePullStream(Microsoft.CognitiveServices.Speech.Audio.PullAudioInputStreamCallback,Microsoft.CognitiveServices.Speech.Audio.AudioStreamFormat)">
            <summary>
            Creates a PullAudioInputStream that delegates to the specified callback interface for read() and close() methods.
            </summary>
            <param name="callback">The custom audio input object, derived from PullAudioInputStreamCallback.</param>
            <param name="format">The audio data format in which audio will be returned from the callback's read() method.</param>
            <returns>The pull audio input stream being created.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Audio.AudioInputStream.Dispose">
            <summary>
            Dispose of associated resources.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Audio.AudioInputStream.Dispose(System.Boolean)">
            <summary>
            This method performs cleanup of resources.
            The Boolean parameter <paramref name="disposing"/> indicates whether the method is called from <see cref="M:System.IDisposable.Dispose"/> (if <paramref name="disposing"/> is true) or from the finalizer (if <paramref name="disposing"/> is false).
            Derived classes should override this method to dispose resource if needed.
            </summary>
            <param name="disposing">Flag to request disposal.</param>
            <returns></returns>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.Audio.AudioInputStream.isDisposing">
            <summary>
            isDisposing is a flag used to indicate if object is being disposed.
            </summary>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.Audio.PushAudioInputStream">
            <summary>
            Represents memory backed push audio input stream used for custom audio input configurations.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Audio.PushAudioInputStream.#ctor">
            <summary>
            Creates a memory backed PushAudioInputStream using the default format (16 kHz, 16 bit, mono PCM).
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Audio.PushAudioInputStream.#ctor(Microsoft.CognitiveServices.Speech.Audio.AudioStreamFormat)">
            <summary>
            Creates a memory backed PushAudioInputStream with the specified audio format.
            </summary>
            <param name="format">The audio data format in which audio will be written to the push audio stream's write() method.</param>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Audio.PushAudioInputStream.Write(System.Byte[])">
            <summary>
            Writes the audio data specified by making an internal copy of the data.
            Note: The dataBuffer should not contain any audio header.
            </summary>
            <param name="dataBuffer">The audio buffer of which this function will make a copy.</param>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Audio.PushAudioInputStream.Write(System.Byte[],System.Int32)">
            <summary>
            Writes the audio data specified by making an internal copy of the data.
            </summary>
            <param name="dataBuffer">The audio buffer of which this function will make a copy.</param>
            <param name="size">The size of the data in the audio buffer. Note the size could be smaller than dataBuffer.Length</param>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Audio.PushAudioInputStream.SetProperty(Microsoft.CognitiveServices.Speech.PropertyId,System.String)">
            <summary>
            Set value of a property associated to data buffer. The properties of the audio data should be set before writing the audio data.
            Added in version 1.5.0
            </summary>
            <param name="id">A property Id.</param>
            <param name="value">The value of the property.</param>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Audio.PushAudioInputStream.SetProperty(System.String,System.String)">
            <summary>
            Set value of a property associated to data buffer. The properties of the audio data should be set before writing the audio data.
            Added in version 1.5.0
            </summary>
            <param name="name">The name of the property.</param>
            <param name="value">The value of the property.</param>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Audio.PushAudioInputStream.Close">
            <summary>
            Closes the stream.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Audio.PushAudioInputStream.Dispose(System.Boolean)">
            <summary>
            This method performs cleanup of resources.
            The Boolean parameter <paramref name="disposing"/> indicates whether the method is called from <see cref="M:System.IDisposable.Dispose"/> (if <paramref name="disposing"/> is true) or from the finalizer (if <paramref name="disposing"/> is false).
            Derived classes should override this method to dispose resource if needed.
            </summary>
            <param name="disposing">Flag to request disposal.</param>
            <returns></returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.Audio.PullAudioInputStream">
            <summary>
            Represents audio input stream used for custom audio input configurations.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Audio.PullAudioInputStream.#ctor(Microsoft.CognitiveServices.Speech.Audio.PullAudioInputStreamCallback)">
            <summary>
            Creates a PullAudioInputStream that delegates to the specified callback interface for read() and close() methods using the default format (16 kHz, 16 bit, mono PCM).
            </summary>
            <param name="callback">The custom audio input object, derived from PullAudioInputStreamCallback.</param>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Audio.PullAudioInputStream.#ctor(Microsoft.CognitiveServices.Speech.Audio.PullAudioInputStreamCallback,Microsoft.CognitiveServices.Speech.Audio.AudioStreamFormat)">
            <summary>
            Creates a PullAudioInputStream that delegates to the specified callback interface for read() and close() methods.
            </summary>
            <param name="callback">The custom audio input object, derived from PullAudioInputStreamCallback.</param>
            <param name="format">The audio data format in which audio will be returned from the callback's read() method.</param>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Audio.PullAudioInputStream.Dispose(System.Boolean)">
            <summary>
            This method performs cleanup of resources.
            The Boolean parameter <paramref name="disposing"/> indicates whether the method is called from <see cref="M:System.IDisposable.Dispose"/> (if <paramref name="disposing"/> is true) or from the finalizer (if <paramref name="disposing"/> is false).
            Derived classes should override this method to dispose resource if needed.
            </summary>
            <param name="disposing">Flag to request disposal.</param>
            <returns></returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.Audio.PullAudioInputStreamCallback">
            <summary>
            An abstract base class that defines callback methods (Read() and Close()) for custom audio input streams).
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Audio.PullAudioInputStreamCallback.Read(System.Byte[],System.UInt32)">
            <summary>
            Reads binary data from the stream.
            Note: The dataBuffer returned by Read() should not contain any audio header.
            </summary>
            <param name="dataBuffer">The buffer to fill</param>
            <param name="size">The size of the buffer.</param>
            <returns>The number of bytes filled, or 0 in case the stream hits its end and there is no more data available.
            If there is no data immediately available, Read() blocks until the next data becomes available.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Audio.PullAudioInputStreamCallback.GetProperty(Microsoft.CognitiveServices.Speech.PropertyId)">
            <summary>
            Get property associated to data buffer, such as a timestamp or userId. if the property is not available, an empty string must be returned.
            Added in version 1.5.0
            </summary>
            <param name="id">A property id.</param>
            <returns>The value of the property </returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Audio.PullAudioInputStreamCallback.Close">
            <summary>
            Closes the audio input stream.
            </summary>
            <returns></returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Audio.PullAudioInputStreamCallback.Dispose">
            <summary>
            Dispose of associated resources.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Audio.PullAudioInputStreamCallback.Dispose(System.Boolean)">
            <summary>
            This method performs cleanup of resources.
            The Boolean parameter <paramref name="disposing"/> indicates whether the method is called from <see cref="M:System.IDisposable.Dispose"/> (if <paramref name="disposing"/> is true) or from the finalizer (if <paramref name="disposing"/> is false).
            Derived classes should override this method to dispose resource if needed.
            </summary>
            <param name="disposing">Flag to request disposal.</param>
            <returns></returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.Audio.AudioOutputStream">
            <summary>
            Represents audio output stream used for custom audio output configurations.
            Updated in version 1.7.0
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Audio.AudioOutputStream.CreatePullStream">
            <summary>
            Creates a memory backed PullAudioOutputStream.
            </summary>
            <returns>The pull audio output stream being created.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Audio.AudioOutputStream.CreatePushStream(Microsoft.CognitiveServices.Speech.Audio.PushAudioOutputStreamCallback)">
            <summary>
            Creates a PushAudioOutputStream that delegates to the specified callback interface for write() and close() methods.
            </summary>
            <param name="callback">The custom audio output object, derived from PushAudioOutputStreamCallback</param>
            <returns>The push audio output stream being created.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Audio.AudioOutputStream.Dispose">
            <summary>
            Dispose of associated resources.
            </summary>
            <returns></returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Audio.AudioOutputStream.Dispose(System.Boolean)">
            <summary>
            This method performs cleanup of resources.
            The Boolean parameter <paramref name="disposing"/> indicates whether the method is called from <see cref="M:System.IDisposable.Dispose"/> (if <paramref name="disposing"/> is true) or from the finalizer (if <paramref name="disposing"/> is false).
            Derived classes should override this method to dispose resource if needed.
            </summary>
            <param name="disposing">Flag to request disposal.</param>
            <returns></returns>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.Audio.AudioOutputStream.isDisposing">
            <summary>
            isDisposing is a flag used to indicate if object is being disposed.
            </summary>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.Audio.PullAudioOutputStream">
            <summary>
            Represents memory backed pull audio output stream used for custom audio output configurations.
            Updated in version 1.7.0
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Audio.PullAudioOutputStream.#ctor">
            <summary>
            Creates a memory backed PullAudioOutputStream.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Audio.PullAudioOutputStream.Read(System.Byte[])">
            <summary>
            Read audio from the stream.
            The maximal number of bytes to be read is determined by the size of dataBuffer.
            If there is no data immediately available, read() blocks until the next data becomes available.
            </summary>
            <param name="buffer">The buffer to receive the audio data</param>
            <returns>The number of bytes filled, or 0 in case the stream hits its end and there is no more data available.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Audio.PullAudioOutputStream.Dispose(System.Boolean)">
            <summary>
            This method performs cleanup of resources.
            The Boolean parameter <paramref name="disposing"/> indicates whether the method is called from <see cref="M:System.IDisposable.Dispose"/> (if <paramref name="disposing"/> is true) or from the finalizer (if <paramref name="disposing"/> is false).
            Derived classes should override this method to dispose resource if needed.
            </summary>
            <param name="disposing">Flag to request disposal.</param>
            <returns></returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.Audio.PushAudioOutputStream">
            <summary>
            Represents audio output stream used for custom audio output configurations.
            Updated in version 1.7.0
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Audio.PushAudioOutputStream.#ctor(Microsoft.CognitiveServices.Speech.Audio.PushAudioOutputStreamCallback)">
            <summary>
            Creates a PushAudioOutputStream that delegates to the specified callback interface for write() and close() methods.
            </summary>
            <param name="callback">The custom audio output object, derived from PushAudioOutputStreamCallback.</param>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Audio.PushAudioOutputStream.Dispose(System.Boolean)">
            <summary>
            This method performs cleanup of resources.
            The Boolean parameter <paramref name="disposing"/> indicates whether the method is called from <see cref="M:System.IDisposable.Dispose"/> (if <paramref name="disposing"/> is true) or from the finalizer (if <paramref name="disposing"/> is false).
            Derived classes should override this method to dispose resource if needed.
            </summary>
            <param name="disposing">Flag to request disposal.</param>
            <returns></returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.Audio.PushAudioOutputStreamCallback">
            <summary>
            An abstract base class that defines callback methods (Write() and Close()) for custom audio output streams).
            Added in version 1.4.0
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Audio.PushAudioOutputStreamCallback.Write(System.Byte[])">
            <summary>
            Writes binary data to the stream.
            </summary>
            <param name="dataBuffer">The buffer containing the data to be written</param>
            <returns>The number of bytes written.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Audio.PushAudioOutputStreamCallback.Close">
            <summary>
            Closes the audio output stream.
            </summary>
            <returns></returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Audio.PushAudioOutputStreamCallback.Dispose">
            <summary>
            Dispose of associated resources.
            </summary>
            <returns></returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Audio.PushAudioOutputStreamCallback.Dispose(System.Boolean)">
            <summary>
            This method performs cleanup of resources.
            The Boolean parameter <paramref name="disposing"/> indicates whether the method is called from <see cref="M:System.IDisposable.Dispose"/> (if <paramref name="disposing"/> is true) or from the finalizer (if <paramref name="disposing"/> is false).
            Derived classes should override this method to dispose resource if needed.
            </summary>
            <param name="disposing">Flag to request disposal.</param>
            <returns></returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.Audio.AudioStreamContainerFormat">
            <summary>
            Supported audio input container formats.
            Added in version 1.4.0
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.Audio.AudioStreamContainerFormat.OGG_OPUS">
            <summary>
            Stream ContainerFormat definition for OGG OPUS.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.Audio.AudioStreamContainerFormat.MP3">
            <summary>
            Stream ContainerFormat definition for MP3.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.Audio.AudioStreamContainerFormat.FLAC">
            <summary>
            Stream ContainerFormat definition for FLAC. Added in version 1.7.0. 
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.Audio.AudioStreamContainerFormat.ALAW">
            <summary>
            Stream ContainerFormat definition for ALAW. Added in version 1.7.0. 
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.Audio.AudioStreamContainerFormat.MULAW">
            <summary>
            Stream ContainerFormat definition for MULAW. Added in version 1.7.0. 
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.Audio.AudioStreamContainerFormat.AMRNB">
            <summary>
            Stream ContainerFormat definition for AMRNB. Currently not supported. 
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.Audio.AudioStreamContainerFormat.AMRWB">
            <summary>
            Stream ContainerFormat definition for AMRWB. Currently not supported. 
            </summary>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.Audio.AudioStreamFormat">
            <summary>
            Represents audio stream format used for custom audio input configurations.
            Updated in version 1.5.0.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Audio.AudioStreamFormat.GetDefaultInputFormat">
            <summary>
            Creates an audio stream format object representing the default microphone input format (16 kHz, 16 bit, mono PCM).
            </summary>
            <returns>The audio stream format being created.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Audio.AudioStreamFormat.GetDefaultOutputFormat">
            <summary>
            Creates an audio stream format object representing the default speaker output format (16 kHz, 16 bit, mono PCM).
            Added in version 1.4.0
            </summary>
            <returns>The audio stream format being created.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Audio.AudioStreamFormat.GetWaveFormatPCM(System.UInt32,System.Byte,System.Byte)">
            <summary>
            Creates an audio stream format object with the specified PCM waveformat characteristics.
            </summary>
            <param name="samplesPerSecond">Sample rate, in samples per second (Hertz).</param>
            <param name="bitsPerSample">Bits per sample.</param>
            <param name="channels">Number of channels in the waveform-audio data.</param>
            <returns>The audio stream format being created.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Audio.AudioStreamFormat.GetCompressedFormat(Microsoft.CognitiveServices.Speech.Audio.AudioStreamContainerFormat)">
            <summary>
            Creates an audio stream format object with the specified compressed audio container format, to be used as input format.
            Support added in 1.4.0.
            </summary>
            <param name="compressedFormat">Formats are defined in AudioStreamContainerFormat enum</param>
            <returns>The audio stream format being created.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Audio.AudioStreamFormat.Dispose">
            <summary>
            Dispose of associated resources.
            </summary>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.AudioDataStream">
            <summary>
            Represents audio data stream used for operating audio data as a stream.
            Added in version 1.4.0
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.AudioDataStream.FromWavFileInput(System.String)">
            <summary>
            Creates a memory backed AudioDataStream for the specified audio file.
            Added in version 1.14.0
            </summary>
            <param name="fileName">Specifies the audio input file.</param>
            <returns>The audio data stream being created.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.AudioDataStream.FromResult(Microsoft.CognitiveServices.Speech.SpeechSynthesisResult)">
            <summary>
            Creates a memory backed AudioDataStream from given speech synthesis result.
            </summary>
            <param name="result">The speech synthesis result.</param>
            <returns>The audio data stream being created.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.AudioDataStream.FromResult(Microsoft.CognitiveServices.Speech.KeywordRecognitionResult)">
            <summary>
            Obtains the memory backed AudioDataStream associated with a given KeywordRecognition result.
            </summary>
            <param name="result">The keyword recognition result.</param>
            <returns>An audio stream with the input to the KeywordRecognizer starting from right before the Keyword.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.AudioDataStream.GetStatus">
            <summary>
            Get current status of the audio data stream.
            </summary>
            <returns>Current status.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.AudioDataStream.CanReadData(System.UInt32)">
            <summary>
            Check whether the stream has enough data to be read.
            </summary>
            <param name="bytesRequested">The requested data size in bytes.</param>
            <returns>A bool indicating whether the stream has enough data to be read.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.AudioDataStream.CanReadData(System.UInt32,System.UInt32)">
            <summary>
            Check whether the stream has enough data to be read, starting from the specified position.
            </summary>
            <param name="pos">The position counting from start of the stream.</param>
            <param name="bytesRequested">The requested data size in bytes.</param>
            <returns>A bool indicating whether the stream has enough data to be read.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.AudioDataStream.ReadData(System.Byte[])">
            <summary>
            Reads the audio data from the audio data stream.
            The maximal number of bytes to be read is determined by the size of buffer.
            If there is no data immediately available, ReadData() blocks until the next data becomes available.
            </summary>
            <param name="buffer">The buffer to receive the audio data.</param>
            <returns>The number of bytes filled, or 0 in case the stream hits its end and there is no more data available.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.AudioDataStream.ReadData(System.UInt32,System.Byte[])">
            <summary>
            Reads the audio data from the audio data stream, starting from the specified position.
            The maximal number of bytes to be read is determined by the size of buffer.
            If there is no data immediately available, ReadData() blocks until the next data becomes available.
            </summary>
            <param name="pos">The position counting from start of the stream.</param>
            <param name="buffer">The buffer to receive the audio data.</param>
            <returns>The number of bytes filled, or 0 in case the stream hits its end and there is no more data available.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.AudioDataStream.SaveToWaveFileAsync(System.String)">
            <summary>
            Save the audio data to a file, asynchronously.
            </summary>
            <param name="fileName">Name of the file for saving.</param>
            <returns>An asynchronous operation representing the saving.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.AudioDataStream.SetPosition(System.UInt32)">
            <summary>
            Set current position of the audio data stream.
            </summary>
            <param name="pos">Position to be set.</param>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.AudioDataStream.GetPosition">
            <summary>
            Get current position of the audio data stream.
            </summary>
            <returns>Current position.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.AudioDataStream.DetachInput">
            <summary>
            Stops any more data from getting to the stream.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.AudioDataStream.Dispose">
            <summary>
            Dispose of associated resources.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.AudioDataStream.Dispose(System.Boolean)">
            <summary>
            This method performs cleanup of resources.
            The Boolean parameter <paramref name="disposing"/> indicates whether the method is called from <see cref="M:System.IDisposable.Dispose"/> (if <paramref name="disposing"/> is true) or from the finalizer (if <paramref name="disposing"/> is false).
            Derived classes should override this method to dispose resource if needed.
            </summary>
            <param name="disposing">Flag to request disposal.</param>
            <returns></returns>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.AudioDataStream.Properties">
            <summary>
            Contains properties of the audio data stream.
            </summary>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.AutoDetectSourceLanguageConfig">
            <summary>
            Auto Detect Source Language configuration.
            Updated in 1.13.0
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.AutoDetectSourceLanguageConfig.FromOpenRange">
            <summary>
            Creates an instance of the AutoDetectSourceLanguageConfig with open range
            Note: only <see cref="T:Microsoft.CognitiveServices.Speech.SpeechSynthesizer"/> supports source language auto detection from open range,
            for <see cref="T:Microsoft.CognitiveServices.Speech.Recognizer"/>, please use AutoDetectSourceLanguageConfig with specific source languages.
            Added in 1.13.0
            </summary>
            <returns>A new AutoDetectSourceLanguageConfig instance.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.AutoDetectSourceLanguageConfig.FromLanguages(System.String[])">
            <summary>
            Creates an instance of the AutoDetectSourceLanguageConfig with source languages
            </summary>
            <param name="languages">The list of source languages.</param>
            <returns>A new AutoDetectSourceLanguageConfig instance.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.AutoDetectSourceLanguageConfig.FromSourceLanguageConfigs(Microsoft.CognitiveServices.Speech.SourceLanguageConfig[])">
            <summary>
            Creates an instance of the AutoDetectSourceLanguageConfig with a list of source language config
            </summary>
            <param name="sourceLanguageConfigs">The list of source languages config</param>
            <returns>A new AutoDetectSourceLanguageConfig instance.</returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.AutoDetectSourceLanguageResult">
            <summary>
            Contains auto detected source language result
            Added in 1.9.0
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.AutoDetectSourceLanguageResult.Language">
            <summary>
            Presents the detected language
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.AutoDetectSourceLanguageResult.FromResult(Microsoft.CognitiveServices.Speech.SpeechRecognitionResult)">
            <summary>
            Creates an instance of AutoDetectSourceLanguageResult object for the speech recognition result.
            </summary>
            <param name="result">The speech recongition result.</param>
            <returns>A new AutoDetectSourceLanguageResult instance</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.AutoDetectSourceLanguageResult.#ctor(Microsoft.CognitiveServices.Speech.RecognitionResult)">
            <summary>
            Creates an instance of AutoDetectSourceLanguageResult object for any recognition result.
            </summary>
            <param name="result">The recongition result.</param>
            <returns>A new AutoDetectSourceLanguageResult instance</returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.Connection">
            <summary>
            Connection is a proxy class for managing connection to the speech service of the specified Recognizer.
            By default, a Recognizer autonomously manages connection to service when needed.
            The Connection class provides additional methods for users to explicitly open or close a connection and
            to subscribe to connection status changes.
            The use of Connection is optional. It is intended for scenarios where fine tuning of application
            behavior based on connection status is needed. Users can optionally call Open() to manually
            initiate a service connection before starting recognition on the Recognizer associated with this Connection.
            After starting a recognition, calling Open() or Close() might fail. This will not impact
            the Recognizer or the ongoing recognition. Connection might drop for various reasons, the Recognizer will
            always try to reinstitute the connection as required to guarantee ongoing operations. In all these cases
            Connected/Disconnected events will indicate the change of the connection status.
            Added in version 1.2.0.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Connection.FromRecognizer(Microsoft.CognitiveServices.Speech.Recognizer)">
            <summary>
            Gets the Connection instance from the specified recognizer.
            </summary>
            <param name="recognizer">The recognizer associated with the connection.</param>
            <returns>The Connection instance of the recognizer.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Connection.FromConversationTranslator(Microsoft.CognitiveServices.Speech.Transcription.ConversationTranslator)">
            <summary>
            Gets the Connection instance from the conversation translator.
            </summary>
            <param name="convTrans">The conversation translator associated with the connection.</param>
            <returns>The Connection instance of the conversation translator.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Connection.FromDialogServiceConnector(Microsoft.CognitiveServices.Speech.Dialog.DialogServiceConnector)">
            <summary>
            Gets the Connection instance from the specified dialog service connector, used for observing and managing
            connection and disconnection from the speech service.
            </summary>
            <param name="dialogServiceConnector">The dialog service connector associated with the connection.</param>
            <returns>The Connection instance of the dialog service connector.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Connection.Dispose">
            <summary>
            Dispose of associated resources.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Connection.Dispose(System.Boolean)">
            <summary>
            This method performs cleanup of resources.
            The Boolean parameter <paramref name="disposing"/> indicates whether the method is called from <see cref="M:System.IDisposable.Dispose"/> (if <paramref name="disposing"/> is true) or from the finalizer (if <paramref name="disposing"/> is false).
            Derived classes should override this method to dispose resource if needed.
            </summary>
            <param name="disposing">Flag to request disposal.</param>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Connection.Open(System.Boolean)">
            <summary>
            Starts to set up connection to the service.
            Users can optionally call Open() to manually set up a connection in advance before starting recognition on the
            Recognizer associated with this Connection. After starting recognition, calling Open() might fail, depending on
            the process state of the Recognizer. But the failure does not affect the state of the associated Recognizer.
            Note: On return, the connection might not be ready yet. Please subscribe to the Connected event to
            be notified when the connection is established.
            </summary>
            <param name="forContinuousRecognition">Indicates whether the connection is used for continuous recognition or single-shot recognition.</param>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Connection.Close">
            <summary>
            Closes the connection the service.
            Users can optionally call Close() to manually shutdown the connection of the associated Recognizer. The call
            might fail, depending on the process state of the Recognizer. But the failure does not affect the state of the
            associated Recognizer.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Connection.SendMessageAsync(System.String,System.String)">
            <summary>
            Sends a message to the speech service.
            Added in version 1.7.0.
            </summary>
            <param name="path">The path of the message.</param>
            <param name="payload">The payload of the message. This is a json string.</param>
            <returns>A task representing the asynchronous operation that sends the message.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Connection.SendMessageAsync(System.String,System.Byte[],System.UInt32)">
            <summary>
            Sends a binary message to the speech service.
            Added in version 1.10.0.
            </summary>
            <param name="path">The path of the message.</param>
            <param name="payload">The binary payload of the message.</param>
            <param name="size">The size of the binary payload.</param>
            <returns>A task representing the asynchronous operation that sends the message.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Connection.SetMessageProperty(System.String,System.String,System.String)">
            <summary>
            Appends a parameter in a message to service.
            Added in version 1.7.0.
            </summary>
            <param name="path">The path of the network message.</param>
            <param name="propertyName">Name of the property.</param>
            <param name="propertyValue">Value of the property. This is a json string.</param>
        </member>
        <member name="E:Microsoft.CognitiveServices.Speech.Connection.Connected">
            <summary>
            The Connected event to indicate that the recognizer is connected to service.
            In order to receive the Connected event after subscribing to it, the Connection object itself needs to be alive.
            If the Connection object owning this event is out of its life time, all subscribed events won't be delivered.
            </summary>
        </member>
        <member name="E:Microsoft.CognitiveServices.Speech.Connection.Disconnected">
            <summary>
            The Disconnected event to indicate that the recognizer is disconnected from service.
            In order to receive the Disconnected event after subscribing to it, the Connection object itself needs to be alive.
            If the Connection object owning this event is out of its life time, all subscribed events won't be delivered.
            </summary>
        </member>
        <member name="E:Microsoft.CognitiveServices.Speech.Connection.MessageReceived">
            <summary>
            The MessageReceived event indicates that the service has sent a network message to the client.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Connection.FireEvent_Connected(System.IntPtr,System.IntPtr)">
             <summary>
             Defines a private methods which raise a C# event when a corresponding callback is invoked from the native layer.
             </summary>
            
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.ConnectionEventArgs">
            <summary>
            Defines payload for Connected/Disconnected events
            Added in version 1.2.0.
            </summary>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.ConnectionEventType">
            <summary>
            Define connection event types.
            </summary>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.ConnectionMessage">
            <summary>
            ConnectionMessage represents implementation specific messages sent to and received from
            the speech service. These messages are provided for debugging purposes and should not
            be used for production use cases with the Azure Cognitive Services Speech Service.
            Messages sent to and received from the Speech Service are subject to change without
            notice. This includes message contents, headers, payloads, ordering, etc.
            Added in version 1.10.0.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.ConnectionMessage.Path">
            <summary>
            The message path.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.ConnectionMessage.IsTextMessage">
            <summary>
            Checks to see if the ConnectionMessage is a text message.
            See also IsBinaryMessage().
            </summary>
            <returns>A bool indicated if the message payload is text.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.ConnectionMessage.IsBinaryMessage">
            <summary>
            Checks to see if the ConnectionMessage is a binary message.
            See also GetBinaryMessage().
            </summary>
            <returns>A bool indicated if the message payload is binary.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.ConnectionMessage.GetTextMessage">
            <summary>
            Gets the text message payload. Typically the text message content-type is
            application/json. To determine other content-types use
            Properties.GetProperty("Content-Type").
            </summary>
            <returns>A string containing the text message.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.ConnectionMessage.GetBinaryMessage">
            <summary>
            Gets the binary message payload.
            </summary>
            <returns>An array of bytes containing the binary message.</returns>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.ConnectionMessage.Properties">
            <summary>
            A collection of properties and their values defined for this <see cref="T:Microsoft.CognitiveServices.Speech.ConnectionMessage"/>.
            Message headers can be accessed via this collection (e.g. "Content-Type").
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.ConnectionMessage.ToString">
            <summary>
            Returns a string that represents the connection message.
            </summary>
            <returns>A string that represents the connection message.</returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.ConnectionMessageEventArgs">
            <summary>
            Defines payload for Connection's MessageReceived events
            Added in version 1.10.0.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.ConnectionMessageEventArgs.Message">
            <summary>
            Gets the <see cref="T:Microsoft.CognitiveServices.Speech.ConnectionMessage"/> associated with this <see cref="T:Microsoft.CognitiveServices.Speech.ConnectionMessageEventArgs"/>.
            </summary>
            <returns>A ConnectionMessage containing the message.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.ConnectionMessageEventArgs.ToString">
            <summary>
            Returns a string that represents the connection message event.
            </summary>
            <returns>A string that represents the connection message event.</returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.Transcription.Conversation">
            <summary>
            Perform conversation transcribing on the speech input. It returns recognized text and speaker id.
            Added in version 1.8.0
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Transcription.Conversation.CreateConversationAsync(Microsoft.CognitiveServices.Speech.SpeechConfig,System.String)">
            <summary>
            Creates a new conversation.
            </summary>
            <param name="speechConfig">The speech configuration to use.</param>
            <param name="conversationId">(Optional) The identifier for the conversation you want to join.</param>
            <returns></returns>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Transcription.Conversation.ConversationId">
            <summary>
            Gets/sets the conversation id.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Transcription.Conversation.AuthorizationToken">
            <summary>
            Gets/sets authorization token used to communicate with the service.
            Note: The caller needs to ensure that the authorization token is valid. Before the authorization token
            expires, the caller needs to refresh it by calling this setter with a new valid token.
            Otherwise, the recognizer will encounter errors during recognition.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Transcription.Conversation.SpeechRecognitionLanguage">
            <summary>
            Gets the language name that is used for recognition.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Transcription.Conversation.OutputFormat">
            <summary>
            Gets the output format setting.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Transcription.Conversation.Properties">
            <summary>
            Gets the collection of properties and their values defined for this <see cref="T:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranscriber"/>.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Transcription.Conversation.NativeHandle">
            <summary>
            Gets the native handle for the conversation.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Transcription.Conversation.AddParticipantAsync(System.String)">
             <summary>
             Add a participant to a conversation using the user's id.
            
             Note: The returned participants can be used to remove. If the client changes the participant's attributes,
             the changed attributes are passed on to the service only when the participants is added again.
            
             </summary>
             <param name="userId">A user id.</param>
             <returns>An asynchronous operation representing adding a participant.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Transcription.Conversation.AddParticipantAsync(Microsoft.CognitiveServices.Speech.Transcription.User)">
            <summary>
            Add a participant to a conversation using the User object.
            </summary>
            <param name="user">A User object.</param>
            <returns>An asynchronous operation representing adding a participant.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Transcription.Conversation.AddParticipantAsync(Microsoft.CognitiveServices.Speech.Transcription.Participant)">
            <summary>
            Add a participant to a conversation using the Participant object
            </summary>
            <param name="participant">A participant object.</param>
            <returns>An asynchronous operation representing adding a participant.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Transcription.Conversation.RemoveParticipantAsync(Microsoft.CognitiveServices.Speech.Transcription.Participant)">
            <summary>
            Remove a participant in a conversation using the Participant object
            </summary>
            <param name="participant">A Participant object.</param>
            <returns>An asynchronous operation representing adding a participant.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Transcription.Conversation.RemoveParticipantAsync(Microsoft.CognitiveServices.Speech.Transcription.User)">
            <summary>
            Remove a participant in a conversation using the User object
            </summary>
            <param name="user">A User object.</param>
            <returns>An asynchronous operation representing removing a participant.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Transcription.Conversation.RemoveParticipantAsync(System.String)">
            <summary>
            Remove a participant from a conversation using a user id object
            </summary>
            <param name="userId">A user id.</param>
            <returns>An asynchronous operation representing removing a participant.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Transcription.Conversation.EndConversationAsync">
            <summary>
            End a conversation.
            </summary>
            <returns>An asynchronous operation representing ending a conversation.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Transcription.Conversation.StartConversationAsync">
            <summary>
            Start a conversation.
            </summary>
            <returns>An asynchronous operation representing starting a conversation.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Transcription.Conversation.DeleteConversationAsync">
            <summary>
            Delete a conversation. After this no one will be able to join the conversation.
            </summary>
            <returns>An asynchronous operation representing deleting a conversation.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Transcription.Conversation.LockConversationAsync">
            <summary>
            Lock a conversation. This will prevent new participants from joining.
            </summary>
            <returns>An asynchronous operation representing locking a conversation.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Transcription.Conversation.UnlockConversationAsync">
            <summary>
            Unlocks a conversation.
            </summary>
            <returns>An asynchronous operation representing unlocking a conversation.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Transcription.Conversation.MuteAllParticipantsAsync">
            <summary>
            Mute all other participants in the conversation. After this no other participants will
            have their speech recognitions broadcast, nor be able to send text messages.
            </summary>
            <returns>An asynchronous operation representing muting all participants.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Transcription.Conversation.UnmuteAllParticipantsAsync">
            <summary>
            Unmute all other participants in the conversation.
            </summary>
            <returns>An asynchronous operation representing un-muting all participants.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Transcription.Conversation.MuteParticipantAsync(System.String)">
            <summary>
            Mute a participant.
            </summary>
            <param name="userId">A user identifier.</param>
            <returns>An asynchronous operation representing muting a particular participant.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Transcription.Conversation.UnmuteParticipantAsync(System.String)">
            <summary>
            Unmute a participant.
            </summary>
            <param name="userId">A user identifier.</param>
            <returns>An asynchronous operation representing un-muting a particular participant.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Transcription.Conversation.Dispose(System.Boolean)">
            <summary>
            
            </summary>
            <param name="disposeManaged"></param>
            <returns></returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.Transcription.ConversationExpirationEventArgs">
            <summary>
            Defines a payload for the <see cref="E:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranslator.ConversationExpiration"/> event.
            Added in 1.9.0.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Transcription.ConversationExpirationEventArgs.#ctor(System.IntPtr)">
            <summary>
            Creates a new instance.
            </summary>
            <param name="eventHandle">The event handle</param>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Transcription.ConversationExpirationEventArgs.ExpirationTime">
            <summary>
            How much longer until the conversation expires.
            </summary>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.Transcription.ParticipantChangedReason">
            <summary>
            Why the participant changed event was raised
            Added in version 1.9.0
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.Transcription.ParticipantChangedReason.JoinedConversation">
            <summary>
            Participant has joined the conversation.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.Transcription.ParticipantChangedReason.LeftConversation">
            <summary>
            Participant has left the conversation. This could be voluntary, or involuntary
            (e.g. they are experiencing networking issues).
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.Transcription.ParticipantChangedReason.Updated">
            <summary>
            The participants' state has changed (e.g. they became muted, changed their nickname).
            </summary>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.Transcription.ConversationParticipantsChangedEventArgs">
            <summary>
            Defines a payload for the <see cref="E:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranslator.ParticipantsChanged" /> event.
            Added in version 1.9.0
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Transcription.ConversationParticipantsChangedEventArgs.#ctor(System.IntPtr)">
            <summary>
            Creates a new instance.
            </summary>
            <param name="handle">The event handle.</param>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Transcription.ConversationParticipantsChangedEventArgs.Reason">
            <summary>
            Why the participant changed event was raised (e.g. a participant joined).
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.Transcription.ConversationParticipantsChangedEventArgs.Participants">
            <summary>
            The participant(s) that joined, left, or were updated.
            </summary>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranscriber">
            <summary>
            Perform conversation transcribing on the speech input. It returns recognized text and speaker id.
            Added in version 1.5.0
            </summary>
        </member>
        <member name="E:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranscriber.Transcribing">
            <summary>
            The event <see cref="E:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranscriber.Transcribing"/> signals that an intermediate transcription result is received.
            </summary>
        </member>
        <member name="E:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranscriber.Transcribed">
            <summary>
            The event <see cref="E:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranscriber.Transcribed"/> signals that a final transcription result is received.
            </summary>
        </member>
        <member name="E:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranscriber.Canceled">
            <summary>
            The event <see cref="E:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranscriber.Canceled"/> signals that the speech recognition was canceled.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranscriber.#ctor">
            <summary>
            Creates a new instance of Conversation Transcriber.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranscriber.#ctor(Microsoft.CognitiveServices.Speech.Audio.AudioConfig)">
            <summary>
            Creates a new instance of ConversationTranscriber.
            </summary>
            <param name="audioConfig">Audio configuration</param>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranscriber.JoinConversationAsync(Microsoft.CognitiveServices.Speech.Transcription.Conversation)">
            <summary>
            Join a conversation.
            </summary>
            <param name="conversation">The conversation to be joined.</param>
            <returns>An asynchronous operation representing joining a conversation.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranscriber.LeaveConversationAsync">
            <summary>
            Leave a conversation.
            </summary>
            <returns>An asynchronous operation representing leaving a conversation.</returns>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranscriber.AuthorizationToken">
            <summary>
            Gets/sets authorization token used to communicate with the service.
            Note: The caller needs to ensure that the authorization token is valid. Before the authorization token
            expires, the caller needs to refresh it by calling this setter with a new valid token.
            Otherwise, the recognizer will encounter errors during recognition.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranscriber.SpeechRecognitionLanguage">
            <summary>
            Gets the language name that is used for recognition.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranscriber.OutputFormat">
            <summary>
            Gets the output format setting.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranscriber.Properties">
            <summary>
            Gets the collection of properties and their values defined for this <see cref="T:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranscriber"/>.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranscriber.StartTranscribingAsync">
            <summary>
            Starts conversation trancsribing on a continuous audio stream, until StopTranscribingAsync() is called.
            User must subscribe to events to receive recognition results.
            </summary>
            <returns>A task representing the asynchronous operation that starts the recognition.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranscriber.StopTranscribingAsync">
            <summary>
            Stops conversation transcribing.
            </summary>
            <returns>A task representing the asynchronous operation that stops the recognition.</returns>
            <remarks>This is used to pause the conversation. The client can start the conversation again by calling StartTranscribingAsync.</remarks>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranscriber.Dispose(System.Boolean)">
            <summary>
            Disposes of the object
            </summary>
            <param name="disposing">True to dispose managed resources</param>
            <returns></returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranscriptionResult">
            <summary>
            Class that defines the result of conversation transcriber.
            Added in version 1.5.0
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranscriptionResult.#ctor(System.IntPtr)">
            <summary>
            Constructor to create ConversationTranscriptionResult
            </summary>
            <param name="resultPtr">The result handle.</param>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranscriptionResult.UserId">
            <summary>
            A string that represents the user id.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranscriptionResult.UtteranceId">
            <summary>
            A string that represents the utterance. This id is consistence for intermediates and final speech recognition result from one speaker.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranscriptionResult.ToString">
            <summary>
            Returns a string that represents the conversation transcription result.
            </summary>
            <returns>A string that represents the conversation transcription result.</returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranscriptionEventArgs">
            <summary>
            Class that defines conversation transcriber event arguments.
            Added in version 1.5.0
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranscriptionEventArgs.Result">
            <summary>
            Represents the conversation transcription result.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranscriptionEventArgs.ToString">
            <summary>
            Returns a string that represents the session id and the conversation transcription result event.
            </summary>
            <returns>A string that represents the conversation transcription event.</returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranscriptionCanceledEventArgs">
            <summary>
            Defines payload of conversation transcriber canceled result events.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranscriptionCanceledEventArgs.Reason">
            <summary>
            The reason the result was canceled.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranscriptionCanceledEventArgs.ErrorCode">
            <summary>
            The error code in case of an unsuccessful recognition (<see cref="P:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranscriptionCanceledEventArgs.Reason"/> is set to Error).
            If Reason is not Error, ErrorCode returns NoError.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranscriptionCanceledEventArgs.ErrorDetails">
            <summary>
            The error message in case of an unsuccessful recognition (<see cref="P:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranscriptionCanceledEventArgs.Reason"/> is set to Error).
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranscriptionCanceledEventArgs.ToString">
            <summary>
            Returns a string that represents the session id and the conversation transcription result event.
            </summary>
            <returns>A string that represents the conversation transcriber event.</returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranslationEventArgs">
            <summary>
            Defines a payload for <see cref="E:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranslator.Transcribing"/>, and
            <see cref="E:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranslator.Transcribed"/> events.
            Added in 1.9.0.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranslationEventArgs.#ctor(System.IntPtr)">
            <summary>
            Creates a new instance.
            </summary>
            <param name="handle">The event handle.</param>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranslationEventArgs.Result">
            <summary>
            Gets the conversation translation result.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranslationEventArgs.ToString">
            <summary>
            Returns a string that represents the conversation translation event.
            </summary>
            <returns>The string representation.</returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranslationCanceledEventArgs">
            <summary>
            Defines a payload for the <see cref="E:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranslator.Canceled"/> event.
            Added in 1.9.0.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranslationCanceledEventArgs.#ctor(System.IntPtr)">
            <summary>
            Creates a new instance.
            </summary>
            <param name="handle">The event handle.</param>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranslationCanceledEventArgs.Reason">
            <summary>
            The reason the recognition was canceled.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranslationCanceledEventArgs.ErrorCode">
            <summary>
            The error code in case of an unsuccessful recognition (<see cref="P:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranslationCanceledEventArgs.Reason"/> is set to Error).
            If Reason is not Error, ErrorCode returns NoError.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranslationCanceledEventArgs.ErrorDetails">
            <summary>
            The error message in case of an unsuccessful recognition (<see cref="P:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranslationCanceledEventArgs.Reason"/> is set to Error).
            </summary>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranslationResult">
            <summary>
            Defines a conversation translation result.
            Added in 1.9.0.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranslationResult.#ctor(System.IntPtr)">
            <summary>
            Creates a new instance.
            </summary>
            <param name="resultPtr">The result handle.</param>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranslationResult.ParticipantId">
            <summary>
            The unique identifier for the participant this result is for.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranslationResult.OriginalLang">
            <summary>
            The original language this result was in.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranslationResult.ToString">
            <summary>
            Returns a string that represents the conversation translation result.
            </summary>
            <returns>A string representation.</returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranslator">
            <summary>
            A conversation translator that enables a connected experience where participants can use their
            own devices to see everyone else's recognitions and IMs in their own languages. Participants
            can also speak and send IMs to others.
            Added in 1.9.0
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranslator.#ctor">
            <summary>
            Creates a new instance of the Conversation Translator using the default microphone input.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranslator.#ctor(Microsoft.CognitiveServices.Speech.Audio.AudioConfig)">
            <summary>
            Creates a new instance of the Conversation Translator.
            </summary>
            <param name="audioConfig">Audio configuration.</param>
            <exception cref="T:System.ArgumentNullException">If the audioConfig is null.</exception>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranslator.#ctor(Microsoft.CognitiveServices.Speech.Internal.InteropSafeHandle)">
            <summary>
            Creates a new instance.
            </summary>
            <param name="nativeHandle">The handle to the native conversation translator.</param>
        </member>
        <member name="E:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranslator.SessionStarted">
            <summary>
            Event that signals the start of a conversation translation session.
            </summary>
        </member>
        <member name="E:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranslator.SessionStopped">
            <summary>
            Event that signals the end of a conversation translation session.
            </summary>
        </member>
        <member name="E:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranslator.Canceled">
            <summary>
            Event that signals an error with the conversation transcription, or the end of the
            audio stream has been reached.
            </summary>
        </member>
        <member name="E:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranslator.ParticipantsChanged">
            <summary>
            Event that signals participants in the room have changed (e.g. a new participant joined).
            </summary>
        </member>
        <member name="E:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranslator.ConversationExpiration">
            <summary>
            Event that signals how many more minutes are left before the conversation expires.
            </summary>
        </member>
        <member name="E:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranslator.Transcribing">
            <summary>
            Event that signals an intermediate conversation translation result is available for a
            conversation participant.
            </summary>
        </member>
        <member name="E:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranslator.Transcribed">
            <summary>
            Event that signals a final conversation translation result is available for a conversation
            participant.
            </summary>
        </member>
        <member name="E:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranslator.TextMessageReceived">
            <summary>
            Event that signals a translated text message from a conversation participant.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranslator.SpeechRecognitionLanguage">
            <summary>
            Gets the language name that is used for recognition.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranslator.ParticipantId">
            <summary>
            Gets your participant identifier
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranslator.AuthorizationToken">
            <summary>
            Gets or sets the authorization token used to connect to the conversation service
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranslator.Properties">
            <summary>
            Gets the collection of properties and their values defined for this <see cref="T:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranslator"/>.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranslator.JoinConversationAsync(Microsoft.CognitiveServices.Speech.Transcription.Conversation,System.String)">
            <summary>
            Joins an existing conversation. You should use this method if you have created a conversation
            using <see cref="M:Microsoft.CognitiveServices.Speech.Transcription.Conversation.CreateConversationAsync(Microsoft.CognitiveServices.Speech.SpeechConfig,System.String)"/>.
            </summary>
            <param name="conversation">The conversation to join.</param>
            <param name="nickname">The display name to use for the current participant.</param>
            <returns>An asynchronous operation.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranslator.JoinConversationAsync(System.String,System.String,System.String)">
            <summary>
            Joins an existing conversation.
            </summary>
            <param name="conversationId">The unique identifier for the conversation to join.</param>
            <param name="nickname">The display name to use for the current participant.</param>
            <param name="lang">The speech language to use for the current participant.</param>
            <returns>An asynchronous operation.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranslator.StartTranscribingAsync">
            <summary>
            Starts sending audio to the conversation service for speech recognition and translation. You
            should subscribe to the <see cref="E:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranslator.Transcribing"/>, and <see cref="E:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranslator.Transcribed"/> events to
            receive conversation translation results for yourself, and other participants in the
            conversation.
            </summary>
            <returns>An asynchronous operation.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranslator.StopTranscribingAsync">
            <summary>
            Stops sending audio to the conversation service. You will still receive <see cref="E:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranslator.Transcribing"/>,
            and <see cref="E:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranslator.Transcribed"/> events for other participants in the conversation.
            </summary>
            <returns>An asynchronous operation.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranslator.SendTextMessageAsync(System.String)">
            <summary>
            Sends an instant message to all participants in the conversation. This instant message
            will be translated into each participant's text language.
            </summary>
            <param name="message">The message to send.</param>
            <returns>An asynchronous operation.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranslator.SetAuthorizationToken(System.String,System.String)">
            <summary>
            Sets the Cognitive Speech authorization token that will be used for connecting to the server.
            </summary>
            <param name="authToken">The authorization token.</param>
            <param name="region">(Optional) The Azure region for this token.</param>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranslator.LeaveConversationAsync">
            <summary>
            Leave the current conversation. After this is called, you will no longer receive any events.
            </summary>
            <returns>An asynchronous operation.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Transcription.ConversationTranslator.Dispose(System.Boolean)">
            <summary>
            Disposes of the object
            </summary>
            <param name="disposeManaged">True to dispose managed resources</param>
            <returns></returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.Transcription.Participant">
            <summary>
            Represents a participant in a conversation.
            Changed in version 1.9.0
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Transcription.Participant.From(System.String,System.String,System.String)">
            <summary>
            Creates a Participant using user id, her/his preferred language and her/his voice signature.
            If voice signature is empty then user will not be identified.
            </summary>
            <param name="userId">A user id.</param>
            <param name="preferredLanguage">A preferred language.</param>
            <param name="voiceSignature">A voice signature of the user.</param>
            <returns>A Participant object</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Transcription.Participant.#ctor(System.IntPtr)">
            <summary>
            Internal constructor
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Transcription.Participant.Id">
            <summary>
            The unique identifier for the participant.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Transcription.Participant.Avatar">
            <summary>
            Gets the colour of the user's avatar as an HTML hex string (e.g. FF0000 for red).
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Transcription.Participant.DisplayName">
            <summary>
            The participant's display name. Please note that each participant within the same conversation must
            have a different display name. Duplicate names within the same conversation are not allowed. You can
            use the <see cref="P:Microsoft.CognitiveServices.Speech.Transcription.Participant.Id"/> property as another way to refer to each participant.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Transcription.Participant.IsMuted">
            <summary>
            Gets whether or not this participant is muted.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Transcription.Participant.IsUsingTts">
            <summary>
            Gets whether or not the participant is using Text To Speech (TTS).
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Transcription.Participant.IsHost">
            <summary>
            Gets whether or not this participant is the host.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Transcription.Participant.PreferredLanguage">
            <summary>
            The participant's preferred spoken language.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Transcription.Participant.VoiceSignature">
            <summary>
            The participant's voice signature.
            If voice signature is empty then user will not be identified.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Transcription.Participant.Properties">
            <summary>
            Contains properties of the participant.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Transcription.Participant.ParticipantHandle">
            <summary>
            Gets the native handle.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Transcription.Participant.Dispose(System.Boolean)">
            <summary>
            Disposes of the object.
            </summary>
            <param name="disposeManaged">True to dispose managed resources.</param>
            <returns></returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.Transcription.User">
            <summary>
            Represents a user in a conversation.
            Added in version 1.5.0
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Transcription.User.FromUserId(System.String)">
            <summary>
            Create a user using user id
            </summary>
            <param name="userId">A user id.</param>
            <returns>A user object</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Transcription.User.#ctor(System.IntPtr)">
            <summary>
            Internal constructor
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Transcription.User.UserId">
            <summary>
            Get user id.
            </summary>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.DetailedSpeechRecognitionResultCollection">
            <summary>
            Collection of best recognitions.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.DetailedSpeechRecognitionResultCollection.NBest">
            <summary>
            Enumerable of alternative interpretations of the same speech recognition result.
            </summary>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.DetailedSpeechRecognitionResult">
            <summary>
            Detailed recognition result.
            Changed in version 1.7.0.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.DetailedSpeechRecognitionResult.Confidence">
            <summary>
            Confidence of recognition.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.DetailedSpeechRecognitionResult.Text">
            <summary>
            Recognized text.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.DetailedSpeechRecognitionResult.LexicalForm">
            <summary>
            Raw lexical form.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.DetailedSpeechRecognitionResult.NormalizedForm">
            <summary>
            Normalized form.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.DetailedSpeechRecognitionResult.MaskedNormalizedForm">
            <summary>
            Normalized form with masked profanity.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.DetailedSpeechRecognitionResult.PronunciationAssessment">
            <summary>
            Sentence level pronunciation assessment result, available when pronunciation assessment is enabled.
            Added in version 1.14.0
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.DetailedSpeechRecognitionResult.Words">
            <summary>
            Word level timing result list
            Added in version 1.7.0.
            </summary>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.WordLevelTimingResult">
            <summary>
            Word level timing result.
            Added in version 1.7.0.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.WordLevelTimingResult.Duration">
            <summary>
            Duration in ticks.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.WordLevelTimingResult.Offset">
            <summary>
            Offset in ticks.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.WordLevelTimingResult.Word">
            <summary>
            Recognized word.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.WordLevelTimingResult.PronunciationAssessment">
            <summary>
            Word level pronunciation assessment result, available when pronuncation assessment is enabled.
            Added in version 1.14.0
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.WordLevelTimingResult.Phonemes">
            <summary>
            Phoneme level timing result list.
            Added in version 1.14.0.
            </summary>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.PhonemeLevelTimingResult">
            <summary>
            Phoneme level timing result.
            Added in version 1.14.0.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.PhonemeLevelTimingResult.Duration">
            <summary>
            Duration in ticks.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.PhonemeLevelTimingResult.Offset">
            <summary>
            Offset in ticks.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.PhonemeLevelTimingResult.Phoneme">
            <summary>
            Recognized Phoneme.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.PhonemeLevelTimingResult.PronunciationAssessment">
            <summary>
            Phoneme level pronunciation assessment result, available when pronuncation assessment is enabled.
            </summary>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.SentenceLevelPronunciationAssessmentResult">
            <summary>
            Sentence level pronunciation assessment results
            Added in version 1.14.0.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.SentenceLevelPronunciationAssessmentResult.AccuracyScore">
            <summary>
            Accuracy score.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.SentenceLevelPronunciationAssessmentResult.PronunciationScore">
            <summary>
            Pronunciation score.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.SentenceLevelPronunciationAssessmentResult.CompletenessScore">
            <summary>
            Completeness score.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.SentenceLevelPronunciationAssessmentResult.FluencyScore">
            <summary>
            Fluency score.
            </summary>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.WordLevelPronunciationAssessmentResult">
            <summary>
            Word level pronunciation assessment results
            Added in version 1.14.0.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.WordLevelPronunciationAssessmentResult.AccuracyScore">
            <summary>
            Accuracy score.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.WordLevelPronunciationAssessmentResult.ErrorType">
            <summary>
            Error type.
            </summary>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.PhonemeLevelPronunciationAssessmentResult">
            <summary>
            Phoneme level pronunciation assessment results
            Added in version 1.14.0.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.PhonemeLevelPronunciationAssessmentResult.AccuracyScore">
            <summary>
            Accuracy score.
            </summary>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.Intent.LanguageUnderstandingModel">
            <summary>
            Represents language understanding model used for intent recognition.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Intent.LanguageUnderstandingModel.FromEndpoint(System.String)">
            <summary>
            Creates an language understanding model using the specified endpoint.
            </summary>
            <param name="uri">A string that represents the endpoint of the language understanding model.</param>
            <returns>The language understanding model being created.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Intent.LanguageUnderstandingModel.FromAppId(System.String)">
            <summary>
            Creates an language understanding model using the application id of Language Understanding service.
            </summary>
            <param name="appId">A string that represents the application id of Language Understanding service.</param>
            <returns>The language understanding model being created.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Intent.LanguageUnderstandingModel.FromSubscription(System.String,System.String,System.String)">
            <summary>
            Creates an language understanding model using hostname, subscription key and application id of Language Understanding service.
            </summary>
            <param name="subscriptionKey">A string that represents the subscription key of Language Understanding service.</param>
            <param name="appId">A string that represents the application id of Language Understanding service.</param>
            <param name="region">A string that represents the region of the Language Understanding service (see the <a href="https://aka.ms/csspeech/region">region page</a>).</param>
            <returns>The language understanding model being created.</returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.Intent.IntentRecognitionResult">
            <summary>
            Defines result of intent recognition.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Intent.IntentRecognitionResult.IntentId">
            <summary>
            A string that represents the intent identifier being recognized.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Intent.IntentRecognitionResult.ToString">
            <summary>
            Returns a string that represents the intent recognition result.
            </summary>
            <returns>A string that represents the intent recognition result.</returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.Intent.IntentRecognitionEventArgs">
            <summary>
            Define payload of intent recognizing/recognized events.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Intent.IntentRecognitionEventArgs.Result">
            <summary>
            Represents the intent recognition result.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Intent.IntentRecognitionEventArgs.ToString">
            <summary>
            Returns a string that represents the session id and the intent recognition result event.
            </summary>
            <returns>A string that represents the intent recognition result event.</returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.Intent.IntentRecognitionCanceledEventArgs">
            <summary>
            Define payload of intent recognition canceled result events.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Intent.IntentRecognitionCanceledEventArgs.Reason">
            <summary>
            The reason the result was canceled.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Intent.IntentRecognitionCanceledEventArgs.ErrorCode">
            <summary>
            The error code in case of an unsuccessful recognition (<see cref="P:Microsoft.CognitiveServices.Speech.Intent.IntentRecognitionCanceledEventArgs.Reason"/> is set to Error).
            If Reason is not Error, ErrorCode returns NoError.
            Added in version 1.1.0.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Intent.IntentRecognitionCanceledEventArgs.ErrorDetails">
            <summary>
            The error message in case of an unsuccessful recognition (<see cref="P:Microsoft.CognitiveServices.Speech.Intent.IntentRecognitionCanceledEventArgs.Reason"/> is set to Error).
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Intent.IntentRecognitionCanceledEventArgs.ToString">
            <summary>
            Returns a string that represents the session id and the intent recognition result event.
            </summary>
            <returns>A string that represents the intent recognition result event.</returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.Intent.IntentRecognizer">
            <summary>
            Perform intent recognition on the speech input. It returns both recognized text and recognized intent.
            </summary>
        </member>
        <member name="E:Microsoft.CognitiveServices.Speech.Intent.IntentRecognizer.Recognizing">
            <summary>
            The event <see cref="E:Microsoft.CognitiveServices.Speech.Intent.IntentRecognizer.Recognizing"/> signals that an intermediate recognition result is received.
            </summary>
        </member>
        <member name="E:Microsoft.CognitiveServices.Speech.Intent.IntentRecognizer.Recognized">
            <summary>
            The event <see cref="E:Microsoft.CognitiveServices.Speech.Intent.IntentRecognizer.Recognized"/> signals that a final recognition result is received.
            </summary>
        </member>
        <member name="E:Microsoft.CognitiveServices.Speech.Intent.IntentRecognizer.Canceled">
            <summary>
            The event <see cref="E:Microsoft.CognitiveServices.Speech.Intent.IntentRecognizer.Canceled"/> signals that the intent recognition was canceled.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Intent.IntentRecognizer.#ctor(Microsoft.CognitiveServices.Speech.SpeechConfig)">
            <summary>
            Creates a new instance of IntentRecognizer.
            </summary>
            <param name="speechConfig">Speech configuration</param>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Intent.IntentRecognizer.#ctor(Microsoft.CognitiveServices.Speech.SpeechConfig,Microsoft.CognitiveServices.Speech.Audio.AudioConfig)">
            <summary>
            Creates a new instance of IntentRecognizer.
            </summary>
            <param name="speechConfig">Speech configuration</param>
            <param name="audioConfig">Audio configuration</param>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Intent.IntentRecognizer.SpeechRecognitionLanguage">
            <summary>
            Gets the language name that is used for recognition.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Intent.IntentRecognizer.AuthorizationToken">
            <summary>
            Gets/sets authorization token used to communicate with the service.
            Note: The caller needs to ensure that the authorization token is valid. Before the authorization token
            expires, the caller needs to refresh it by calling this setter with a new valid token.
            Otherwise, the recognizer will encounter errors during recognition.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Intent.IntentRecognizer.Properties">
            <summary>
            Gets the collection of properties and their values defined for this <see cref="T:Microsoft.CognitiveServices.Speech.Intent.IntentRecognizer"/>.
            Note: The property collection is only valid until the recognizer owning this Properties is disposed or finalized.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Intent.IntentRecognizer.RecognizeOnceAsync">
            <summary>
            Starts speech recognition with intent recognition, and returns after a single utterance is recognized. The end of a
            single utterance is determined by listening for silence at the end or until a maximum of 15
            seconds of audio is processed.  The task returns the recognition text as result.
            Note: Since RecognizeOnceAsync() returns only a single utterance, it is suitable only for single
            shot recognition like command or query.
            For long-running multi-utterance recognition, use StartContinuousRecognitionAsync() instead.
            </summary>
            <returns>A task representing the recognition operation. The task returns a value of <see cref="T:Microsoft.CognitiveServices.Speech.Intent.IntentRecognitionResult"/></returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Intent.IntentRecognizer.StartContinuousRecognitionAsync">
            <summary>
            Starts speech recognition on a continuous audio stream, until StopContinuousRecognitionAsync() is called.
            User must subscribe to events to receive recognition results.
            </summary>
            <returns>A task representing the asynchronous operation that starts the recognition.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Intent.IntentRecognizer.StopContinuousRecognitionAsync">
            <summary>
            Stops continuous intent recognition.
            </summary>
            <returns>A task representing the asynchronous operation that stops the recognition.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Intent.IntentRecognizer.StartKeywordRecognitionAsync(Microsoft.CognitiveServices.Speech.KeywordRecognitionModel)">
            <summary>
            Starts speech recognition on a continuous audio stream with keyword spotting, until StopKeywordRecognitionAsync() is called.
            User must subscribe to events to receive recognition results.
            </summary>
            Note: Keyword spotting (KWS) functionality might work with any microphone type, official KWS support, however, is currently limited to the microphone arrays found in the Azure Kinect DK hardware or the Speech Devices SDK.
            <param name="model">The keyword recognition model that specifies the keyword to be recognized.</param>
            <returns>A task representing the asynchronous operation that starts the recognition.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Intent.IntentRecognizer.StopKeywordRecognitionAsync">
            <summary>
            Stops continuous speech recognition with keyword spotting.
            </summary>
            Note: Keyword spotting (KWS) functionality might work with any microphone type, official KWS support, however, is currently limited to the microphone arrays found in the Azure Kinect DK hardware or the Speech Devices SDK.
            <returns>A task representing the asynchronous operation that stops the recognition.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Intent.IntentRecognizer.AddIntent(System.String)">
            <summary>
            Adds a simple phrase that may be spoken by the user, indicating a specific user intent.
            </summary>
            <param name="simplePhrase">The phrase corresponding to the intent.</param>
            <remarks>Once recognized, the IntentRecognitionResult's IntentId property will match the simplePhrase specified here.</remarks>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Intent.IntentRecognizer.AddIntent(System.String,System.String)">
            <summary>
            Adds a simple phrase that may be spoken by the user, indicating a specific user intent.
            </summary>
            <param name="simplePhrase">The phrase corresponding to the intent.</param>
            <param name="intentId">A custom id string to be returned in the IntentRecognitionResult's IntentId property.</param>
            <remarks>Once recognized, the result's intent id will match the id supplied here.</remarks>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Intent.IntentRecognizer.AddIntent(Microsoft.CognitiveServices.Speech.Intent.LanguageUnderstandingModel,System.String)">
            <summary>
            Adds a single intent by name from the specified Language Understanding Model.
            </summary>
            <param name="model">The language understanding model containing the intent.</param>
            <param name="intentName">The name of the single intent to be included from the language understanding model.</param>
            <remarks>Once recognized, the IntentRecognitionResult's IntentId property will contain the intentName specified here.</remarks>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Intent.IntentRecognizer.AddIntent(Microsoft.CognitiveServices.Speech.Intent.LanguageUnderstandingModel,System.String,System.String)">
            <summary>
            Adds a single intent by name from the specified Language Understanding Model.
            </summary>
            <param name="model">The language understanding model containing the intent.</param>
            <param name="intentName">The name of the single intent to be included from the language understanding model.</param>
            <param name="intentId">A custom id string to be returned in the IntentRecognitionResult's IntentId property.</param>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Intent.IntentRecognizer.AddAllIntents(Microsoft.CognitiveServices.Speech.Intent.LanguageUnderstandingModel,System.String)">
            <summary>
            Adds all intents from the specified Language Understanding Model.
            </summary>
            <param name="model">The language understanding model from Language Understanding service.</param>
            <param name="intentId">A custom string id to be returned in the IntentRecognitionResult's IntentId property.</param>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Intent.IntentRecognizer.AddAllIntents(Microsoft.CognitiveServices.Speech.Intent.LanguageUnderstandingModel)">
            <summary>
            Adds all intents from the specified Language Understanding Model.
            </summary>
            <param name="model">The language understanding model from Language Understanding service.</param>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Intent.IntentRecognizer.Dispose(System.Boolean)">
            <summary>
            This method performs cleanup of resources.
            The Boolean parameter <paramref name="disposing"/> indicates whether the method is called from <see cref="M:System.IDisposable.Dispose"/> (if <paramref name="disposing"/> is true) or from the finalizer (if <paramref name="disposing"/> is false).
            Derived classes should override this method to dispose resource if needed.
            </summary>
            <param name="disposing">Flag to request disposal.</param>
            <returns></returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.KeywordRecognitionModel">
            <summary>
            Represents keyword recognition model used with StartKeywordRecognitionAsync.
            </summary>
            Note: Keyword spotting (KWS) functionality might work with any microphone type, official KWS support, however, is currently limited to the microphone arrays found in the Azure Kinect DK hardware or the Speech Devices SDK.
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.KeywordRecognitionModel.FromFile(System.String)">
            <summary>
            Creates a keyword recognition model using the specified file.
            </summary>
            <param name="fileName">A string that represents file name for the keyword recognition model.</param>
            <returns>The keyword recognition model being created.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.KeywordRecognitionModel.Dispose">
            <summary>
            Dispose of associated resources.
            </summary>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.KeywordRecognitionEventArgs">
            <summary>
            Class for the events emitted by the <see cref="T:Microsoft.CognitiveServices.Speech.KeywordRecognizer" />.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.KeywordRecognitionEventArgs.Result">
            <summary>
            Keyword recognition event result.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.KeywordRecognitionEventArgs.ToString">
            <summary>
            Returns a string that represents the keyword recognition result event.
            </summary>
            <returns>A string that represents the keyword recognition result event.</returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.KeywordRecognitionResult">
            <summary>
            Class that defines the results emitted by the <see cref="T:Microsoft.CognitiveServices.Speech.KeywordRecognizer" />.
            </summary>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.KeywordRecognizer">
            <summary>
            Recognizer type that is specialized to only handle keyword activation.
            <seealso cref="T:Microsoft.CognitiveServices.Speech.KeywordRecognitionResult" />
            <seealso cref="T:Microsoft.CognitiveServices.Speech.KeywordRecognitionEventArgs" />
            <seealso cref="T:Microsoft.CognitiveServices.Speech.KeywordRecognitionModel" />
            <seealso cref="T:Microsoft.CognitiveServices.Speech.Internal.AudioConfig" />
            </summary>
            <example>
            First, the object needs to be instantiated:
            <code>
            // (This sample uses the microphone. You can use any input source.)
            var audioConfig = Microsoft.CognitiveServices.Speech.Audio.AudioConfig.FromDefaultMicrophoneInput();
            var recognizer = new KeywordRecognizer (audioConfig);
            </code>
            (optional) Then, the events need to be wired in order to receive notifications:
            <code>
            recognizer.Recognized += (s, e) =&gt;
            {
                // Keyword detected!
            };
            </code>
            All set up. Start recognition.
            <code>
            // for .table, see:
            // https://docs.microsoft.com/azure/cognitive-services/speech-service/custom-keyword-basics
            var keywordModel = KeywordRecognitionModel.FromFile(@"C:\path\to\your\tablefile.table");
            var result = recognizer.RecognizeOnceAsync(keywordModel);
            result.Wait();
            </code>
            </example>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.KeywordRecognizer.gch">
            <summary>
            GC handle for callbacks for context.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.KeywordRecognizer.#ctor(Microsoft.CognitiveServices.Speech.Audio.AudioConfig)">
            <summary>
            Creates a KeywordRecognizer from an <see cref="T:Microsoft.CognitiveServices.Speech.Internal.AudioConfig" />. The config is intended
            to define the audio input to be used by the recognizer object.
            </summary>
            <param name="audioConfig">Defines the audio input to be used by the recognizer.</param>
            <returns>A new KeywordRecognizer that will consume audio from the specified input.</returns>
            <remarks>
            If no audio config is provided, it will be equivalent to calling with a config constructed with
            <see cref="M:Microsoft.CognitiveServices.Speech.Audio.AudioConfig.FromDefaultMicrophoneInput" />
            </remarks>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.KeywordRecognizer.RecognizeOnceAsync(Microsoft.CognitiveServices.Speech.KeywordRecognitionModel)">
            <summary>
            Starts a keyword recognition session. This session will last until the first keyword is recognized. When this happens,
            a <see cref="E:Microsoft.CognitiveServices.Speech.KeywordRecognizer.Recognized" /> event will be raised and the session will end. To rearm the keyword, the method needs to be called
            again after the event is emitted.
            </summary>
            <param name="model">The <see cref="T:Microsoft.CognitiveServices.Speech.KeywordRecognitionModel" /> that describes the keyword we want to detect.</param>
            <returns>A future that resolves to a <see cref="T:Microsoft.CognitiveServices.Speech.KeywordRecognitionResult" /> that resolves once a keyword is detected.</returns>
            <remarks>
            Note that if no keyword is detected in the input, the task will never resolve (unless <see cref="M:Microsoft.CognitiveServices.Speech.KeywordRecognizer.StopRecognitionAsync" /> is called.
            </remarks>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.KeywordRecognizer.StopRecognitionAsync">
            <summary>
            Stops a currently active keyword recognition session.
            </summary>
            <returns>A future that resolves when the active session (if any) is stopped.</returns>
        </member>
        <member name="E:Microsoft.CognitiveServices.Speech.KeywordRecognizer.Recognized">
            <summary>
            Signal for events related to the recognition of keywords.
            </summary>
        </member>
        <member name="E:Microsoft.CognitiveServices.Speech.KeywordRecognizer.Canceled">
            <summary>
            Signal for events relating to the cancellation of an interaction. The event indicates if the reason is a direct cancellation or an error.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.KeywordRecognizer.Properties">
            <summary>
            A collection of properties and their values defined for this <see cref="T:Microsoft.CognitiveServices.Speech.KeywordRecognizer"/>.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.KeywordRecognizer.isDisposing">
            <summary>
            isDisposing is a flag used to indicate if object is being disposed.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.KeywordRecognizer.Dispose">
            <summary>
            This method performs cleanup of resources.
            </summary>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.NoMatchReason">
            <summary>
            Defines the possible reasons a recognition result might not be recognized.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.NoMatchReason.NotRecognized">
            <summary>
            Indicates that speech was detected, but not recognized.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.NoMatchReason.InitialSilenceTimeout">
            <summary>
            Indicates that the start of the audio stream contained only silence, and the service timed out waiting for speech.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.NoMatchReason.InitialBabbleTimeout">
            <summary>
            Indicates that the start of the audio stream contained only noise, and the service timed out waiting for speech.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.NoMatchReason.KeywordNotRecognized">
            <summary>
            Indicates that the spotted keyword has been rejected by the keyword verification service.
            Added in version 1.5.0
            </summary>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.OutputFormat">
            <summary>
            Output format.
            </summary>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.ProfanityOption">
            <summary>
            Profanity option.
            Added in version 1.5.0.
            </summary>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.PronunciationAssessment.PronunciationAssessmentConfig">
            <summary>
            Class that defines pronunciation assessment configuration
            Added in 1.14.0
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.PronunciationAssessment.PronunciationAssessmentConfig.#ctor(System.String,Microsoft.CognitiveServices.Speech.PronunciationAssessment.GradingSystem,Microsoft.CognitiveServices.Speech.PronunciationAssessment.Granularity,System.Boolean)">
            <summary>
            Creates an instance of the PronunciationAssessmentConfig
            For the parameters details, see
            https://docs.microsoft.com/azure/cognitive-services/speech-service/rest-speech-to-text#pronunciation-assessment-parameters
            </summary>
            <param name="referenceText">The reference text</param>
            <param name="gradingSystem">The point system for score calibration</param>
            <param name="granularity">The evaluation granularity</param>
            <param name="enableMiscue">If enables miscue calculation</param>
            <returns>A new PronunciationAssessmentConfig instance.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.PronunciationAssessment.PronunciationAssessmentConfig.FromJson(System.String)">
            <summary>
            Creates an instance of the PronunciationAssessmentConfig from json.
            see https://docs.microsoft.com/azure/cognitive-services/speech-service/rest-speech-to-text#pronunciation-assessment-parameters
            </summary>
            <param name="json">The json string containing the pronunciation assessment parameters.</param>
            <returns>A new PronunciationAssessmentConfig instance.</returns>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.PronunciationAssessment.PronunciationAssessmentConfig.ReferenceText">
            <summary>
            Reference Text
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.PronunciationAssessment.PronunciationAssessmentConfig.ToJson">
            <summary>
            Gets to json string of pronunciation assessment parameters.
            </summary>
            <returns>json string of pronunciation assessment parameters.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.PronunciationAssessment.PronunciationAssessmentConfig.ApplyTo(Microsoft.CognitiveServices.Speech.Recognizer)">
            <summary>
            Applies the settings in this config to a recognizer.
            </summary>
            <param name="recognizer">The target recognizer.</param>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.PronunciationAssessment.GradingSystem">
            <summary>
            Defines the point system for pronunciation score calibration; default value is FivePoint.
            Added in version 1.14.0
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PronunciationAssessment.GradingSystem.FivePoint">
            <summary>
            Five point calibration
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PronunciationAssessment.GradingSystem.HundredMark">
            <summary>
            Hundred mark
            </summary>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.PronunciationAssessment.Granularity">
            <summary>
            Defines the pronunciation evaluation granularity; default value is Phoneme.
            Added in version 1.14.0
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PronunciationAssessment.Granularity.Phoneme">
            <summary>
            Shows the score on the full text, word and phoneme level
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PronunciationAssessment.Granularity.Word">
            <summary>
            Shows the score on the full text and word level
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PronunciationAssessment.Granularity.FullText">
            <summary>
            Shows the score on the full text level only
            </summary>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.PronunciationAssessment.PronunciationAssessmentResult">
            <summary>
            Contains pronunciation assessment result
            Added in 1.14.0
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.PronunciationAssessment.PronunciationAssessmentResult.AccuracyScore">
            <summary>
            The score indicating the pronunciation accuracy of the given speech, which indicates
            how closely the phonemes match a native speaker's pronunciation.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.PronunciationAssessment.PronunciationAssessmentResult.PronunciationScore">
            <summary>
            The overall score indicating the pronunciation quality of the given speech.
            This is calculated from AccuracyScore, FluencyScore and CompletenessScore with weight.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.PronunciationAssessment.PronunciationAssessmentResult.CompletenessScore">
            <summary>
            The score indicating the completeness of the given speech by calculating the ratio of pronounced words towards entire input.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.PronunciationAssessment.PronunciationAssessmentResult.FluencyScore">
            <summary>
            The score indicating the fluency of the given speech.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.PronunciationAssessment.PronunciationAssessmentResult.Words">
            <summary>
            Word level pronunciation assessment result
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.PronunciationAssessment.PronunciationAssessmentResult.FromResult(Microsoft.CognitiveServices.Speech.SpeechRecognitionResult)">
            <summary>
            Creates an instance of PronunciationAssessmentResult object for the speech recognition result.
            </summary>
            <param name="result">The speech recongition result.</param>
            <returns>A new PronunciationAssessmentResult instance</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.PronunciationAssessment.PronunciationAssessmentResult.#ctor(Microsoft.CognitiveServices.Speech.DetailedSpeechRecognitionResult)">
            <summary>
            Creates an instance of PronunciationAssessmentResult object for a DetailedSpeechRecognitionResult result.
            </summary>
            <param name="result">The DetailedSpeechRecognitionResult result.</param>
            <returns>A new PronunciationAssessmentResult instance</returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.PronunciationAssessment.PronunciationAssessmentWordResult">
            <summary>
            Contains word level pronunciation assessment result
            Added in 1.14.0
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.PronunciationAssessment.PronunciationAssessmentWordResult.Word">
            <summary>
            The word text
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.PronunciationAssessment.PronunciationAssessmentWordResult.AccuracyScore">
            <summary>
            The score indicating the pronunciation accuracy of the given speech, which indicates
            how closely the phonemes match a native speaker's pronunciation.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.PronunciationAssessment.PronunciationAssessmentWordResult.ErrorType">
            <summary>
            This value indicates whether a word is omitted, inserted or badly pronounced, compared to ReferenceText.
            Possible values are None (meaning no error on this word), Omission, Insertion and Mispronunciation.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.PronunciationAssessment.PronunciationAssessmentWordResult.Phonemes">
            <summary>
            Phoneme level pronunciation assessment result
            </summary>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.PronunciationAssessment.PronunciationAssessmentPhonemeResult">
            <summary>
            Contains phoneme level pronunciation assessment result
            Added in 1.14.0
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.PronunciationAssessment.PronunciationAssessmentPhonemeResult.Phoneme">
            <summary>
            The phoneme text
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.PronunciationAssessment.PronunciationAssessmentPhonemeResult.AccuracyScore">
            <summary>
            The score indicating the pronunciation accuracy of the given speech, which indicates
            how closely the phonemes match a native speaker's pronunciation.
            </summary>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.PropertyCollection">
            <summary>
            Class to retrieve or set a property value from a property collection.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.PropertyCollection.#ctor(System.IntPtr)">
            <summary>
            Constructor to create PropertyCollection
            </summary>
            <param name="propertyBagPtr">The property bag handle.</param>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.PropertyCollection.Close">
            <summary>
            Dispose the property bag
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.PropertyCollection.GetProperty(Microsoft.CognitiveServices.Speech.PropertyId)">
            <summary>
            Returns value of a property.
            If the property value is not defined, an empty string is returned.
            </summary>
            <param name="id">The ID of property. See <see cref="T:Microsoft.CognitiveServices.Speech.PropertyId"/></param>
            <returns>value of the property</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.PropertyCollection.GetProperty(System.String)">
            <summary>
            Returns value of a property.
            If the property value is not defined, an empty string is returned.
            </summary>
            <param name="propertyName">The name of property</param>
            <returns>value of the property</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.PropertyCollection.GetProperty(Microsoft.CognitiveServices.Speech.PropertyId,System.String)">
            <summary>
            Returns value of a property.
            If the property value is not defined, the specified default value is returned.
            </summary>
            <param name="id">The id of property. See <see cref="T:Microsoft.CognitiveServices.Speech.PropertyId"/></param>
            <param name="defaultValue">The default value which is returned if no value is defined for the property.</param>
            <returns>value of the property.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.PropertyCollection.GetProperty(System.String,System.String)">
            <summary>
            Returns value of a property.
            If the property value is not defined, the specified default value is returned.
            </summary>
            <param name="propertyName">The name of property.</param>
            <param name="defaultValue">The default value which is returned if no value is defined for the property.</param>
            <returns>value of the property.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.PropertyCollection.SetProperty(Microsoft.CognitiveServices.Speech.PropertyId,System.String)">
            <summary>
            Set value of a property.
            </summary>
            <param name="id">The id of property. See <see cref="T:Microsoft.CognitiveServices.Speech.PropertyId"/></param>
            <param name="value">value to set</param>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.PropertyCollection.SetProperty(System.String,System.String)">
            <summary>
            Set value of a property.
            </summary>
            <param name="propertyName">The name of property.</param>
            <param name="value">value to set</param>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.PropertyId">
            <summary>
            Defines speech property ids.
            Changed in version 1.9.0.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_Key">
            <summary>
            The Cognitive Services Speech Service subscription key. If you are using an intent recognizer, you need
            to specify the LUIS endpoint key for your particular LUIS app. Under normal circumstances, you shouldn't
            have to use this property directly.
            Instead, use <see cref="M:Microsoft.CognitiveServices.Speech.SpeechConfig.FromSubscription(System.String,System.String)"/>.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_Endpoint">
            <summary>
            The Cognitive Services Speech Service endpoint (url). Under normal circumstances, you shouldn't
            have to use this property directly.
            Instead, use  <see cref="M:Microsoft.CognitiveServices.Speech.SpeechConfig.FromEndpoint(System.Uri,System.String)"/>, or <see cref="M:Microsoft.CognitiveServices.Speech.SpeechConfig.FromEndpoint(System.Uri)"/>.
            NOTE: This endpoint is not the same as the endpoint used to obtain an access token.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_Region">
            <summary>
            The Cognitive Services Speech Service region. Under normal circumstances, you shouldn't have to
            use this property directly.
            Instead, use <see cref="M:Microsoft.CognitiveServices.Speech.SpeechConfig.FromSubscription(System.String,System.String)"/>, <see cref="M:Microsoft.CognitiveServices.Speech.SpeechConfig.FromEndpoint(System.Uri,System.String)"/>,
            <see cref="M:Microsoft.CognitiveServices.Speech.SpeechConfig.FromEndpoint(System.Uri)"/>, <see cref="M:Microsoft.CognitiveServices.Speech.SpeechConfig.FromHost(System.Uri,System.String)"/>,
            <see cref="M:Microsoft.CognitiveServices.Speech.SpeechConfig.FromHost(System.Uri)"/>, <see cref="M:Microsoft.CognitiveServices.Speech.SpeechConfig.FromAuthorizationToken(System.String,System.String)"/>.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceAuthorization_Token">
            <summary>
            The Cognitive Services Speech Service authorization token (aka access token). Under normal circumstances,
            you shouldn't have to use this property directly.
            Instead, use <see cref="M:Microsoft.CognitiveServices.Speech.SpeechConfig.FromAuthorizationToken(System.String,System.String)"/>,
            <see cref="P:Microsoft.CognitiveServices.Speech.SpeechRecognizer.AuthorizationToken"/>, <see cref="P:Microsoft.CognitiveServices.Speech.Intent.IntentRecognizer.AuthorizationToken"/>, <see cref="P:Microsoft.CognitiveServices.Speech.Translation.TranslationRecognizer.AuthorizationToken"/>.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceAuthorization_Type">
            <summary>
            The Cognitive Services Speech Service authorization type. Currently unused.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_EndpointId">
            <summary>
            The Cognitive Services Custom Speech Service endpoint id. Under normal circumstances, you shouldn't
            have to use this property directly.
            Instead use <see cref="M:Microsoft.CognitiveServices.Speech.SpeechConfig.FromEndpoint(System.Uri,System.String)"/>, or <see cref="M:Microsoft.CognitiveServices.Speech.SpeechConfig.FromEndpoint(System.Uri)"/>.
            NOTE: The endpoint id is available in the Custom Speech Portal, listed under Endpoint Details.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_Host">
            <summary>
            The Cognitive Services Speech Service host (url). Under normal circumstances, you shouldn't
            have to use this property directly.
            Instead, use <see cref="M:Microsoft.CognitiveServices.Speech.SpeechConfig.FromHost(System.Uri,System.String)"/>, or <see cref="M:Microsoft.CognitiveServices.Speech.SpeechConfig.FromHost(System.Uri)"/>.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_ProxyHostName">
            <summary>
            The host name of the proxy server used to connect to the Cognitive Services Speech Service. Under normal circumstances,
            you shouldn't have to use this property directly.
            Instead use <see cref="M:Microsoft.CognitiveServices.Speech.SpeechConfig.SetProxy(System.String,System.Int32,System.String,System.String)"/>.
            NOTE: This property id was added in version 1.1.0.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_ProxyPort">
            <summary>
            The port of the proxy server used to connect to the Cognitive Services Speech Service. Under normal circumstances,
            you shouldn't have to use this property directly.
            Instead use <see cref="M:Microsoft.CognitiveServices.Speech.SpeechConfig.SetProxy(System.String,System.Int32,System.String,System.String)"/>.
            NOTE: This property id was added in version 1.1.0.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_ProxyUserName">
            <summary>
            The user name of the proxy server used to connect to the Cognitive Services Speech Service. Under normal circumstances,
            you shouldn't have to use this property directly.
            Instead use <see cref="M:Microsoft.CognitiveServices.Speech.SpeechConfig.SetProxy(System.String,System.Int32,System.String,System.String)"/>.
            NOTE: This property id was added in version 1.1.0.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_ProxyPassword">
            <summary>
            The password of the proxy server used to connect to the Cognitive Services Speech Service. Under normal circumstances,
            you shouldn't have to use this property directly.
            Instead use <see cref="M:Microsoft.CognitiveServices.Speech.SpeechConfig.SetProxy(System.String,System.Int32,System.String,System.String)"/>.
            NOTE: This property id was added in version 1.1.0.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_Url">
            <summary>
            The URL string built from speech configuration.
            This property is intended to be read-only. The SDK is using it internally.
            NOTE: Added in version 1.5.0.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_TranslationToLanguages">
            <summary>
            The list of comma separated languages (in BCP-47 format) used as target translation languages. Under normal circumstances,
            you shouldn't have to use this property directly.
            Instead, use <see cref="M:Microsoft.CognitiveServices.Speech.SpeechTranslationConfig.AddTargetLanguage(System.String)"/> and the read-only <see cref="P:Microsoft.CognitiveServices.Speech.SpeechTranslationConfig.TargetLanguages"/> collection.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_TranslationVoice">
            <summary>
            The name of the Cognitive Service Text to Speech Service voice. Under normal circumstances, you shouldn't have to use this
            property directly. Instead use <see cref="P:Microsoft.CognitiveServices.Speech.SpeechTranslationConfig.VoiceName"/>.
            NOTE: Valid voice names can be found <a href="https://aka.ms/csspeech/voicenames">here</a>.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_TranslationFeatures">
            <summary>
            Translation features. For internal use.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_IntentRegion">
            <summary>
            The Language Understanding Service Region. Under normal circumstances, you shouldn't have to use this property directly.
            Instead use <see cref="T:Microsoft.CognitiveServices.Speech.Intent.LanguageUnderstandingModel"/>.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_RecoMode">
            <summary>
            The Cognitive Services Speech Service recognition mode. Can be "INTERACTIVE", "CONVERSATION", "DICTATION".
            This property is intended to be read-only. The SDK is using it internally.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_RecoLanguage">
            <summary>
            The spoken language to be recognized (in BCP-47 format). Under normal circumstances, you shouldn't have to use this property directly.
            Instead, use <see cref="P:Microsoft.CognitiveServices.Speech.SpeechConfig.SpeechRecognitionLanguage"/>.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PropertyId.Speech_SessionId">
            <summary>
            The session id. This id is a universally unique identifier (aka UUID) representing a specific binding of an audio input stream
            and the underlying speech recognition instance to which it is bound. Under normal circumstances,
            you shouldn't have to use this property directly.
            Instead use <see cref="P:Microsoft.CognitiveServices.Speech.SessionEventArgs.SessionId"/>.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_SynthLanguage">
            <summary>
            The spoken language to be synthesized (e.g. en-US)
            Added in version 1.4.0
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_SynthVoice">
            <summary>
            The name of the voice to be used for speech synthesis
            Added in version 1.4.0
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_SynthOutputFormat">
            <summary>
            The string to specify speech synthesis output audio format (e.g. riff-16khz-16bit-mono-pcm)
            Added in version 1.4.0
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_InitialSilenceTimeoutMs">
            <summary>
            The initial silence timeout value (in milliseconds) used by the service.
            Added in version 1.5.0
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_EndSilenceTimeoutMs">
            <summary>
            The end silence timeout value (in milliseconds) used by the service.
            Added in version 1.5.0
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_EnableAudioLogging">
            <summary>
            A boolean value specifying whether audio logging is enabled in the service or not.
            Added in version 1.5.0
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages">
            <summary>
            The auto detect source languages
            Added in version 1.9.0
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceConnection_AutoDetectSourceLanguageResult">
            <summary>
            The auto detect source language result
            Added in version 1.9.0
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceResponse_RequestDetailedResultTrueFalse">
            <summary>
            The requested Cognitive Services Speech Service response output format (simple or detailed). Under normal circumstances, you shouldn't have
            to use this property directly.
            Instead, use <see cref="P:Microsoft.CognitiveServices.Speech.SpeechConfig.OutputFormat"/>.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceResponse_RequestProfanityFilterTrueFalse">
            <summary>
            The requested Cognitive Services Speech Service response output profanity level. Currently unused.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceResponse_ProfanityOption">
            <summary>
            The requested Cognitive Services Speech Service response output profanity setting.
            Allowed values are "masked", "removed", and "raw".
            Added in version 1.5.0.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceResponse_PostProcessingOption">
            <summary>
            A string value specifying which post processing option should be used by service.
            Allowed values are "TrueText".
            Added in version 1.5.0
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceResponse_RequestWordLevelTimestamps">
            <summary>
            A boolean value specifying whether to include word-level timestamps in the response result.
            Added in version 1.5.0
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceResponse_StablePartialResultThreshold">
            <summary>
            The number of times a word has to be in partial results to be returned.
            Added in version 1.5.0
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceResponse_OutputFormatOption">
            <summary>
            A string value specifying the output format option in the response result. Internal use only.
            Added in version 1.5.0.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceResponse_TranslationRequestStablePartialResult">
            <summary>
            A boolean value to request for stabilizing translation partial results by omitting words in the end.
            Added in version 1.5.0.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceResponse_JsonResult">
            <summary>
            The Cognitive Services Speech Service response output (in JSON format). This property is available on
            recognition result objects only.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceResponse_JsonErrorDetails">
            <summary>
            The Cognitive Services Speech Service error details (in JSON format). Under normal circumstances, you shouldn't have to
            use this property directly. Instead use <see cref="P:Microsoft.CognitiveServices.Speech.CancellationDetails.ErrorDetails"/>.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PropertyId.SpeechServiceResponse_RecognitionLatencyMs">
            <summary>
            The recognition latency in milliseconds. Read-only, available on final speech/translation/intent results.
            This measures the latency between when an audio input is received by the SDK, and the moment the final result is received from the service.
            The SDK computes the time difference between the last audio fragment from the audio input that is contributing to the final result, and the time the final result is received from the speech service.
            Added in version 1.3.0.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PropertyId.CancellationDetails_Reason">
            <summary>
            The cancellation reason. Currently unused.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PropertyId.CancellationDetails_ReasonText">
            <summary>
            The cancellation text. Currently unused.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PropertyId.CancellationDetails_ReasonDetailedText">
            <summary>
            The cancellation detailed text. Currently unused.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PropertyId.LanguageUnderstandingServiceResponse_JsonResult">
            <summary>
            The Language Understanding Service response output (in JSON format). Available via <see cref="P:Microsoft.CognitiveServices.Speech.RecognitionResult.Properties"/>.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PropertyId.Speech_LogFilename">
            <summary>
            The file name to write logs.
            Added in version 1.4.0.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PropertyId.Conversation_ApplicationId">
            <summary>
            Identifier used to connect to the backend service.
            Added in version 1.5.0.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PropertyId.Conversation_DialogType">
            <summary>
            Type of dialog backend to connect to.
            Added in version 1.7.0.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PropertyId.Conversation_Initial_Silence_Timeout">
            <summary>
            Silence timeout for listening
            Added in version 1.5.0.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PropertyId.Conversation_From_Id">
            <summary>
            From Id to add to speech recognition activities.
            Added in version 1.5.0.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PropertyId.Conversation_Conversation_Id">
            <summary>
            ConversationId for the session.
            Added in version 1.8.0.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PropertyId.Conversation_Custom_Voice_Deployment_Ids">
            <summary>
            Comma separated list of custom voice deployment ids.
            Added in version 1.8.0.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PropertyId.Conversation_Speech_Activity_Template">
            <summary>
            Speech activity template, stamp properties from the template on the activity generated by the service for speech.
            Added in version 1.10.0.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PropertyId.Conversation_ParticipantId">
            <summary>
            Gets your identifier in the conversation.
            Added in version 1.13.0
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PropertyId.ConversationTranscribingService_DataBufferUserId">
            <summary>
            The user id associated to data buffer written by client when using Pull/Push audio mode streams.
            Added in version 1.5.0.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PropertyId.ConversationTranscribingService_DataBufferTimeStamp">
            <summary>
            The time stamp associated to data buffer written by client when using Pull/Push audio mode streams.
            The time stamp is a 64-bit value with a resolution of 90 kHz. The same as the presentation timestamp in an MPEG transport stream.
            See https://en.wikipedia.org/wiki/Presentation_timestamp.
            Added in version 1.5.0.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PropertyId.PronunciationAssessment_ReferenceText">
            <summary>
            The reference text of the audio for pronunciation evaluation.
            For this and the following pronunciation assessment parameters, see
            https://docs.microsoft.com/azure/cognitive-services/speech-service/rest-speech-to-text#pronunciation-assessment-parameters for details.
            Under normal circumstances, you shouldn't have to use this property directly.
            Added in version 1.14.0
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PropertyId.PronunciationAssessment_GradingSystem">
            <summary>
            The point system for pronunciation score calibration (FivePoint or HundredMark).
            Under normal circumstances, you shouldn't have to use this property directly.
            Added in version 1.14.0
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PropertyId.PronunciationAssessment_Granularity">
            <summary>
            The pronunciation evaluation granularity (Phoneme, Word, or FullText).
            Under normal circumstances, you shouldn't have to use this property directly.
            Added in version 1.14.0
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PropertyId.PronunciationAssessment_EnableMiscue">
            <summary>
            Defines if enable miscue calculation. 
            With this enabled, the pronounced words will be compared to the reference text, 
            and will be marked with omission/insertion based on the comparison. The default setting is False.
            Under normal circumstances, you shouldn't have to use this property directly.
            Added in version 1.14.0
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PropertyId.PronunciationAssessment_Json">
            <summary>
            The json string of pronunciation assessment parameters
            Under normal circumstances, you shouldn't have to use this property directly.
            Added in version 1.14.0
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.PropertyId.PronunciationAssessment_Params">
            <summary>
            Pronunciation assessment parameters.
            This property is intended to be read-only. The SDK is using it internally.
            Added in version 1.14.0
            </summary>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.ResultReason">
            <summary>
            Defines the possible reasons a recognition result might be generated.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.ResultReason.NoMatch">
            <summary>
            Indicates speech could not be recognized. More details can be found in the NoMatchDetails object.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.ResultReason.Canceled">
            <summary>
            Indicates that the recognition was canceled. More details can be found using the CancellationDetails object.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.ResultReason.RecognizingSpeech">
            <summary>
            Indicates the speech result contains hypothesis text.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.ResultReason.RecognizedSpeech">
            <summary>
            Indicates the speech result contains final text that has been recognized.
            Speech Recognition is now complete for this phrase.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.ResultReason.RecognizingIntent">
            <summary>
            Indicates the intent result contains hypothesis text and intent.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.ResultReason.RecognizedIntent">
            <summary>
            Indicates the intent result contains final text and intent.
            Speech Recognition and Intent determination are now complete for this phrase.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.ResultReason.TranslatingSpeech">
            <summary>
            Indicates the translation result contains hypothesis text and its translation(s).
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.ResultReason.TranslatedSpeech">
            <summary>
            Indicates the translation result contains final text and corresponding translation(s).
            Speech Recognition and Translation are now complete for this phrase.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.ResultReason.SynthesizingAudio">
            <summary>
            Indicates the synthesized audio result contains a non-zero amount of audio data
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.ResultReason.SynthesizingAudioCompleted">
            <summary>
            Indicates the synthesized audio is now complete for this phrase.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.ResultReason.RecognizingKeyword">
            <summary>
            Indicates the speech result contains (unverified) keyword text.
            Added in version 1.3.0
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.ResultReason.RecognizedKeyword">
            <summary>
            Indicates that keyword recognition completed recognizing the given keyword.
            Added in version 1.3.0
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.ResultReason.SynthesizingAudioStarted">
            <summary>
            Indicates the speech synthesis is now started.
            Added in version 1.4.0
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.ResultReason.TranslatingParticipantSpeech">
            <summary>
            Indicates the transcription result contains hypothesis text and its translation(s) for
            other participants in the conversation.
            Added in version 1.9.0
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.ResultReason.TranslatedParticipantSpeech">
            <summary>
            Indicates the transcription result contains final text and corresponding translation(s)
            for other participants in the conversation. Speech Recognition and Translation are now
            complete for this phrase.
            Added in version 1.9.0
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.ResultReason.TranslatedInstantMessage">
            <summary>
            Indicates the transcription result contains the instant message and corresponding
            translation(s).
            Added in version 1.9.0
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.ResultReason.TranslatedParticipantInstantMessage">
            <summary>
            Indicates the transcription result contains the instant message for other participants
            in the conversation and corresponding translation(s).
            Added in version 1.9.0
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.ResultReason.EnrollingVoiceProfile">
            <summary>
            Indicates the voice profile is being enrolled and customers need to send more audio to create a voice profile.
            Added in version 1.12.0
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.ResultReason.EnrolledVoiceProfile">
            <summary>
            Indicates the voice profile has been enrolled.
            Added in version 1.12.0
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.ResultReason.RecognizedSpeakers">
            <summary>
            Indicates successful identification of some speakers.
            Added in version 1.12.0
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.ResultReason.RecognizedSpeaker">
            <summary>
            Indicates successfully verified one speaker.
            Added in version 1.12.0
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.ResultReason.ResetVoiceProfile">
            <summary>
            Indicates a voice profile has been reset successfully.
            Added in version 1.12.0
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.ResultReason.DeletedVoiceProfile">
            <summary>
            Indicates a voice profile has been deleted successfully.
            Added in version 1.12.0
            </summary>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.CancellationReason">
            <summary>
            Defines the possible reasons a recognition result might be canceled.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.CancellationReason.Error">
            <summary>
            Indicates that an error occurred during speech recognition.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.CancellationReason.EndOfStream">
            <summary>
            Indicates that the end of the audio stream was reached.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.CancellationReason.CancelledByUser">
            <summary>
            Indicates that request was cancelled by the user.
            Added in version 1.14.0
            </summary>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.CancellationErrorCode">
            <summary>
            Defines error code in case that CancellationReason is Error.
            Added in version 1.1.0.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.CancellationErrorCode.NoError">
            <summary>
            No error.
            If CancellationReason is EndOfStream, CancellationErrorCode 
            is set to NoError.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.CancellationErrorCode.AuthenticationFailure">
            <summary>
            Indicates an authentication error.
            An authentication error occurs if subscription key or authorization token is invalid, expired, 
            or does not match the region being used.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.CancellationErrorCode.BadRequest">
            <summary>
            Indicates that one or more recognition parameters are invalid or the audio format is not supported.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.CancellationErrorCode.TooManyRequests">
            <summary>
            Indicates that the number of parallel requests exceeded the number of allowed concurrent transcriptions for the subscription.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.CancellationErrorCode.Forbidden">
            <summary>
            Indicates that the free subscription used by the request ran out of quota.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.CancellationErrorCode.ConnectionFailure">
            <summary>
            Indicates a connection error.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.CancellationErrorCode.ServiceTimeout">
            <summary>
            Indicates a time-out error when waiting for response from service.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.CancellationErrorCode.ServiceError">
            <summary>
            Indicates that an error is returned by the service.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.CancellationErrorCode.ServiceUnavailable">
            <summary>
            Indicates that the service is currently unavailable.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.CancellationErrorCode.RuntimeError">
            <summary>
            Indicates an unexpected runtime error.
            </summary>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.RecognitionEventArgs">
            <summary>
            Defines payload for recognition events like Speech Start/End Detected
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.RecognitionEventArgs.Offset">
            <summary>
            Represents the message offset in tick (100 nanoseconds)
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.RecognitionEventArgs.ToString">
            <summary>
            Returns a string that represents the recognition event payload.
            </summary>
            <returns>A string that represents the recognition event payload.</returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.RecognitionEventType">
            <summary>
            Define recognition event types.
            </summary>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.RecognitionResult">
            <summary>
            Contains detailed information about result of a recognition operation.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.RecognitionResult.ResultId">
            <summary>
            Specifies the result identifier.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.RecognitionResult.Reason">
            <summary>
            Specifies status of speech recognition result.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.RecognitionResult.Text">
            <summary>
            Presents the recognized text in the result.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.RecognitionResult.Duration">
            <summary>
            Duration of the recognized speech.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.RecognitionResult.OffsetInTicks">
            <summary>
            Offset of the recognized speech in ticks. A single tick represents one hundred nanoseconds or one ten-millionth of a second.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.RecognitionResult.Properties">
            <summary>
            Contains properties of the results.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.RecognitionResult.ToString">
            <summary>
            Returns a string that represents the speech recognition result.
            </summary>
            <returns>A string that represents the speech recognition result.</returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.CancellationDetails">
            <summary>
            Contains detailed information about why a result was canceled.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.CancellationDetails.FromResult(Microsoft.CognitiveServices.Speech.RecognitionResult)">
            <summary>
            Creates an instance of CancellationDetails object for the canceled SpeechRecognitionResult.
            </summary>
            <param name="result">The result that was canceled.</param>
            <returns>The CancellationDetails object being created.</returns>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.CancellationDetails.Reason">
            <summary>
            The reason the recognition was canceled.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.CancellationDetails.ErrorCode">
            <summary>
            The error code in case of an unsuccessful recognition (<see cref="P:Microsoft.CognitiveServices.Speech.CancellationDetails.Reason"/> is set to Error).
            If Reason is not Error, ErrorCode returns NoError.
            Added in version 1.1.0.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.CancellationDetails.ErrorDetails">
            <summary>
            The error message in case of an unsuccessful recognition (<see cref="P:Microsoft.CognitiveServices.Speech.CancellationDetails.Reason"/> is set to Error).
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.CancellationDetails.ToString">
            <summary>
            Returns a string that represents the cancellation details.
            </summary>
            <returns>A string that represents the cancellation details.</returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.NoMatchDetails">
            <summary>
            Contains detailed information for NoMatch recognition results.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.NoMatchDetails.FromResult(Microsoft.CognitiveServices.Speech.RecognitionResult)">
            <summary>
            Creates an instance of NoMatchDetails object for NoMatch RecognitionResults.
            </summary>
            <param name="result">The recognition result that was not recognized.</param>
            <returns>The NoMatchDetails object being created.</returns>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.NoMatchDetails.Reason">
            <summary>
            The reason the result was not recognized.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.NoMatchDetails.ToString">
            <summary>
            Returns a string that represents the cancellation details.
            </summary>
            <returns>A string that represents the cancellation details.</returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.Recognizer">
            <summary>
            Defines the base class Recognizer which mainly contains common event handlers.
            </summary>
        </member>
        <member name="E:Microsoft.CognitiveServices.Speech.Recognizer.SessionStarted">
            <summary>
            Defines event handler for session started event.
            </summary>
        </member>
        <member name="E:Microsoft.CognitiveServices.Speech.Recognizer.SessionStopped">
            <summary>
            Defines event handler for session stopped event.
            </summary>
        </member>
        <member name="E:Microsoft.CognitiveServices.Speech.Recognizer.SpeechStartDetected">
            <summary>
            Defines event handler for speech start detected event.
            </summary>
        </member>
        <member name="E:Microsoft.CognitiveServices.Speech.Recognizer.SpeechEndDetected">
            <summary>
            Defines event handler for speech end detected event.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Recognizer.Dispose">
            <summary>
            Dispose of associated resources.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Recognizer.Dispose(System.Boolean)">
            <summary>
            This method performs cleanup of resources.
            The Boolean parameter <paramref name="disposing"/> indicates whether the method is called from <see cref="M:System.IDisposable.Dispose"/> (if <paramref name="disposing"/> is true) or from the finalizer (if <paramref name="disposing"/> is false).
            Derived classes should override this method to dispose resource if needed.
            </summary>
            <param name="disposing">Flag to request disposal.</param>
            <returns></returns>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.Recognizer.gch">
            <summary>
            GC handle for callbacks for context.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.Recognizer.disposed">
            <summary>
            disposed is a flag used to indicate if object is disposed.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.Recognizer.isDisposing">
            <summary>
            isDisposing is a flag used to indicate if object is being disposed.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.Recognizer.recognizerLock">
            <summary>
            recognizerLock is used to synchronize access to objects member variables from multiple threads
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Recognizer.FireEvent_SetSessionStarted(System.IntPtr,System.IntPtr,System.IntPtr)">
             <summary>
             Define a private methods which raise a C# event when a corresponding callback is invoked from the native layer.
             </summary>
            
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Recognizer.DoAsyncRecognitionAction(System.Action)">
            <summary>
            This methods checks if a recognizer is disposed before performing async recognition action.
            The Action parameter <paramref name="recoImplAction"/> can be any internal async recognition method of Speech, Translation and Intent Recognizer.
            The method is called from all async recognition methods (e.g. <see cref="M:Microsoft.CognitiveServices.Speech.SpeechRecognizer.StartContinuousRecognitionAsync"/>).
            ObjectDisposedException will be thrown and the action will not be performed if its recognizer is not available anymore.
            The purpose of this method is to prevent possible race condition if async recognitions are not awaited.
            </summary>
            <param name="recoImplAction">Actual implementation.</param>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.ServicePropertyChannel">
            <summary>
            Defines channels used to pass property settings to service.
            Added in version 1.5.0.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.ServicePropertyChannel.UriQueryParameter">
            <summary>
            Uses URI query parameter to pass property settings to service.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.ServicePropertyChannel.HttpHeader">
            <summary>
            Uses HttpHeader to set a key/value in a HTTP header.
            </summary>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.SessionEventArgs">
            <summary>
            Defines payload for SessionStarted/Stopped events.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.SessionEventArgs.SessionId">
            <summary>
            Represents the session identifier.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SessionEventArgs.ToString">
            <summary>
            Returns a string that represents the session event.
            </summary>
            <returns>A string that represents the session event.</returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.SessionEventType">
            <summary>
            Define session event types.
            </summary>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.SourceLanguageConfig">
            <summary>
            Source Language configuration.
            Added in 1.9.0
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SourceLanguageConfig.FromLanguage(System.String)">
            <summary>
            Creates an instance of the SourceLanguageConfig with source language
            </summary>
            <param name="language">The source language</param>
            <returns>A new SourceLanguageConfig instance.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SourceLanguageConfig.FromLanguage(System.String,System.String)">
            <summary>
            Creates an instance of the SourceLanguageConfig with source language and custom endpoint id. A custom endpoint id corresponds to custom models. 
            </summary>
            <param name="language">The source language</param>
            <param name="endpointId">The custom endpoint id</param>
            <returns>A new SourceLanguageConfig instance.</returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.SpeakerIdentificationModel">
            <summary>
            Represents speaker identification model.
            Added in version 1.12.0
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeakerIdentificationModel.FromProfiles(System.Collections.Generic.IEnumerable{Microsoft.CognitiveServices.Speech.VoiceProfile})">
            <summary>
            Creates a speaker identification model from the voice profiles.
            </summary>
            <param name="profiles">a collection of voice profiles.</param>
            <returns>The speaker identification model being created.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeakerIdentificationModel.Dispose">
            <summary>
            Dispose of associated resources.
            </summary>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.SpeakerRecognitionResult">
            <summary>
            Contains detailed information about result of a speaker recognition operation.
            Added in 1.12.0
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.SpeakerRecognitionResult.ResultId">
            <summary>
            Specifies the result identifier.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.SpeakerRecognitionResult.Reason">
            <summary>
            Specifies status of speaker recognition result.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.SpeakerRecognitionResult.ProfileId">
            <summary>
            Presents the recognized profile id.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.SpeakerRecognitionResult.Score">
            <summary>
            Presents the similarity score of the recognized speaker.
            The score is a float number indicating the similarity between input audio and targeted voice profile.This number is between 0 and 1. A higher number means higher similarity.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.SpeakerRecognitionResult.Properties">
            <summary>
            Contains properties of the results.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeakerRecognitionResult.ToString">
            <summary>
            Returns a string that represents the speaker recognition result.
            </summary>
            <returns>A string that represents the speaker recognition result.</returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.SpeakerRecognitionCancellationDetails">
            <summary>
            Contains detailed information about why a result was canceled.
            Added in version 1.12.0
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeakerRecognitionCancellationDetails.FromResult(Microsoft.CognitiveServices.Speech.SpeakerRecognitionResult)">
            <summary>
            Contains the detailed information about why a speaker recognition result was canceled.
            </summary>
            <param name="result">The result that was canceled.</param>
            <returns>The CancellationDetails object being created.</returns>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.SpeakerRecognitionCancellationDetails.Reason">
            <summary>
            The reason the recognition was canceled.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.SpeakerRecognitionCancellationDetails.ErrorCode">
            <summary>
            The error code in case of an unsuccessful recognition (<see cref="P:Microsoft.CognitiveServices.Speech.SpeakerRecognitionCancellationDetails.Reason"/> is set to Error).
            If Reason is not Error, ErrorCode returns NoError.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.SpeakerRecognitionCancellationDetails.ErrorDetails">
            <summary>
            The error message in case of an unsuccessful recognition (<see cref="P:Microsoft.CognitiveServices.Speech.SpeakerRecognitionCancellationDetails.Reason"/> is set to Error).
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeakerRecognitionCancellationDetails.ToString">
            <summary>
            Returns a string that represents the cancellation details.
            </summary>
            <returns>A string that represents the cancellation details.</returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.SpeakerRecognizer">
            <summary>
            Perform speaker recognition.
            Added in version 1.12.0
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeakerRecognizer.#ctor(Microsoft.CognitiveServices.Speech.SpeechConfig,Microsoft.CognitiveServices.Speech.Audio.AudioConfig)">
             <summary>
             Creates a speaker recognizer.
             </summary>
             <param name="speechConfig">The speech configuration to use.</param>
             <param name="audioConfig">The audio config to use.</param>
             <returns></returns>
            
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.SpeakerRecognizer.Properties">
            <summary>
            Gets the collection of properties and their values defined for this <see cref="T:Microsoft.CognitiveServices.Speech.SpeakerRecognizer"/>.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeakerRecognizer.RecognizeOnceAsync(Microsoft.CognitiveServices.Speech.SpeakerVerificationModel)">
            <summary>
            Verify the speaker in the speaker verification model.
            </summary>
            <param name="model">A SpeakerVerificationModel.</param>
            <returns>An asynchronous operation representing verifying the speaker in the model.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeakerRecognizer.RecognizeOnceAsync(Microsoft.CognitiveServices.Speech.SpeakerIdentificationModel)">
            <summary>
            Identify the speakers in the speaker identification Model.
            </summary>
            <param name="model">A speaker identification model.</param>
            <returns>An asynchronous operation representing identifying the speakers in the model.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeakerRecognizer.Dispose(System.Boolean)">
             <summary>
            
             </summary>
             <param name="disposeManaged"></param>
             <returns></returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.SpeakerVerificationModel">
            <summary>
            Represents speaker verification model.
            Added in 1.12.0
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeakerVerificationModel.FromProfile(Microsoft.CognitiveServices.Speech.VoiceProfile)">
            <summary>
            Creates a speaker verification model from the voice profile.
            </summary>
            <param name="profile">A voice profile.</param>
            <returns>The speaker verification model being created.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeakerVerificationModel.Dispose">
            <summary>
            Dispose of associated resources.
            </summary>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.ClassLanguageModel">
            <summary>
            Represents a list of grammars for dynamic grammar scenarios.
            Added in version 1.7.0.
            </summary>
            <remarks>
            ClassLanguageModels are only usable in specific scenarios and are not generally available.
            </remarks>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.ClassLanguageModel.FromStorageId(System.String)">
            <summary>
            Creates a class language model from a storage ID.
            </summary>
            <param name="storageId))">The persisted storage ID of the language model.</param>
            <returns>The grammar.</returns>
            <remarks>
            Creating a ClassLanguageModel from a storage ID is only usable in specific scenarios and is not generally available.
            </remarks>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.ClassLanguageModel.#ctor(System.IntPtr)">
            <summary>
            Internal constructor. Creates a new instance using the provided native handle.
            </summary>
            <param name="hgrammar">Grammar handle.</param>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.ClassLanguageModel.AssignClass(System.String,Microsoft.CognitiveServices.Speech.Grammar)">
            <summary>
            Adds a single grammar to the current grammar list
            </summary>
            <param name="grammar">The grammar to add</param>
            <param name="className">The name of the class the grammar represents.</param>
            <remarks>
            Currently Class Language Models are the only support grammars to add.
            </remarks>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.Grammar">
            <summary>
            Represents base class grammar for customizing speech recognition.
            Added in version 1.5.0.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Grammar.#ctor(System.IntPtr)">
            <summary>
            Internal constructor. Creates a new instance using the provided native handle.
            </summary>
            <param name="hgrammar">Grammar handle.</param>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Grammar.FromStorageId(System.String)">
            <summary>
            Creates a Grammar from its storage Id.
            Added in version 1.7.0.
            </summary>
            <param name="storageId">The storage ID for the grammar.</param>
            <returns>A reference to the grammar</returns>
            <remarks>
            Creating a grammar from a storage ID is only usable in specific scenarios and is not generally possible.
            </remarks>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Grammar.NativeHandle">
            <summary>
            Internal native handle property.
            </summary>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.RecognitionFactorScope">
            <summary>
            Defines the scope that a Recognition Factor is applied to.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.RecognitionFactorScope.PartialPhrase">
            <summary>
            A Recognition Factor will apply to grammars that can be referenced as individual partial phrases.
            </summary>
            <remarks>
            Currently only applies to PhraseListGrammars
            </remarks>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.GrammarList">
            <summary>
            Represents a list of grammars for dynamic grammar scenarios.
            Added in version 1.7.0.
            </summary>
            <remarks>
            GrammarLists are only usable in specific scenarios and are not generally available.
            </remarks>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.GrammarList.FromRecognizer(Microsoft.CognitiveServices.Speech.Recognizer)">
            <summary>
            Creates a grammar lsit for the specified recognizer.
            </summary>
            <param name="recognizer">The recognizer from which to obtain the grammar list.</param>
            <returns>The grammar list associated with the recognizer.</returns>
            <remarks>
            Creating a grammar list from a recognizer is only usable in specific scenarios and is not generally available.
            </remarks>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.GrammarList.#ctor(System.IntPtr)">
            <summary>
            Internal constructor. Creates a new instance using the provided native handle.
            </summary>
            <param name="hgrammar">Grammar handle.</param>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.GrammarList.Add(Microsoft.CognitiveServices.Speech.Grammar)">
            <summary>
            Adds a single grammar to the current grammar list
            </summary>
            <param name="grammar">The grammar to add</param>
            <remarks>
            Currently Class Language Models are the only support grammars to add.
            </remarks>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.GrammarList.SetRecognitionFactor(System.Double,Microsoft.CognitiveServices.Speech.RecognitionFactorScope)">
            <summary>
            Sets the Recognition Factor applied to all grammars in a recognizer's GrammarList
            </summary>
            <param name="factor">The RecognitionFactor to apply</param>
            <param name="scope">The scope for the Recognition Factor being set</param>
            <remarks>
            The Recognition Factor is a numerical value greater than 0 modifies the default weight applied to supplied grammars.
            Setting the Recognition Factor to 0 will disable the supplied grammars.
            The default Recognition Factor is 1.
            </remarks>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.GrammarPhrase">
            <summary>
            Represents a phrase that may be spoken by the user.
            Added in version 1.5.0.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.GrammarPhrase.From(System.String)">
            <summary>
            Creates a grammar phrase using the specified phrase text.
            </summary>
            <param name="text">The text representing a phrase that may be spoken by the user.</param>
            <returns>A shared pointer to a grammar phrase.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.GrammarPhrase.#ctor(System.IntPtr)">
            <summary>
            Internal constructor. Creates a new instance using the provided native handle.
            </summary>
            <param name="hphrase">Grammar phrase handle.</param>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.GrammarPhrase.NativeHandle">
            <summary>
            Internal native handle property.
            </summary>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.PhraseListGrammar">
            <summary>
            Represents a phrase list grammar for dynamic grammar scenarios.
            Added in version 1.5.0.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.PhraseListGrammar.FromRecognizer(Microsoft.CognitiveServices.Speech.Recognizer)">
            <summary>
            Creates a phrase list grammar for the specified recognizer.
            </summary>
            <param name="recognizer">The recognizer from which to obtain the phrase list grammar.</param>
            <returns>The phrase list grammar.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.PhraseListGrammar.#ctor(System.IntPtr)">
            <summary>
            Internal constructor. Creates a new instance using the provided native handle.
            </summary>
            <param name="hgrammar">Grammar handle.</param>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.PhraseListGrammar.AddPhrase(System.String)">
            <summary>
            Adds a simple phrase that may be spoken by the user.
            </summary>
            <param name="text">The phrase to be added.</param>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.PhraseListGrammar.Clear">
            <summary>
            Clears all phrases from the phrase list grammar.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.PhraseListGrammar.FromRecognizer(Microsoft.CognitiveServices.Speech.Recognizer,System.String)">
            <summary>
            Internal. Creates a phrase list grammar for the specified recognizer, with the specified name.
            </summary>
            <param name="recognizer">The recognizer from which to obtain the phrase list grammar.</param>
            <param name="name">The name of the phrase list grammar to create.</param>
            <returns>The phrase list grammar.</returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.SpeechConfig">
            <summary>
            Speech configuration.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeechConfig.FromSubscription(System.String,System.String)">
            <summary>
            Creates an instance of speech configuration with specified subscription key and region.
            </summary>
            <param name="subscriptionKey">The subscription key, can be empty if authorization token is specified later.</param>
            <param name="region">The region name (see the <a href="https://aka.ms/csspeech/region">region page</a>).</param>
            <returns>A speech config instance.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeechConfig.FromAuthorizationToken(System.String,System.String)">
            <summary>
            Creates an instance of the speech config with specified authorization token and region.
            Note: The caller needs to ensure that the authorization token is valid. Before the authorization token
            expires, the caller needs to refresh it by calling this setter with a new valid token.
            As configuration values are copied when creating a new recognizer, the new token value will not apply to recognizers that have already been created.
            For recognizers that have been created before, you need to set authorization token of the corresponding recognizer
            to refresh the token. Otherwise, the recognizers will encounter errors during recognition.
            </summary>
            <param name="authorizationToken">The authorization token.</param>
            <param name="region">The region name (see the <a href="https://aka.ms/csspeech/region">region page</a>).</param>
            <returns>A speech config instance.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeechConfig.FromEndpoint(System.Uri,System.String)">
            <summary>
            Creates an instance of the speech config with specified endpoint and subscription key.
            This method is intended only for users who use a non-standard service endpoint or parameters.
            Note: The query parameters specified in the endpoint URI are not changed, even if they are set by any other APIs.
            For example, if the recognition language is defined in URI as query parameter "language=de-DE", and the property SpeechRecognitionLanguage is set to "en-US",
            the language setting in URI takes precedence, and the effective language is "de-DE".
            Only the parameters that are not specified in the endpoint URI can be set by other APIs.
            Note: To use an authorization token with FromEndpoint, use FromEndpoint(System.Uri),
            and then set the AuthorizationToken property on the created SpeechConfig instance.
            </summary>
            <param name="endpoint">The service endpoint to connect to.</param>
            <param name="subscriptionKey">The subscription key.</param>
            <returns>A speech config instance.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeechConfig.FromEndpoint(System.Uri)">
            <summary>
            Creates an instance of the speech config with specified endpoint.
            This method is intended only for users who use a non-standard service endpoint or parameters.
            Note: The query parameters specified in the endpoint URI are not changed, even if they are set by any other APIs.
            For example, if the recognition language is defined in URI as query parameter "language=de-DE", and the property SpeechRecognitionLanguage is set to "en-US",
            the language setting in URI takes precedence, and the effective language is "de-DE".
            Only the parameters that are not specified in the endpoint URI can be set by other APIs.
            Note: If the endpoint requires a subscription key for authentication, use FromEndpoint(System.Uri, string) to pass
            the subscription key as parameter.
            To use an authorization token with FromEndpoint, use this method to create a SpeechConfig instance, and then
            set the AuthorizationToken property on the created SpeechConfig instance.
            Note: Added in version 1.5.0.
            </summary>
            <param name="endpoint">The service endpoint to connect to.</param>
            <returns>A speech config instance.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeechConfig.FromHost(System.Uri,System.String)">
            <summary>
            Creates an instance of the speech config with specified host and subscription key.
            This method is intended only for users who use a non-default service host. Standard resource path will be assumed.
            For services with a non-standard resource path or no path at all, use FromEndpoint instead.
            Note: Query parameters are not allowed in the host URI and must be set by other APIs.
            Note: To use an authorization token with FromHost, use FromHost(System.Uri),
            and then set the AuthorizationToken property on the created SpeechConfig instance.
            Note: Added in version 1.8.0.
            </summary>
            <param name="host">The service host to connect to. Format is "protocol://host:port" where ":port" is optional.</param>
            <param name="subscriptionKey">The subscription key.</param>
            <returns>A speech config instance.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeechConfig.FromHost(System.Uri)">
            <summary>
            Creates an instance of the speech config with specified host.
            This method is intended only for users who use a non-default service host. Standard resource path will be assumed.
            For services with a non-standard resource path or no path at all, use FromEndpoint instead.
            Note: Query parameters are not allowed in the host URI and must be set by other APIs.
            Note: If the host requires a subscription key for authentication, use FromHost(System.Uri, string) to pass
            the subscription key as parameter.
            To use an authorization token with FromHost, use this method to create a SpeechConfig instance, and then
            set the AuthorizationToken property on the created SpeechConfig instance.
            Note: Added in version 1.8.0.
            </summary>
            <param name="host">The service host to connect to. Format is "protocol://host:port" where ":port" is optional.</param>
            <returns>A speech config instance.</returns>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.SpeechConfig.SubscriptionKey">
            <summary>
            Subscription key.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.SpeechConfig.Region">
            <summary>
            Region.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.SpeechConfig.AuthorizationToken">
            <summary>
            Gets/sets the authorization token.
            Note: The caller needs to ensure that the authorization token is valid. Before the authorization token
            expires, the caller needs to refresh it by calling this setter with a new valid token.
            As configuration values are copied when creating a new recognizer, the new token value will not apply to recognizers that have already been created.
            For recognizers that have been created before, you need to set authorization token of the corresponding recognizer
            to refresh the token. Otherwise, the recognizers will encounter errors during recognition.
            Changed in version 1.3.0.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.SpeechConfig.SpeechRecognitionLanguage">
            <summary>
            Specifies the name of spoken language to be recognized in BCP-47 format
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.SpeechConfig.OutputFormat">
            <summary>
            Gets/sets the speech recognition output format: simple or detailed.
            Note: This output format is for speech recognition results, use <see cref="P:Microsoft.CognitiveServices.Speech.SpeechConfig.SpeechSynthesisOutputFormat"/> 
            and <see cref="M:Microsoft.CognitiveServices.Speech.SpeechConfig.SetSpeechSynthesisOutputFormat(Microsoft.CognitiveServices.Speech.SpeechSynthesisOutputFormat)"/> to get/set synthesized audio output format.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.SpeechConfig.EndpointId">
            <summary>
            Sets the endpoint ID of a customized speech model that is used for speech recognition.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.SpeechConfig.SpeechSynthesisLanguage">
            <summary>
            Gets/sets the speech synthesis language, e.g. en-US
            Added in version 1.4.0
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.SpeechConfig.SpeechSynthesisVoiceName">
            <summary>
            Gets/sets the speech synthesis voice name
            Added in version 1.4.0
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.SpeechConfig.SpeechSynthesisOutputFormat">
            <summary>
            Gets the speech synthesis output format
            Added in version 1.4.0
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeechConfig.SetSpeechSynthesisOutputFormat(Microsoft.CognitiveServices.Speech.SpeechSynthesisOutputFormat)">
            <summary>
            Sets the speech synthesis output format.
            Added in version 1.4.0
            </summary>
            <param name="format">The synthesis output format ID (e.g. Riff16Khz16BitMonoPcm).</param>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeechConfig.SetProxy(System.String,System.Int32,System.String,System.String)">
             <summary>
             Sets proxy configuration.
             Added in version 1.1.0
            
             Note: Proxy functionality is not available on macOS. This function will have no effect on this platform.
             </summary>
             <param name="proxyHostName">The host name of the proxy server, without the protocol scheme (http://)</param>
             <param name="proxyPort">The port number of the proxy server.</param>
             <param name="proxyUserName">The user name of the proxy server.</param>
             <param name="proxyPassword">The password of the proxy server.</param>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeechConfig.SetProxy(System.String,System.Int32)">
            <summary>
            Sets proxy configuration.
            Added in version 1.3.0
            </summary>
            <param name="proxyHostName">The host name of the proxy server.</param>
            <param name="proxyPort">The port number of the proxy server.</param>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeechConfig.SetProperty(System.String,System.String)">
            <summary>
            Sets the property by name.
            </summary>
            <param name="name">Name of the property</param>
            <param name="value">Value of the property</param>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeechConfig.SetProperty(Microsoft.CognitiveServices.Speech.PropertyId,System.String)">
            <summary>
            Sets the property by propertyId
            Added in version 1.3.0.
            </summary>
            <param name="id">PropertyId of the property</param>
            <param name="value">Value of the property</param>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeechConfig.GetProperty(System.String)">
            <summary>
            Gets the property by name.
            </summary>
            <param name="name">Name of the property</param>
            <returns>Value of the property</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeechConfig.GetProperty(Microsoft.CognitiveServices.Speech.PropertyId)">
            <summary>
            Gets the property by propertyId
            Added in version 1.3.0.
            </summary>
            <param name="id">PropertyId of the property</param>
            <returns>Value of the property</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeechConfig.SetServiceProperty(System.String,System.String,Microsoft.CognitiveServices.Speech.ServicePropertyChannel)">
            <summary>
            Sets a property value that will be passed to service using the specified channel.
            Added in version 1.5.0.
            </summary>
            <param name="name">The property name.</param>
            <param name="value">The property value.</param>
            <param name="channel">The channel used to pass the specified property to service.</param>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeechConfig.SetProfanity(Microsoft.CognitiveServices.Speech.ProfanityOption)">
            <summary>
            Sets profanity option.
            Added in version 1.5.0.
            </summary>
            <param name="profanity">The property option to set.</param>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeechConfig.EnableAudioLogging">
            <summary>
            Enable audio logging in service.
            Added in version 1.5.0.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeechConfig.RequestWordLevelTimestamps">
            <summary>
            Includes word-level timestamps.
            Added in version 1.5.0.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeechConfig.EnableDictation">
            <summary>
            Enable dictation. Only supported in speech continuous recognition.
            Added in version 1.5.0.
            </summary>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.SpeechRecognitionResult">
            <summary>
            Defines result of speech recognition.
            </summary>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.SpeechRecognitionEventArgs">
            <summary>
            Define payload of speech recognizing/recognized events.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.SpeechRecognitionEventArgs.Result">
            <summary>
            Specifies the recognition result.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeechRecognitionEventArgs.ToString">
            <summary>
            Returns a string that represents the speech recognition result event.
            </summary>
            <returns>A string that represents the speech recognition result event.</returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.SpeechRecognitionCanceledEventArgs">
            <summary>
            Define payload of speech recognition canceled result events.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.SpeechRecognitionCanceledEventArgs.Reason">
            <summary>
            The reason the recognition was canceled.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.SpeechRecognitionCanceledEventArgs.ErrorCode">
            <summary>
            The error code in case of an unsuccessful recognition (<see cref="P:Microsoft.CognitiveServices.Speech.SpeechRecognitionCanceledEventArgs.Reason"/> is set to Error).
            If Reason is not Error, ErrorCode returns NoError.
            Added in version 1.1.0.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.SpeechRecognitionCanceledEventArgs.ErrorDetails">
            <summary>
            The error message in case of an unsuccessful recognition (<see cref="P:Microsoft.CognitiveServices.Speech.SpeechRecognitionCanceledEventArgs.Reason"/> is set to Error).
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeechRecognitionCanceledEventArgs.ToString">
            <summary>
            Returns a string that represents the speech recognition result event.
            </summary>
            <returns>A string that represents the speech recognition result event.</returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.SpeechRecognitionResultExtensions">
            <summary>
            Extension methods for speech recognition result
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeechRecognitionResultExtensions.Best(Microsoft.CognitiveServices.Speech.SpeechRecognitionResult)">
            <summary>
            Returns best possible recognitions for the result if the recognizer
            was created with detailed output format.
            </summary>
            <param name="result">Recognition result.</param>
            <returns>A collection of best recognitions.</returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.SpeechRecognizer">
             <summary>
             Performs speech recognition from microphone, file, or other audio input streams, and gets transcribed text as result.
             </summary>
             <example>
             An example to use the speech recognizer from microphone and listen to events generated by the recognizer.
             <code>
             public async Task SpeechContinuousRecognitionAsync()
             {
                 // Creates an instance of a speech config with specified subscription key and service region.
                 // Replace with your own subscription key and service region (e.g., "westus").
                 var config = SpeechConfig.FromSubscription("YourSubscriptionKey", "YourServiceRegion");
            
                 // Creates a speech recognizer from microphone.
                 using (var recognizer = new SpeechRecognizer(config))
                 {
                     // Subscribes to events.
                     recognizer.Recognizing += (s, e) => {
                         Console.WriteLine($"RECOGNIZING: Text={e.Result.Text}");
                     };
            
                     recognizer.Recognized += (s, e) => {
                         var result = e.Result;
                         Console.WriteLine($"Reason: {result.Reason.ToString()}");
                         if (result.Reason == ResultReason.RecognizedSpeech)
                         {
                                 Console.WriteLine($"Final result: Text: {result.Text}.");
                         }
                     };
            
                     recognizer.Canceled += (s, e) => {
                         Console.WriteLine($"\n    Recognition Canceled. Reason: {e.Reason.ToString()}, CanceledReason: {e.Reason}");
                     };
            
                     recognizer.SessionStarted += (s, e) => {
                         Console.WriteLine("\n    Session started event.");
                     };
            
                     recognizer.SessionStopped += (s, e) => {
                         Console.WriteLine("\n    Session stopped event.");
                     };
            
                     // Starts continuous recognition. Uses StopContinuousRecognitionAsync() to stop recognition.
                     await recognizer.StartContinuousRecognitionAsync().ConfigureAwait(false);
            
                     do
                     {
                         Console.WriteLine("Press Enter to stop");
                     } while (Console.ReadKey().Key != ConsoleKey.Enter);
            
                     // Stops recognition.
                     await recognizer.StopContinuousRecognitionAsync().ConfigureAwait(false);
                 }
             }
             </code>
             </example>
        </member>
        <member name="E:Microsoft.CognitiveServices.Speech.SpeechRecognizer.Recognizing">
            <summary>
            The event <see cref="E:Microsoft.CognitiveServices.Speech.SpeechRecognizer.Recognizing"/> signals that an intermediate recognition result is received.
            </summary>
        </member>
        <member name="E:Microsoft.CognitiveServices.Speech.SpeechRecognizer.Recognized">
            <summary>
            The event <see cref="E:Microsoft.CognitiveServices.Speech.SpeechRecognizer.Recognized"/> signals that a final recognition result is received.
            </summary>
        </member>
        <member name="E:Microsoft.CognitiveServices.Speech.SpeechRecognizer.Canceled">
            <summary>
            The event <see cref="E:Microsoft.CognitiveServices.Speech.SpeechRecognizer.Canceled"/> signals that the speech recognition was canceled.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeechRecognizer.#ctor(Microsoft.CognitiveServices.Speech.SpeechConfig)">
            <summary>
            Creates a new instance of SpeechRecognizer.
            </summary>
            <param name="speechConfig">Speech configuration</param>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeechRecognizer.#ctor(Microsoft.CognitiveServices.Speech.SpeechConfig,Microsoft.CognitiveServices.Speech.Audio.AudioConfig)">
            <summary>
            Creates a new instance of SpeechRecognizer.
            </summary>
            <param name="speechConfig">Speech configuration</param>
            <param name="audioConfig">Audio configuration</param>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeechRecognizer.#ctor(Microsoft.CognitiveServices.Speech.SpeechConfig,System.String)">
            <summary>
            Creates a new instance of SpeechRecognizer.
            Added in 1.9.0
            </summary>
            <param name="speechConfig">Speech configuration</param>
            <param name="language">The source language</param>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeechRecognizer.#ctor(Microsoft.CognitiveServices.Speech.SpeechConfig,System.String,Microsoft.CognitiveServices.Speech.Audio.AudioConfig)">
            <summary>
            Creates a new instance of SpeechRecognizer.
            Added in 1.9.0
            </summary>
            <param name="speechConfig">Speech configuration</param>
            <param name="language">The source language</param>
            <param name="audioConfig">Audio configuration</param>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeechRecognizer.#ctor(Microsoft.CognitiveServices.Speech.SpeechConfig,Microsoft.CognitiveServices.Speech.SourceLanguageConfig)">
            <summary>
            Creates a new instance of SpeechRecognizer.
            Added in 1.9.0
            </summary>
            <param name="speechConfig">Speech configuration</param>
            <param name="sourceLanguageConfig">The source language config</param>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeechRecognizer.#ctor(Microsoft.CognitiveServices.Speech.SpeechConfig,Microsoft.CognitiveServices.Speech.SourceLanguageConfig,Microsoft.CognitiveServices.Speech.Audio.AudioConfig)">
            <summary>
            Creates a new instance of SpeechRecognizer.
            Added in 1.9.0
            </summary>
            <param name="speechConfig">Speech configuration</param>
            <param name="sourceLanguageConfig">The source language config</param>
            <param name="audioConfig">Audio configuration</param>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeechRecognizer.#ctor(Microsoft.CognitiveServices.Speech.SpeechConfig,Microsoft.CognitiveServices.Speech.AutoDetectSourceLanguageConfig)">
            <summary>
            Creates a new instance of SpeechRecognizer.
            Added in 1.9.0
            </summary>
            <param name="speechConfig">Speech configuration</param>
            <param name="autoDetectSourceLanguageConfig">The auto detect source language config</param>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeechRecognizer.#ctor(Microsoft.CognitiveServices.Speech.SpeechConfig,Microsoft.CognitiveServices.Speech.AutoDetectSourceLanguageConfig,Microsoft.CognitiveServices.Speech.Audio.AudioConfig)">
            <summary>
            Creates a new instance of SpeechRecognizer.
            Added in 1.9.0
            </summary>
            <param name="speechConfig">Speech configuration</param>
            <param name="autoDetectSourceLanguageConfig">The auto detect source language config</param>
            <param name="audioConfig">Audio configuration</param>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.SpeechRecognizer.EndpointId">
            <summary>
            Gets the endpoint ID of a customized speech model that is used for speech recognition.
            </summary>
            <returns>the endpoint ID of a customized speech model that is used for speech recognition</returns>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.SpeechRecognizer.AuthorizationToken">
            <summary>
            Gets/sets authorization token used to communicate with the service.
            Note: The caller needs to ensure that the authorization token is valid. Before the authorization token
            expires, the caller needs to refresh it by calling this setter with a new valid token.
            Otherwise, the recognizer will encounter errors during recognition.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.SpeechRecognizer.SpeechRecognitionLanguage">
            <summary>
            Gets the language name that was set when the recognizer was created.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.SpeechRecognizer.OutputFormat">
            <summary>
            Gets the output format setting.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.SpeechRecognizer.Properties">
            <summary>
            The collection of properties and their values defined for this <see cref="T:Microsoft.CognitiveServices.Speech.SpeechRecognizer"/>.
            Note: The property collection is only valid until the recognizer owning this Properties is disposed or finalized.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeechRecognizer.RecognizeOnceAsync">
             <summary>
             Starts speech recognition, and returns after a single utterance is recognized. The end of a
             single utterance is determined by listening for silence at the end or until a maximum of 15
             seconds of audio is processed.  The task returns the recognition text as result.
             Note: Since RecognizeOnceAsync() returns only a single utterance, it is suitable only for single
             shot recognition like command or query.
             For long-running multi-utterance recognition, use StartContinuousRecognitionAsync() instead.
             </summary>
             <returns>A task representing the recognition operation. The task returns a value of <see cref="T:Microsoft.CognitiveServices.Speech.SpeechRecognitionResult"/> </returns>
             <example>
             The following example creates a speech recognizer, and then gets and prints the recognition result.
             <code>
             public async Task SpeechSingleShotRecognitionAsync()
             {
                 // Creates an instance of a speech config with specified subscription key and service region.
                 // Replace with your own subscription key and service region (e.g., "westus").
                 var config = SpeechConfig.FromSubscription("YourSubscriptionKey", "YourServiceRegion");
            
                 // Creates a speech recognizer using microphone as audio input. The default language is "en-us".
                 using (var recognizer = new SpeechRecognizer(config))
                 {
                     Console.WriteLine("Say something...");
            
                     // Starts speech recognition, and returns after a single utterance is recognized. The end of a
                     // single utterance is determined by listening for silence at the end or until a maximum of 15
                     // seconds of audio is processed.  The task returns the recognition text as result.
                     // Note: Since RecognizeOnceAsync() returns only a single utterance, it is suitable only for single
                     // shot recognition like command or query.
                     // For long-running multi-utterance recognition, use StartContinuousRecognitionAsync() instead.
                     var result = await recognizer.RecognizeOnceAsync();
            
                     // Checks result.
                     if (result.Reason == ResultReason.RecognizedSpeech)
                     {
                         Console.WriteLine($"RECOGNIZED: Text={result.Text}");
                     }
                     else if (result.Reason == ResultReason.NoMatch)
                     {
                         Console.WriteLine($"NOMATCH: Speech could not be recognized.");
                     }
                     else if (result.Reason == ResultReason.Canceled)
                     {
                         var cancellation = CancellationDetails.FromResult(result);
                         Console.WriteLine($"CANCELED: Reason={cancellation.Reason}");
            
                         if (cancellation.Reason == CancellationReason.Error)
                         {
                             Console.WriteLine($"CANCELED: ErrorCode={cancelation.ErrorCode}");
                             Console.WriteLine($"CANCELED: ErrorDetails={cancellation.ErrorDetails}");
                             Console.WriteLine($"CANCELED: Did you update the subscription info?");
                         }
                     }
                 }
             }
             </code>
             </example>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeechRecognizer.StartContinuousRecognitionAsync">
            <summary>
            Starts speech recognition on a continuous audio stream, until StopContinuousRecognitionAsync() is called.
            User must subscribe to events to receive recognition results.
            </summary>
            <returns>A task representing the asynchronous operation that starts the recognition.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeechRecognizer.StopContinuousRecognitionAsync">
            <summary>
            Stops continuous speech recognition.
            </summary>
            <returns>A task representing the asynchronous operation that stops the recognition.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeechRecognizer.StartKeywordRecognitionAsync(Microsoft.CognitiveServices.Speech.KeywordRecognitionModel)">
            <summary>
            Starts speech recognition on a continuous audio stream with keyword spotting, until StopKeywordRecognitionAsync() is called.
            User must subscribe to events to receive recognition results.
            </summary>
            Note: Keyword spotting (KWS) functionality might work with any microphone type, official KWS support, however, is currently limited to the microphone arrays found in the Azure Kinect DK hardware or the Speech Devices SDK.
            <param name="model">The keyword recognition model that specifies the keyword to be recognized.</param>
            <returns>A task representing the asynchronous operation that starts the recognition.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeechRecognizer.StopKeywordRecognitionAsync">
            <summary>
            Stops continuous speech recognition with keyword spotting.
            </summary>
            Note: Keyword spotting (KWS) functionality might work with any microphone type, official KWS support, however, is currently limited to the microphone arrays found in the Azure Kinect DK hardware or the Speech Devices SDK.
            <returns>A task representing the asynchronous operation that stops the recognition.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeechRecognizer.Dispose(System.Boolean)">
            <summary>
            This method performs cleanup of resources.
            The Boolean parameter <paramref name="disposing"/> indicates whether the method is called from <see cref="M:System.IDisposable.Dispose"/> (if <paramref name="disposing"/> is true) or from the finalizer (if <paramref name="disposing"/> is false).
            Derived classes should override this method to dispose resource if needed.
            </summary>
            <param name="disposing">Flag to request disposal.</param>
            <returns></returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.SpeechSynthesisOutputFormat">
            <summary>
            Defines the possible speech synthesis output audio format.
            Added in version 1.4.0
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.SpeechSynthesisOutputFormat.Raw8Khz8BitMonoMULaw">
            <summary>
            raw-8khz-8bit-mono-mulaw
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.SpeechSynthesisOutputFormat.Riff16Khz16KbpsMonoSiren">
            <summary>
            riff-16khz-16kbps-mono-siren
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.SpeechSynthesisOutputFormat.Audio16Khz16KbpsMonoSiren">
            <summary>
            audio-16khz-16kbps-mono-siren
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.SpeechSynthesisOutputFormat.Audio16Khz32KBitRateMonoMp3">
            <summary>
            audio-16khz-32kbitrate-mono-mp3
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.SpeechSynthesisOutputFormat.Audio16Khz128KBitRateMonoMp3">
            <summary>
            audio-16khz-128kbitrate-mono-mp3
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.SpeechSynthesisOutputFormat.Audio16Khz64KBitRateMonoMp3">
            <summary>
            audio-16khz-64kbitrate-mono-mp3
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.SpeechSynthesisOutputFormat.Audio24Khz48KBitRateMonoMp3">
            <summary>
            audio-24khz-48kbitrate-mono-mp3
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.SpeechSynthesisOutputFormat.Audio24Khz96KBitRateMonoMp3">
            <summary>
            audio-24khz-96kbitrate-mono-mp3
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.SpeechSynthesisOutputFormat.Audio24Khz160KBitRateMonoMp3">
            <summary>
            audio-24khz-160kbitrate-mono-mp3
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.SpeechSynthesisOutputFormat.Raw16Khz16BitMonoTrueSilk">
            <summary>
            raw-16khz-16bit-mono-truesilk
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.SpeechSynthesisOutputFormat.Riff16Khz16BitMonoPcm">
            <summary>
            riff-16khz-16bit-mono-pcm
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.SpeechSynthesisOutputFormat.Riff8Khz16BitMonoPcm">
            <summary>
            riff-8khz-16bit-mono-pcm
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.SpeechSynthesisOutputFormat.Riff24Khz16BitMonoPcm">
            <summary>
            riff-24khz-16bit-mono-pcm
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.SpeechSynthesisOutputFormat.Riff8Khz8BitMonoMULaw">
            <summary>
            riff-8khz-8bit-mono-mulaw
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.SpeechSynthesisOutputFormat.Raw16Khz16BitMonoPcm">
            <summary>
            raw-16khz-16bit-mono-pcm
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.SpeechSynthesisOutputFormat.Raw24Khz16BitMonoPcm">
            <summary>
            raw-24khz-16bit-mono-pcm
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.SpeechSynthesisOutputFormat.Raw8Khz16BitMonoPcm">
            <summary>
            raw-8khz-16bit-mono-pcm
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.SpeechSynthesisOutputFormat.Ogg16Khz16BitMonoOpus">
            <summary>
            ogg-16khz-16bit-mono-opus
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.SpeechSynthesisOutputFormat.Ogg24Khz16BitMonoOpus">
            <summary>
            ogg-24khz-16bit-mono-opus
            </summary>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.SpeechSynthesisResult">
            <summary>
            Contains detailed information about result of a speech synthesis operation.
            Added in version 1.4.0
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.SpeechSynthesisResult.ResultId">
            <summary>
            Specifies unique ID of speech synthesis result.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.SpeechSynthesisResult.Reason">
            <summary>
            Specifies status of speech synthesis result.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.SpeechSynthesisResult.AudioData">
            <summary>
            Presents the synthesized audio in the result.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.SpeechSynthesisResult.Properties">
            <summary>
            Contains properties of the results.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeechSynthesisResult.Dispose">
            <summary>
            Dispose of associated resources.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeechSynthesisResult.Dispose(System.Boolean)">
            <summary>
            This method performs cleanup of resources.
            The Boolean parameter <paramref name="disposing"/> indicates whether the method is called from <see cref="M:System.IDisposable.Dispose"/> (if <paramref name="disposing"/> is true) or from the finalizer (if <paramref name="disposing"/> is false).
            Derived classes should override this method to dispose resource if needed.
            </summary>
            <param name="disposing">Flag to request disposal.</param>
            <returns></returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.SpeechSynthesisCancellationDetails">
            <summary>
            Contains detailed information about why a speech synthesis result was canceled.
            Added in version 1.4.0
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeechSynthesisCancellationDetails.FromResult(Microsoft.CognitiveServices.Speech.SpeechSynthesisResult)">
            <summary>
            Creates an instance of SpeechSynthesisCancellationDetails object for the canceled SpeechSynthesisResult.
            </summary>
            <param name="result">The result that was canceled.</param>
            <returns>The CancellationDetails object being created.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeechSynthesisCancellationDetails.FromStream(Microsoft.CognitiveServices.Speech.AudioDataStream)">
            <summary>
            Creates an instance of SpeechSynthesisCancellationDetails object for the canceled AudioDataStream.
            </summary>
            <param name="stream">The stream that was canceled</param>
            <returns>The CancellationDetails object being created.</returns>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.SpeechSynthesisCancellationDetails.Reason">
            <summary>
            The reason the synthesis was canceled.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.SpeechSynthesisCancellationDetails.ErrorCode">
            <summary>
            The error code in case of an unsuccessful synthesis (<see cref="P:Microsoft.CognitiveServices.Speech.SpeechSynthesisCancellationDetails.Reason"/> is set to Error).
            If Reason is not Error, ErrorCode returns NoError.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.SpeechSynthesisCancellationDetails.ErrorDetails">
            <summary>
            The error message in case of an unsuccessful synthesis (<see cref="P:Microsoft.CognitiveServices.Speech.SpeechSynthesisCancellationDetails.Reason"/> is set to Error).
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeechSynthesisCancellationDetails.ToString">
            <summary>
            Returns a string that represents the cancellation details.
            </summary>
            <returns>A string that represents the cancellation details.</returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.SpeechSynthesisEventArgs">
            <summary>
            Define payload of speech synthesis events.
            Added in version 1.4.0
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.SpeechSynthesisEventArgs.Result">
            <summary>
            Specifies the synthesis result.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeechSynthesisEventArgs.Dispose">
            <summary>
            Dispose of associated resources.
            </summary>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.SpeechSynthesisWordBoundaryEventArgs">
            <summary>
            Define payload of speech synthesis events.
            Added in version 1.7.0
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.SpeechSynthesisWordBoundaryEventArgs.AudioOffset">
            <summary>
            Specifies current word's binary offset in output audio, by ticks (100ns).
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.SpeechSynthesisWordBoundaryEventArgs.TextOffset">
            <summary>
            Specifies current word's text offset in input text, by characters.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.SpeechSynthesisWordBoundaryEventArgs.WordLength">
            <summary>
            Specifies current word's length, by characters.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeechSynthesisWordBoundaryEventArgs.Dispose">
            <summary>
            Dispose of associated resources.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeechSynthesisWordBoundaryEventArgs.Dispose(System.Boolean)">
            <summary>
            This method performs cleanup of resources.
            The Boolean parameter <paramref name="disposing"/> indicates whether the method is called from <see cref="M:System.IDisposable.Dispose"/> (if <paramref name="disposing"/> is true) or from the finalizer (if <paramref name="disposing"/> is false).
            Derived classes should override this method to dispose resource if needed.
            </summary>
            <param name="disposing">Flag to request disposal.</param>
            <returns></returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.SpeechSynthesizer">
            <summary>
            Performs speech synthesis to speaker, file, or other audio output streams, and gets synthesized audio as result.
            Updated in version 1.7.0
            </summary>
        </member>
        <member name="E:Microsoft.CognitiveServices.Speech.SpeechSynthesizer.SynthesisStarted">
            <summary>
            The event <see cref="E:Microsoft.CognitiveServices.Speech.SpeechSynthesizer.SynthesisStarted"/> signals that the speech synthesis has started.
            </summary>
        </member>
        <member name="E:Microsoft.CognitiveServices.Speech.SpeechSynthesizer.Synthesizing">
            <summary>
            The event <see cref="E:Microsoft.CognitiveServices.Speech.SpeechSynthesizer.Synthesizing"/> signals that the speech synthesis is on going.
            </summary>
        </member>
        <member name="E:Microsoft.CognitiveServices.Speech.SpeechSynthesizer.SynthesisCompleted">
            <summary>
            The event <see cref="E:Microsoft.CognitiveServices.Speech.SpeechSynthesizer.SynthesisCompleted"/> signals that the speech synthesis has completed.
            </summary>
        </member>
        <member name="E:Microsoft.CognitiveServices.Speech.SpeechSynthesizer.SynthesisCanceled">
            <summary>
            The event <see cref="E:Microsoft.CognitiveServices.Speech.SpeechSynthesizer.SynthesisCanceled"/> signals that the speech synthesis was canceled.
            </summary>
        </member>
        <member name="E:Microsoft.CognitiveServices.Speech.SpeechSynthesizer.WordBoundary">
            <summary>
            The event <see cref="E:Microsoft.CognitiveServices.Speech.SpeechSynthesizer.WordBoundary"/> signals that a word boundary was received.
            Added in version 1.7.0
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeechSynthesizer.#ctor(Microsoft.CognitiveServices.Speech.SpeechConfig)">
            <summary>
            Creates a new instance of SpeechSynthesizer.
            </summary>
            <param name="speechConfig">Speech configuration</param>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeechSynthesizer.#ctor(Microsoft.CognitiveServices.Speech.SpeechConfig,Microsoft.CognitiveServices.Speech.Audio.AudioConfig)">
            <summary>
            Creates a new instance of SpeechSynthesizer.
            </summary>
            <param name="speechConfig">Speech configuration</param>
            <param name="audioConfig">Audio configuration</param>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeechSynthesizer.#ctor(Microsoft.CognitiveServices.Speech.SpeechConfig,Microsoft.CognitiveServices.Speech.AutoDetectSourceLanguageConfig,Microsoft.CognitiveServices.Speech.Audio.AudioConfig)">
            <summary>
            Creates a new instance of SpeechSynthesizer.
            Added in 1.13.0
            </summary>
            <param name="speechConfig">Speech configuration</param>
            <param name="autoDetectSourceLanguageConfig">The auto detect source language config</param>
            <param name="audioConfig">Audio configuration</param>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.SpeechSynthesizer.Properties">
            <summary>
            The collection of properties and their values defined for this <see cref="T:Microsoft.CognitiveServices.Speech.SpeechSynthesizer"/>.
            Note: The property collection is only valid until the SpeechSynthesizer owning this Properties is disposed or finalized.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.SpeechSynthesizer.AuthorizationToken">
            <summary>
            Gets/sets authorization token used to communicate with the service.
            Note: The caller needs to ensure that the authorization token is valid. Before the authorization token
            expires, the caller needs to refresh it by calling this setter with a new valid token.
            Otherwise, the synthesizer will encounter errors while speech synthesis.
            Added in version 1.7.0
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeechSynthesizer.SpeakTextAsync(System.String)">
            <summary>
            Execute the speech synthesis on plain text, asynchronously.
            </summary>
            <param name="text">The plain text for synthesis.</param>
            <returns>A task representing the synthesis operation. The task returns a value of SpeechSynthesisResult.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeechSynthesizer.SpeakSsmlAsync(System.String)">
            <summary>
            Execute the speech synthesis on SSML, asynchronously.
            </summary>
            <param name="ssml">The SSML for synthesis.</param>
            <returns>A task representing the synthesis operation. The task returns a value of SpeechSynthesisResult.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeechSynthesizer.StartSpeakingTextAsync(System.String)">
            <summary>
            Start the speech synthesis on plain text, asynchronously.
            </summary>
            <param name="text">The plain text for synthesis.</param>
            <returns>A task representing the synthesis operation. The task returns a value of SpeechSynthesisResult.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeechSynthesizer.StartSpeakingSsmlAsync(System.String)">
            <summary>
            Start the speech synthesis on SSML, asynchronously.
            </summary>
            <param name="ssml">The SSML for synthesis.</param>
            <returns>A task representing the synthesis operation. The task returns a value of SpeechSynthesisResult.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeechSynthesizer.StopSpeakingAsync">
            <summary>
            Stop synthesis
            This method will stop playback and clear the unread data in <see cref="T:Microsoft.CognitiveServices.Speech.Internal.PullAudioOutputStream"/>.
            </summary>
            <returns>A task representing the asynchronous operation that stops the synthesis.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeechSynthesizer.Dispose">
            <summary>
            Dispose of associated resources.
            </summary>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.SpeechTranslationConfig">
            <summary>
            Speech translation configuration.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeechTranslationConfig.FromSubscription(System.String,System.String)">
            <summary>
            Creates an instance of speech translation config with specified subscription key and region.
            </summary>
            <param name="subscriptionKey">The subscription key, can be empty if authorization token is specified later.</param>
            <param name="region">The region name (see the <a href="https://aka.ms/csspeech/region">region page</a>).</param>
            <returns>A speech config instance.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeechTranslationConfig.FromAuthorizationToken(System.String,System.String)">
            <summary>
            Creates an instance of the speech translation config with specified authorization token and region.
            Note: The caller needs to ensure that the authorization token is valid. Before the authorization token
            expires, the caller needs to refresh it by calling this setter on the corresponding
            recognizer with a new valid token.
            </summary>
            <param name="authorizationToken">The authorization token.</param>
            <param name="region">The region name (see the <a href="https://aka.ms/csspeech/region">region page</a>).</param>
            <returns>A speech config instance.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeechTranslationConfig.FromEndpoint(System.Uri,System.String)">
            <summary>
            Creates an instance of the speech translation config with specified endpoint and subscription key.
            This method is intended only for users who use a non-standard service endpoint or parameters.
            Note: The query parameters specified in the endpoint URI are not changed, even if they are set by any other APIs.
            For example, if the recognition language is defined in URI as query parameter "language=de-DE", and the property SpeechRecognitionLanguage is set to "en-US",
            the language setting in URI takes precedence, and the effective language is "de-DE".
            Only the parameters that are not specified in the endpoint URI can be set by other APIs.
            Note: To use an authorization token with FromEndpoint, use FromEndpoint(System.Uri),
            and then set the AuthorizationToken property on the created SpeechTranslationConfig instance.
            </summary>
            <param name="endpoint">The service endpoint to connect to.</param>
            <param name="subscriptionKey">The subscription key.</param>
            <returns>A SpeechTranslationConfig instance.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeechTranslationConfig.FromEndpoint(System.Uri)">
            <summary>
            Creates an instance of the speech translation config with specified endpoint.
            This method is intended only for users who use a non-standard service endpoint or parameters.
            Note: The query parameters specified in the endpoint URI are not changed, even if they are set by any other APIs.
            For example, if the recognition language is defined in URI as query parameter "language=de-DE", and the property SpeechRecognitionLanguage is set to "en-US",
            the language setting in URI takes precedence, and the effective language is "de-DE".
            Only the parameters that are not specified in the endpoint URI can be set by other APIs.
            Note: If the endpoint requires a subscription key for authentication, use FromEndpoint(System.Uri, string) to pass
            the subscription key as parameter.
            To use an authorization token with FromEndpoint, please use this method to create a SpeechTranslationConfig instance, and then
            set the AuthorizationToken property on the created SpeechTranslationConfig instance.
            Note: Added in version 1.5.0.
            </summary>
            <param name="endpoint">The service endpoint to connect to.</param>
            <returns>A SpeechTranslationConfig instance.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeechTranslationConfig.FromHost(System.Uri,System.String)">
            <summary>
            Creates an instance of the speech translation config with specified host and subscription key.
            This method is intended only for users who use a non-default service host. Standard resource path will be assumed.
            For services with a non-standard resource path or no path at all, use FromEndpoint instead.
            Note: Query parameters are not allowed in the host URI and must be set by other APIs.
            Note: To use an authorization token with FromHost, use FromHost(System.Uri),
            and then set the AuthorizationToken property on the created SpeechTranslationConfig instance.
            Note: Added in version 1.8.0.
            </summary>
            <param name="host">The service host to connect to. Format is "protocol://host:port" where ":port" is optional.</param>
            <param name="subscriptionKey">The subscription key.</param>
            <returns>A SpeechTranslationConfig instance.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeechTranslationConfig.FromHost(System.Uri)">
            <summary>
            Creates an instance of the speech translation config with specified host.
            This method is intended only for users who use a non-default service host. Standard resource path will be assumed.
            For services with a non-standard resource path or no path at all, use FromEndpoint instead.
            Note: Query parameters are not allowed in the host URI and must be set by other APIs.
            Note: If the host requires a subscription key for authentication, use FromHost(System.Uri, string) to pass
            the subscription key as parameter.
            To use an authorization token with FromHost, please use this method to create a SpeechTranslationConfig instance, and then
            set the AuthorizationToken property on the created SpeechTranslationConfig instance.
            Note: Added in version 1.8.0.
            </summary>
            <param name="host">The service host to connect to. Format is "protocol://host:port" where ":port" is optional.</param>
            <returns>A SpeechTranslationConfig instance.</returns>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.SpeechTranslationConfig.TargetLanguages">
            <summary>
            Gets a collection of languages to translate to.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeechTranslationConfig.AddTargetLanguage(System.String)">
            <summary>
            Adds a target languages of translation.
            In case when speech synthesis is used and several target languages are specified for translation,
            the speech will be synthesized only for the first language.
            </summary>
            <param name="language"></param>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.SpeechTranslationConfig.RemoveTargetLanguage(System.String)">
            <summary>
            Removes a target languages of translation.
            Added in version 1.7.0.
            </summary>
            <param name="language"></param>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.SpeechTranslationConfig.VoiceName">
            <summary>
            Specifies the name of voice tag if a synthesized audio output is desired.
            </summary>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.StreamStatus">
            <summary>
            Defines the possible status of audio data stream.
            Added in version 1.4.0
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.StreamStatus.Unknown">
            <summary>
            The audio data stream status is unknown
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.StreamStatus.NoData">
            <summary>
            The audio data stream contains no data
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.StreamStatus.PartialData">
            <summary>
            The audio data stream contains partial data of a speak request
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.StreamStatus.AllData">
            <summary>
            The audio data stream contains all data of a speak request
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.StreamStatus.Canceled">
            <summary>
            The audio data stream was cancelled
            </summary>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.Translation.TranslationRecognitionResult">
            <summary>
            Defines a translation result.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Translation.TranslationRecognitionResult.Translations">
            <summary>
            Presents the translation results. Each item in the dictionary represents translation result in one of target languages, where the key
            is the name of the target language, in BCP-47 format, and the value is the translation text in the specified language.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Translation.TranslationRecognitionResult.ToString">
            <summary>
            Returns a string that represents the speech recognition result.
            </summary>
            <returns>A string that represents the speech recognition result.</returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.Translation.TranslationRecognizer">
             <summary>
             Performs translation on the speech input.
             </summary>
             <example>
             An example to use the translation recognizer from microphone and listen to events generated by the recognizer.
             <code>
             public async Task TranslationContinuousRecognitionAsync()
             {
                 // Creates an instance of a speech translation config with specified subscription key and service region.
                 // Replace with your own subscription key and service region (e.g., "westus").
                 var config = SpeechTranslationConfig.FromSubscription("YourSubscriptionKey", "YourServiceRegion");
            
                 // Sets source and target languages.
                 string fromLanguage = "en-US";
                 config.SpeechRecognitionLanguage = fromLanguage;
                 config.AddTargetLanguage("de");
            
                 // Sets voice name of synthesis output.
                 const string GermanVoice = "Microsoft Server Speech Text to Speech Voice (de-DE, Hedda)";
                 config.VoiceName = GermanVoice;
                 // Creates a translation recognizer using microphone as audio input.
                 using (var recognizer = new TranslationRecognizer(config))
                 {
                     // Subscribes to events.
                     recognizer.Recognizing += (s, e) =&gt;
                     {
                         Console.WriteLine($"RECOGNIZING in '{fromLanguage}': Text={e.Result.Text}");
                         foreach (var element in e.Result.Translations)
                         {
                             Console.WriteLine($"    TRANSLATING into '{element.Key}': {element.Value}");
                         }
                     };
            
                     recognizer.Recognized += (s, e) =&gt;
                     {
                         if (e.Result.Reason == ResultReason.TranslatedSpeech)
                         {
                             Console.WriteLine($"\nFinal result: Reason: {e.Result.Reason.ToString()}, recognized text in {fromLanguage}: {e.Result.Text}.");
                             foreach (var element in e.Result.Translations)
                             {
                                 Console.WriteLine($"    TRANSLATING into '{element.Key}': {element.Value}");
                             }
                         }
                     };
            
                     recognizer.Synthesizing += (s, e) =&gt;
                     {
                         var audio = e.Result.GetAudio();
                         Console.WriteLine(audio.Length != 0
                             ? $"AudioSize: {audio.Length}"
                             : $"AudioSize: {audio.Length} (end of synthesis data)");
                     };
            
                     recognizer.Canceled += (s, e) =&gt;
                     {
                         Console.WriteLine($"\nRecognition canceled. Reason: {e.Reason}; ErrorDetails: {e.ErrorDetails}");
                     };
            
                     recognizer.SessionStarted += (s, e) =&gt;
                     {
                         Console.WriteLine("\nSession started event.");
                     };
            
                     recognizer.SessionStopped += (s, e) =&gt;
                     {
                         Console.WriteLine("\nSession stopped event.");
                     };
            
                     // Starts continuous recognition. Uses StopContinuousRecognitionAsync() to stop recognition.
                     Console.WriteLine("Say something...");
                     await recognizer.StartContinuousRecognitionAsync().ConfigureAwait(false);
            
                     do
                     {
                         Console.WriteLine("Press Enter to stop");
                     } while (Console.ReadKey().Key != ConsoleKey.Enter);
            
                     // Stops continuous recognition.
                     await recognizer.StopContinuousRecognitionAsync().ConfigureAwait(false);
                 }
             }
             </code>
             </example>
        </member>
        <member name="E:Microsoft.CognitiveServices.Speech.Translation.TranslationRecognizer.Recognizing">
            <summary>
            The event <see cref="E:Microsoft.CognitiveServices.Speech.Translation.TranslationRecognizer.Recognizing"/> signals that an intermediate recognition result is received.
            </summary>
        </member>
        <member name="E:Microsoft.CognitiveServices.Speech.Translation.TranslationRecognizer.Recognized">
            <summary>
            The event <see cref="E:Microsoft.CognitiveServices.Speech.Translation.TranslationRecognizer.Recognized"/> signals that a final recognition result is received.
            </summary>
        </member>
        <member name="E:Microsoft.CognitiveServices.Speech.Translation.TranslationRecognizer.Canceled">
            <summary>
            The event <see cref="E:Microsoft.CognitiveServices.Speech.Translation.TranslationRecognizer.Canceled"/> signals that the speech to text/synthesis translation was canceled.
            </summary>
        </member>
        <member name="E:Microsoft.CognitiveServices.Speech.Translation.TranslationRecognizer.Synthesizing">
            <summary>
            The event <see cref="E:Microsoft.CognitiveServices.Speech.Translation.TranslationRecognizer.Synthesizing"/> signals that a translation synthesis result is received.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Translation.TranslationRecognizer.#ctor(Microsoft.CognitiveServices.Speech.SpeechTranslationConfig)">
            <summary>
            Creates a translation recognizer using the default microphone input for a specified translation configuration.
            </summary>
            <param name="config">Translation config.</param>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Translation.TranslationRecognizer.#ctor(Microsoft.CognitiveServices.Speech.SpeechTranslationConfig,Microsoft.CognitiveServices.Speech.Audio.AudioConfig)">
            <summary>
            Creates a translation recognizer using the specified speech translator and audio configuration.
            </summary>
            <param name="config">Translation config.</param>
            <param name="audioConfig">Audio config.</param>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Translation.TranslationRecognizer.SpeechRecognitionLanguage">
            <summary>
            Gets the language name that was set when the recognizer was created.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Translation.TranslationRecognizer.TargetLanguages">
            <summary>
            Gets target languages for translation that were set when the recognizer was created.
            The language is specified in BCP-47 format. The translation will provide translated text for each of language.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Translation.TranslationRecognizer.VoiceName">
            <summary>
            Gets the name of output voice if speech synthesis is used.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Translation.TranslationRecognizer.Properties">
            <summary>
            The collection of properties and their values defined for this <see cref="T:Microsoft.CognitiveServices.Speech.Translation.TranslationRecognizer"/>.
            Note: The property collection is only valid until the recognizer owning this Properties is disposed or finalized.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Translation.TranslationRecognizer.AuthorizationToken">
            <summary>
            Gets/sets authorization token used to communicate with the service.
            Note: The caller needs to ensure that the authorization token is valid. Before the authorization token
            expires, the caller needs to refresh it by calling this setter with a new valid token.
            Otherwise, the recognizer will encounter errors during recognition.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Translation.TranslationRecognizer.AddTargetLanguage(System.String)">
            <summary>
            Adds a target language for translation.
            Added in version 1.7.0.
            </summary>
            <param name="language">Translation target language to add.</param>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Translation.TranslationRecognizer.RemoveTargetLanguage(System.String)">
            <summary>
            Removes a target language for translation.
            Added in version 1.7.0.
            </summary>
            <param name="language">Translation target language to remove.</param>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Translation.TranslationRecognizer.RecognizeOnceAsync">
             <summary>
             Starts speech translation, and returns after a single utterance is recognized. The end of a
             single utterance is determined by listening for silence at the end or until a maximum of 15
             seconds of audio is processed.  The task returns the recognition text as result.
             Note: Since RecognizeOnceAsync() returns only a single utterance, it is suitable only for single
             shot recognition like command or query.
             For long-running multi-utterance recognition, use StartContinuousRecognitionAsync() instead.
             </summary>
             <returns>A task representing the recognition operation. The task returns a value of <see cref="T:Microsoft.CognitiveServices.Speech.Translation.TranslationRecognitionResult"/> </returns>
             <example>
             Create a translation recognizer, get and print the recognition result
             <code>
             public async Task TranslationSingleShotRecognitionAsync()
             {
                 // Creates an instance of a speech translation config with specified subscription key and service region.
                 // Replace with your own subscription key and service region (e.g., "westus").
                 var config = SpeechTranslationConfig.FromSubscription("YourSubscriptionKey", "YourServiceRegion");
            
                 string fromLanguage = "en-US";
                 config.SpeechRecognitionLanguage = fromLanguage;
                 config.AddTargetLanguage("de");
            
                 // Creates a translation recognizer.
                 using (var recognizer = new TranslationRecognizer(config))
                 {
                     // Starts recognizing.
                     Console.WriteLine("Say something...");
            
                     // Starts translation recognition, and returns after a single utterance is recognized. The end of a
                     // single utterance is determined by listening for silence at the end or until a maximum of 15
                     // seconds of audio is processed. The task returns the recognized text as well as the translation.
                     // Note: Since RecognizeOnceAsync() returns only a single utterance, it is suitable only for single
                     // shot recognition like command or query.
                     // For long-running multi-utterance recognition, use StartContinuousRecognitionAsync() instead.
                     var result = await recognizer.RecognizeOnceAsync();
            
                     if (result.Reason == ResultReason.TranslatedSpeech)
                     {
                         Console.WriteLine($"\nFinal result: Reason: {result.Reason.ToString()}, recognized text: {result.Text}.");
                         foreach (var element in result.Translations)
                         {
                             Console.WriteLine($"    TRANSLATING into '{element.Key}': {element.Value}");
                         }
                     }
                 }
             }
             </code>
             </example>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Translation.TranslationRecognizer.StartContinuousRecognitionAsync">
            <summary>
            Starts recognition and translation on a continous audio stream, until StopContinuousRecognitionAsync() is called.
            User must subscribe to events to receive translation results.
            </summary>
            <returns>A task representing the asynchronous operation that starts the recognition.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Translation.TranslationRecognizer.StopContinuousRecognitionAsync">
            <summary>
            Stops continuous recognition and translation.
            </summary>
            <returns>A task representing the asynchronous operation that stops the translation.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Translation.TranslationRecognizer.StartKeywordRecognitionAsync(Microsoft.CognitiveServices.Speech.KeywordRecognitionModel)">
            <summary>
            Starts speech recognition on a continuous audio stream with keyword spotting, until StopKeywordRecognitionAsync() is called.
            User must subscribe to events to receive recognition results.
            </summary>
            Note: Keyword spotting (KWS) functionality might work with any microphone type, official KWS support, however, is currently limited to the microphone arrays found in the Azure Kinect DK hardware or the Speech Devices SDK.
            <param name="model">The keyword recognition model that specifies the keyword to be recognized.</param>
            <returns>A task representing the asynchronous operation that starts the recognition.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Translation.TranslationRecognizer.StopKeywordRecognitionAsync">
            <summary>
            Stops continuous speech recognition with keyword spotting.
            </summary>
            Note: Keyword spotting (KWS) functionality might work with any microphone type, official KWS support, however, is currently limited to the microphone arrays found in the Azure Kinect DK hardware or the Speech Devices SDK.
            <returns>A task representing the asynchronous operation that stops the recognition.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Translation.TranslationRecognizer.Dispose(System.Boolean)">
            <summary>
            Disposes of the object.
            </summary>
            <param name="disposing">True to dispose managed resources.</param>
            <returns></returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.Translation.TranslationSynthesisResult">
            <summary>
            Defines translation synthesis result, i.e. the voice output of the translated text in the target language.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Translation.TranslationSynthesisResult.Reason">
            <summary>
            Indicates the possible reasons a TranslationSynthesisResult might be generated.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Translation.TranslationSynthesisResult.GetAudio">
            <summary>
            The voice output of the translated text in the target language.
            </summary>
            <returns>Synthesized audio data.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Translation.TranslationSynthesisResult.ToString">
            <summary>
            Returns a string that represents the synthesis result.
            </summary>
            <returns>A string that represents the synthesis result.</returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.Translation.TranslationSynthesisEventArgs">
            <summary>
            Define payload of translation synthesis result events.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Translation.TranslationSynthesisEventArgs.Result">
            <summary>
            Specifies the translation synthesis result.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Translation.TranslationSynthesisEventArgs.ToString">
            <summary>
            Returns a string that represents the speech recognition result event.
            </summary>
            <returns>A string that represents the speech recognition result event.</returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.Translation.TranslationRecognitionEventArgs">
            <summary>
            Define payload of translation recognizing/recognized events.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Translation.TranslationRecognitionEventArgs.Result">
            <summary>
            Specifies the recognition result.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Translation.TranslationRecognitionEventArgs.ToString">
            <summary>
            Returns a string that represents the speech recognition result event.
            </summary>
            <returns>A string that represents the speech recognition result event.</returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.Translation.TranslationRecognitionCanceledEventArgs">
            <summary>
            Define payload of translation text result recognition canceled result events.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Translation.TranslationRecognitionCanceledEventArgs.Reason">
            <summary>
            The reason the recognition was canceled.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Translation.TranslationRecognitionCanceledEventArgs.ErrorCode">
            <summary>
            The error code in case of an unsuccessful recognition (<see cref="P:Microsoft.CognitiveServices.Speech.Translation.TranslationRecognitionCanceledEventArgs.Reason"/> is set to Error).
            If Reason is not Error, ErrorCode returns NoError.
            Added in version 1.1.0.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.Translation.TranslationRecognitionCanceledEventArgs.ErrorDetails">
            <summary>
            The error message in case of an unsuccessful recognition (<see cref="P:Microsoft.CognitiveServices.Speech.Translation.TranslationRecognitionCanceledEventArgs.Reason"/> is set to Error).
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.Translation.TranslationRecognitionCanceledEventArgs.ToString">
            <summary>
            Returns a string that represents the speech recognition result event.
            </summary>
            <returns>A string that represents the speech recognition result event.</returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.VoiceProfile">
            <summary>
            A VoiceProfile represents a speaker's uniqueness in his/her voice.
            Added in version 1.12.0
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.VoiceProfile.#ctor(System.String,Microsoft.CognitiveServices.Speech.VoiceProfileType)">
             <summary>
             Creates a VoiceProfile.
             </summary>
             <param name="id">An unique id.</param>
             <param name="type">VoiceProfileType.</param>
            
             <returns></returns>
            
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.VoiceProfile.Id">
            <summary>
            a voice profile id.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.VoiceProfile.Dispose(System.Boolean)">
             <summary>
            
             </summary>
             <param name="disposeManaged"></param>
             <returns></returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.VoiceProfileClient">
            <summary>
            A class for VoiceProfileClient.
            Added in version 1.12.0
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.VoiceProfileClient.#ctor(Microsoft.CognitiveServices.Speech.SpeechConfig)">
             <summary>
             Creates a VoiceProfileClient.
             </summary>
             <param name="speechConfig">The speech configuration to use.</param>
             <returns></returns>
            
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.VoiceProfileClient.Properties">
            <summary>
            Gets the collection of properties and their values defined for this <see cref="T:Microsoft.CognitiveServices.Speech.VoiceProfileClient"/>.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.VoiceProfileClient.CreateProfileAsync(Microsoft.CognitiveServices.Speech.VoiceProfileType,System.String)">
            <summary>
            Create a voice profile.
            </summary>
            <param name="voiceProfileType">A voice profile type.</param>
            <param name="locale">a locale, e.g "en-us"</param>
            <returns>An asynchronous operation representing the result of creating a voice profile.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.VoiceProfileClient.EnrollProfileAsync(Microsoft.CognitiveServices.Speech.VoiceProfile,Microsoft.CognitiveServices.Speech.Audio.AudioConfig)">
            <summary>
            Enroll a voice profile.
            </summary>
            <param name="voiceProfile">A voice profile.</param>
            <param name="audioConfig">An audio config.</param>
            <returns>An asynchronous operation representing the result of enrollment of a voice profile.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.VoiceProfileClient.DeleteProfileAsync(Microsoft.CognitiveServices.Speech.VoiceProfile)">
            <summary>
            Delete a voice profile.
            </summary>
            <param name="voiceProfile">A voice profile.</param>
            <returns> An asynchronous operation representing the result of deleting a voice profile.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.VoiceProfileClient.ResetProfileAsync(Microsoft.CognitiveServices.Speech.VoiceProfile)">
            <summary>
            Reset a voice profile.
            </summary>
            <param name="voiceProfile">A voice profile.</param>
            <returns> An asynchronous operation representing the result of reset a voice profile.</returns>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.VoiceProfileClient.Dispose(System.Boolean)">
             <summary>
            
             </summary>
             <param name="disposeManaged"></param>
             <returns></returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.VoiceProfileEnrollmentResult">
            <summary>
            Contains the result of enrolling a voice profile.
            Added in version 1.12.0
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.VoiceProfileEnrollmentResult.ResultId">
            <summary>
            Specifies the result identifier.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.VoiceProfileEnrollmentResult.Reason">
            <summary>
            Specifies reason of the enrollment result.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.VoiceProfileEnrollmentResult.ProfileId">
            <summary>
            Specifies profile id in the enrollment result.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.VoiceProfileEnrollmentResult.EnrollmentsCount">
            <summary>
            Number of enrollment audios accepted for this profile.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.VoiceProfileEnrollmentResult.EnrollmentsLength">
            <summary>
            The total length of enrollment audios accepted for this profile in hundred nanoseconds.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.VoiceProfileEnrollmentResult.RemainingEnrollmentsCount">
            <summary>
            Number of enrollment audios needed to complete profile enrollment.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.VoiceProfileEnrollmentResult.RemainingEnrollmentsSpeechLength">
            <summary>
            The amount of pure speech (which is the amount of audio after removing silence and non-speech segments) needed to complete profile enrollment in hundred nanoseconds.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.VoiceProfileEnrollmentResult.EnrollmentsSpeechLength">
            <summary>
            The summation of pure speech(which is the amount of audio after removing silence and non - speech segments) across all profile enrollments in hundred nanoseconds.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.VoiceProfileEnrollmentResult.AudioLength">
            <summary>
            This enrollment audio length in hundred nanoseconds.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.VoiceProfileEnrollmentResult.AudioSpeechLength">
            <summary>
            This enrollment audio pure speech(which is the amount of audio after removing silence and non - speech segments) length in hundred nanoseconds.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.VoiceProfileEnrollmentResult.Properties">
            <summary>
            Contains properties of the results.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.VoiceProfileEnrollmentResult.ToString">
            <summary>
            Returns a string that represents the enrollment result.
            </summary>
            <returns>A string that represents the enrollment result.</returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.VoiceProfileEnrollmentCancellationDetails">
            <summary>
            Represents the cancellation details of an enrollment result.
            Added in version 1.12.0.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.VoiceProfileEnrollmentCancellationDetails.FromResult(Microsoft.CognitiveServices.Speech.VoiceProfileEnrollmentResult)">
            <summary>
            Create an object that represents the details of a canceled enrollment result.
            </summary>
            <param name="result">a voice profile enrollment result object.</param>
            <returns>a voice profile enrollment cancellation details object.</returns>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.VoiceProfileEnrollmentCancellationDetails.Reason">
            <summary>
            The reason the enrollment was canceled.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.VoiceProfileEnrollmentCancellationDetails.ErrorCode">
            <summary>
            The error code in case of an unsuccessful enrollment (<see cref="P:Microsoft.CognitiveServices.Speech.VoiceProfileEnrollmentCancellationDetails.Reason"/> is set to Error).
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.VoiceProfileEnrollmentCancellationDetails.ErrorDetails">
            <summary>
            The error message in case of an unsuccessful enrollment (<see cref="P:Microsoft.CognitiveServices.Speech.VoiceProfileEnrollmentCancellationDetails.Reason"/> is set to Error).
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.VoiceProfileEnrollmentCancellationDetails.ToString">
            <summary>
            Returns a string that represents the cancellation details.
            </summary>
            <returns>A string that represents the cancellation details.</returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.VoiceProfileResult">
            <summary>
            Contains the result of processing a voice profile.
            Added in version 1.12.0
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.VoiceProfileResult.ResultId">
            <summary>
            Specifies the result identifier.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.VoiceProfileResult.Reason">
            <summary>
            Specifies the reason of voice profile result.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.VoiceProfileResult.Properties">
            <summary>
            Contains properties of the results.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.VoiceProfileResult.ToString">
            <summary>
            Returns a string that represents the voice profile result.
            </summary>
            <returns>A string that represents the voice profile result.</returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.VoiceProfileCancellationDetails">
            <summary>
            Contains detailed information about why a voice profile action was canceled.
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.VoiceProfileCancellationDetails.FromResult(Microsoft.CognitiveServices.Speech.VoiceProfileResult)">
            <summary>
            Creates an instance of VoiceProfileCancellationDetails object for the canceled VoiceProfileResult.
            </summary>
            <param name="result">The result that was canceled.</param>
            <returns>The CancellationDetails object being created.</returns>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.VoiceProfileCancellationDetails.Reason">
            <summary>
            The reason the voice profile action was canceled.
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.VoiceProfileCancellationDetails.ErrorCode">
            <summary>
            The error code in case of an unsuccessful voice profile action (<see cref="P:Microsoft.CognitiveServices.Speech.VoiceProfileCancellationDetails.Reason"/> is set to Error).
            </summary>
        </member>
        <member name="P:Microsoft.CognitiveServices.Speech.VoiceProfileCancellationDetails.ErrorDetails">
            <summary>
            The error message in case of an unsuccessful voice profile action (<see cref="P:Microsoft.CognitiveServices.Speech.VoiceProfileCancellationDetails.Reason"/> is set to Error).
            </summary>
        </member>
        <member name="M:Microsoft.CognitiveServices.Speech.VoiceProfileCancellationDetails.ToString">
            <summary>
            Returns a string that represents the cancellation details.
            </summary>
            <returns>A string that represents the cancellation details.</returns>
        </member>
        <member name="T:Microsoft.CognitiveServices.Speech.VoiceProfileType">
            <summary>
            Output format.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.VoiceProfileType.TextIndependentIdentification">
            <summary>
            Text independent speaker identification.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.VoiceProfileType.TextDependentVerification">
            <summary>
             Text dependent speaker verification.
            </summary>
        </member>
        <member name="F:Microsoft.CognitiveServices.Speech.VoiceProfileType.TextIndependentVerification">
            <summary>
            Text independent verification.
            </summary>
        </member>
    </members>
</doc>
